<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Modelos lineales generalizados – Mi Sitio en Quarto</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d4be639c637f3db3c684c66cefad7e0c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../style.css">
<link rel="stylesheet" href="style.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Mi Sitio en Quarto</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Página de Inicio</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-capítulo-1" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">CAPÍTULO 1</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-capítulo-1">    
        <li>
    <a class="dropdown-item" href="../CAPITULO_1/A1_intro_optimizacion.html">
 <span class="dropdown-text">Introducción a la Optimización</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../CAPITULO_1/A2_optimalidad.html">
 <span class="dropdown-text">Condiciones de optimalidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../CAPITULO_1/A3_metodos_optimizacion.html">
 <span class="dropdown-text">Métodos de optimización</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#la-familia-exponencial" id="toc-la-familia-exponencial" class="nav-link active" data-scroll-target="#la-familia-exponencial"><span class="header-section-number">1</span> La familia exponencial</a>
  <ul class="collapse">
  <li><a href="#ejemplos" id="toc-ejemplos" class="nav-link" data-scroll-target="#ejemplos"><span class="header-section-number">1.1</span> Ejemplos</a>
  <ul class="collapse">
  <li><a href="#distribución-bernoulli" id="toc-distribución-bernoulli" class="nav-link" data-scroll-target="#distribución-bernoulli"><span class="header-section-number">1.1.1</span> Distribución Bernoulli</a></li>
  <li><a href="#distribución-gaussiana" id="toc-distribución-gaussiana" class="nav-link" data-scroll-target="#distribución-gaussiana"><span class="header-section-number">1.1.2</span> Distribución Gaussiana</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#construcción-de-glms" id="toc-construcción-de-glms" class="nav-link" data-scroll-target="#construcción-de-glms"><span class="header-section-number">2</span> Construcción de GLMs</a>
  <ul class="collapse">
  <li><a href="#terminología" id="toc-terminología" class="nav-link" data-scroll-target="#terminología"><span class="header-section-number">2.1</span> Terminología</a></li>
  </ul></li>
  <li><a href="#ajuste-de-parámetros" id="toc-ajuste-de-parámetros" class="nav-link" data-scroll-target="#ajuste-de-parámetros"><span class="header-section-number">3</span> Ajuste de parámetros</a>
  <ul class="collapse">
  <li><a href="#el-principio-de-máxima-verosimilitud" id="toc-el-principio-de-máxima-verosimilitud" class="nav-link" data-scroll-target="#el-principio-de-máxima-verosimilitud"><span class="header-section-number">3.1</span> El principio de máxima verosimilitud</a>
  <ul class="collapse">
  <li><a href="#el-método-de-gradiente-descendente" id="toc-el-método-de-gradiente-descendente" class="nav-link" data-scroll-target="#el-método-de-gradiente-descendente"><span class="header-section-number">3.1.1</span> El método de gradiente descendente</a></li>
  <li><a href="#el-método-de-newton-raphson" id="toc-el-método-de-newton-raphson" class="nav-link" data-scroll-target="#el-método-de-newton-raphson"><span class="header-section-number">3.1.2</span> El método de Newton-Raphson</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regresión-softmax" id="toc-regresión-softmax" class="nav-link" data-scroll-target="#regresión-softmax"><span class="header-section-number">4</span> Regresión Softmax</a>
  <ul class="collapse">
  <li><a href="#la-distribución-multinomial-como-familia-exponencial" id="toc-la-distribución-multinomial-como-familia-exponencial" class="nav-link" data-scroll-target="#la-distribución-multinomial-como-familia-exponencial"><span class="header-section-number">4.1</span> La distribución multinomial como familia exponencial</a></li>
  <li><a href="#función-de-enlace-y-función-de-respuesta" id="toc-función-de-enlace-y-función-de-respuesta" class="nav-link" data-scroll-target="#función-de-enlace-y-función-de-respuesta"><span class="header-section-number">4.2</span> Función de Enlace y Función de Respuesta</a></li>
  <li><a href="#softmax-function-y-modelo-de-clasificación" id="toc-softmax-function-y-modelo-de-clasificación" class="nav-link" data-scroll-target="#softmax-function-y-modelo-de-clasificación"><span class="header-section-number">4.3</span> Softmax Function y Modelo de Clasificación</a>
  <ul class="collapse">
  <li><a href="#hipótesis-del-modelo" id="toc-hipótesis-del-modelo" class="nav-link" data-scroll-target="#hipótesis-del-modelo"><span class="header-section-number">4.3.1</span> Hipótesis del Modelo</a></li>
  </ul></li>
  <li><a href="#ajuste-de-parámetros-1" id="toc-ajuste-de-parámetros-1" class="nav-link" data-scroll-target="#ajuste-de-parámetros-1"><span class="header-section-number">4.4</span> Ajuste de Parámetros</a>
  <ul class="collapse">
  <li><a href="#ejemplo-práctico-en-python" id="toc-ejemplo-práctico-en-python" class="nav-link" data-scroll-target="#ejemplo-práctico-en-python"><span class="header-section-number">4.4.1</span> Ejemplo Práctico en Python</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Modelos lineales generalizados</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<p><span class="math display">\[
\def\RR{\mathbb{R}}
\def\media{\mathbb{E}}
\def\xx{{\bf x}}
\def\XX{{\bf X}}
\def\TT{{\bf T}}
\def\bftheta{\boldsymbol{\theta}}
\def\bfeta{\boldsymbol{\eta}}
\def\bfone{\mathbf{1}}
\]</span></p>
</div>
<hr style="border: 1px solid rgba(50, 0, 0, 1);">
<p>Tanto en el modelo de regresión lineal como en el de regresión logística, asumimos una cierta distribución condicional para <span class="math inline">\(Y|\XX\)</span> que depende de un conjunto de parámetros <span class="math inline">\(\bftheta\)</span>.</p>
<ul>
<li><p>En regresión lineal, suponemos <span class="math inline">\(Y|\XX\sim\mathcal{N}(\mu,\sigma^2)\)</span> con <span class="math inline">\(\mu=\bftheta^T\XX\)</span>.</p></li>
<li><p>En regresión logística, que recordemos está pensado para problemas de clasificación, suponemos <span class="math inline">\(Y|\XX\sim\text{Bernoulli}(\phi)\)</span> con <span class="math inline">\(\phi=g(\bftheta^T\XX)\)</span>, donde <span class="math inline">\(g(z)=1/(1+e^{-z})\)</span>.</p></li>
</ul>
<p>En esta sección mostraremos que ambos métodos son casos especiales de una familia más amplia de modelos, llamados <strong>Modelos Lineales Generalizados (GLMs)</strong>. También mostraremos cómo otros modelos en GLM pueden derivarse y aplicarse a otros problemas de regresión y clasificación.</p>
<section id="la-familia-exponencial" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> La familia exponencial</h1>
<div class="definicion">
<p><strong>Definición:</strong> Decimos que una clase de distribuciones pertenece a la familia exponencial si se puede escribir en la forma</p>
<p><span class="math display">\[p(y; \bfeta) = b(y) \exp\left(\bfeta^T \TT(y) - a(\bfeta)\right)\]</span></p>
</div>
<ul>
<li><span class="math inline">\(\bfeta\)</span> se llama <strong>parámetro natural</strong> de la distribución.</li>
<li><span class="math inline">\(\TT(y)\)</span> es el <strong>estadístico suficiente</strong>.</li>
<li><span class="math inline">\(a(\bfeta)\)</span> es la <strong>función de partición logarítmica</strong> que normaliza la expresión para que la distribución sea válida (es decir, integre a 1).</li>
</ul>
<p>Una elección fija de <span class="math inline">\(\TT\)</span>, <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> define un conjunto de distribuciones parametrizadas por <span class="math inline">\(\bfeta\)</span>, de manera que al variar <span class="math inline">\(\bfeta\)</span> obtenemos diferentes distribuciones dentro de esta familia.</p>
<section id="ejemplos" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="ejemplos"><span class="header-section-number">1.1</span> Ejemplos</h2>
<p>Mostraremos que las distribuciones Bernoulli y Normal son ejemplos de distribuciones de la familia exponencial.</p>
<section id="distribución-bernoulli" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="distribución-bernoulli"><span class="header-section-number">1.1.1</span> Distribución Bernoulli</h3>
<p>Sea <span class="math inline">\(Y\in\{0,1\}\)</span> tal que <span class="math inline">\(Y\sim\text{Bernoulli}(\phi)\)</span>. Entonces</p>
<p><span class="math display">\[
\begin{align*}
p(y; \phi) &amp;= \phi^y (1 - \phi)^{1-y} \\
&amp; = \exp\left( y \log\phi + (1-y)\log(1-\phi) \right) \\
&amp; = \exp\left(\log\left(\frac{\phi}{1-\phi}\right)y+\log(1-\phi)\right) \\
&amp; = \exp\left(\log\left(\frac{\phi}{1-\phi}\right)y+\log(1-\phi)\right)
\end{align*}
\]</span></p>
<p>Reconocemos el parámetro natural <span class="math display">\[\eta=\log\left(\frac{\phi}{1-\phi}\right)\]</span></p>
<p>mientras que el resto de los elementos son: <span class="math display">\[T(y)=y, \qquad a(\eta)=-\log(1-\phi)=\log(1+e^\eta), \qquad b(y)=1.\]</span></p>
</section>
<section id="distribución-gaussiana" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="distribución-gaussiana"><span class="header-section-number">1.1.2</span> Distribución Gaussiana</h3>
<p>Sea <span class="math inline">\(Y\in\RR\)</span> tal que <span class="math inline">\(Y\sim\mathcal{N}(\mu,\sigma^2)\)</span>. Entonces</p>
<p><span class="math display">\[
\begin{align*}
p(y; \mu, \sigma^2) &amp; = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(y - \mu)^2}{2\sigma^2}\right) \\
&amp; = \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2\sigma^2}y^2+\frac{\mu}{\sigma^2}y-\frac{\mu^2}{2\sigma^2}-\log\sigma\right) \\
&amp; = \frac{1}{\sqrt{2\pi}}\exp\left(\left(\frac{\mu}{\sigma^2},-\frac{1}{2\sigma^2}\right)^T(y,y^2)-\frac{\mu^2}{2\sigma^2}-\log\sigma\right)
\end{align*}
\]</span></p>
<p>El parámetro natural es el vector</p>
<p><span class="math display">\[\bfeta=\left(\frac{\mu}{\sigma^2},-\frac{1}{2\sigma^2}\right)\]</span></p>
<p>y el resto de los elementos son <span class="math display">\[\TT(y)=(y,y^2), \qquad a(\bfeta)=\frac{\mu^2}{2\sigma^2}+\log\sigma=-\frac{\eta_1^2}{4\eta_2}+\frac{1}{2}\log(-2\eta_2), \qquad b(y)=\frac{1}{\sqrt{2\pi}}.\]</span></p>
<hr>
<p>Existen muchas otras distribuciones que son miembros de la familia exponencial: la multinomial (que veremos más adelante), la Poisson (para modelar datos de conteo), la gamma y la exponencial (para modelar variables continuas no negativas, como intervalos de tiempo); la beta y la Dirichlet (para distribuciones sobre probabilidades); y muchas más.</p>
<p>En la próxima sección, describiremos una “receta” general para construir modelos en los cuales <span class="math inline">\(y\)</span> (dado <span class="math inline">\(\xx\)</span> y <span class="math inline">\(\theta\)</span>) proviene de cualquiera de estas distribuciones.</p>
</section>
</section>
</section>
<section id="construcción-de-glms" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Construcción de GLMs</h1>
<p>Supongamos que deseas construir un modelo para estimar el número <span class="math inline">\(y\)</span> de clientes que llegan a tu tienda (o el número de visitas a páginas web en tu sitio) en una hora determinada, basándote en ciertas características como promociones en la tienda, publicidad reciente, clima, día de la semana, etc. Sabemos que la distribución Poisson usualmente proporciona un buen modelo para el número de visitantes. Sabiendo esto, ¿cómo podemos proponer un modelo para nuestro problema? Afortunadamente, la Poisson es una distribución de la familia exponencial, por lo que podemos aplicar un Modelo Lineal Generalizado (GLM). En esta sección, describiremos un método para construir modelos GLM para problemas como este.</p>
<p>Más generalmente, consideremos un problema de regresión o clasificación o regresión donde queremos predecir el valor de alguna variable aleatoria <span class="math inline">\(y\)</span> como función de <span class="math inline">\(\xx\)</span>. Para derivar un GLM para este problema, haremos las siguientes tres suposiciones:</p>
<div class="highlight">
<p><strong>Suposición 1:</strong> <span class="math inline">\(y|\xx;\bftheta\sim\text{FamiliaExponencial}(\bfeta)\)</span>.</p>
<p><strong>Suposición 2:</strong> Dado <span class="math inline">\(\xx\)</span>, el objetivo es predecir <span class="math inline">\(\media[T(y)|\xx]\)</span>.</p>
<p><strong>Suposición 3:</strong> El parámetro natural <span class="math inline">\(\bfeta\)</span> y las predictoras <span class="math inline">\(\xx\)</span> están relacionadas linealmente; esto es, <span class="math inline">\(\bfeta=\bftheta^T\xx\)</span>.</p>
</div>
<p>Generalmente <span class="math inline">\(T(y)=y\)</span> y, en tal caso, la suposición 2 significa que queremos que la predicción sea <span class="math inline">\(h(\xx)=\media[\xx]\)</span>. Por otra parte, si el parámetro natural <span class="math inline">\(\bfeta\)</span> es un vector, observar que la suposición 3 implica que <span class="math inline">\(\bftheta\)</span> debe ser una matriz. Esta última suposición podría parecer la menos justificada de las anteriores, y podría considerarse más como una “elección de diseño” en nuestra receta para diseñar GLMs, en lugar de una suposición como tal.</p>
<p>Estas tres suposiciones o elecciones de diseño nos permitirán derivar una clase muy elegante de algoritmos de aprendizaje, a saber, los GLMs, que tienen muchas propiedades deseables, como la facilidad de aprendizaje. Además, los modelos resultantes son frecuentemente muy efectivos.</p>
<section id="terminología" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="terminología"><span class="header-section-number">2.1</span> Terminología</h2>
<ul>
<li><p>La función <span class="math inline">\(g(\bfeta) = \mathbb{E}[T(y); \bfeta]\)</span> se denomina <strong>función de respuesta canónica</strong>.</p></li>
<li><p>La inversa de esta función, <span class="math inline">\(g^{-1}\)</span>, se llama la <strong>función de enlace canónica</strong>.</p></li>
</ul>
</section>
</section>
<section id="ajuste-de-parámetros" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Ajuste de parámetros</h1>
<p>Los Modelos Lineales Generalizados (GLMs) son una extensión poderosa de los modelos lineales que permite trabajar con una amplia variedad de distribuciones en la familia exponencial. En esta sección, discutiremos en detalle cómo se ajustan los parámetros de un GLM usando el principio de máxima verosimilitud.</p>
<section id="el-principio-de-máxima-verosimilitud" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="el-principio-de-máxima-verosimilitud"><span class="header-section-number">3.1</span> El principio de máxima verosimilitud</h2>
<p>El ajuste de parámetros en los GLMs se basa en maximizar la log-verosimilitud de los datos observados. Dado un conjunto de entrenamiento <span class="math inline">\(\{(\xx^{(i)}, y^{(i)})\}_{i=1}^n\)</span>, la función de log-verosimilitud está dada por:</p>
<p><span class="math display">\[
\ell(\theta) = \log L(\theta) = \sum_{i=1}^n \log p(y^{(i)} | \xx^{(i)}; \theta).
\]</span></p>
<p>Para maximizar <span class="math inline">\(\ell(\theta)\)</span>, derivamos con respecto a <span class="math inline">\(\theta\)</span> para obtener el gradiente. En GLMs, las propiedades de la familia exponencial simplifican esta derivada, que resulta ser:</p>
<p><span class="math display">\[
\nabla_\theta \ell(\theta) = \sum_{i=1}^n (T(y^{(i)}) - \mathbb{E}[T(y) | \xx^{(i)}; \theta]) \xx^{(i)}.
\]</span></p>
<p>A continuación describiremos dos métodos iterativos para realizar la tarea de maximizar la log-verosimilitud.</p>
<section id="el-método-de-gradiente-descendente" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="el-método-de-gradiente-descendente"><span class="header-section-number">3.1.1</span> El método de gradiente descendente</h3>
<p>Este método optimiza <span class="math inline">\(\ell(\bftheta)\)</span> iterativamente ajustando los parámetros en la dirección opuesta al gradiente de la función objetivo, con un paso de tamaño controlado por una tasa de aprendizaje <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
\bftheta^{(t+1)} = \bftheta^{(t)} - \alpha \nabla_\theta \ell(\bftheta^{(t)}).
\]</span></p>
<p>El gradiente descendente es computacionalmente barato, pero su convergencia puede ser lenta, especialmente si no se ajusta adecuadamente la tasa de aprendizaje.</p>
</section>
<section id="el-método-de-newton-raphson" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="el-método-de-newton-raphson"><span class="header-section-number">3.1.2</span> El método de Newton-Raphson</h3>
<p>Este método requiere calcular la Hessiana de <span class="math inline">\(\ell(\theta)\)</span>, que es la matriz de segundas derivadas</p>
<p><span class="math display">\[
H(\bftheta) = \sum_{i=1}^n \left(-\text{Var}[T(y) | \xx^{(i)}; \bftheta]\right) \xx^{(i)} (\xx^{(i)})^T,
\]</span></p>
<p>El método de Newton-Raphson actualiza <span class="math inline">\(\bftheta\)</span> como:</p>
<p><span class="math display">\[
\bftheta^{(t+1)} = \bftheta^{(t)} - H(\bftheta^{(t)})^{-1} \nabla_\theta \ell(\bftheta^{(t)}).
\]</span></p>
<p>Aunque este método converge rápidamente en muchas aplicaciones, calcular la Hessiana e invertirla puede ser computacionalmente costoso para modelos de alta dimensionalidad.</p>
</section>
</section>
</section>
<section id="regresión-softmax" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Regresión Softmax</h1>
<p>Consideremos un problema de clasificación en el que <span class="math inline">\(Y \in \{1, 2, \ldots, k\}\)</span>. Por ejemplo, en lugar de clasificar correos electrónicos en dos clases (spam o no spam), podríamos clasificarlos en tres clases: spam, correo personal y correo relacionado con el trabajo. Para modelar esta situación, usaremos la <strong>distribución multinomial</strong> como una distribución de la familia exponencial.</p>
<section id="la-distribución-multinomial-como-familia-exponencial" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="la-distribución-multinomial-como-familia-exponencial"><span class="header-section-number">4.1</span> La distribución multinomial como familia exponencial</h2>
<p>Supongamos que <span class="math inline">\(Y\in\{1, 2, \cdots, k\}\)</span> se distribuye mediante una distribución multinomial con <span class="math inline">\(k-1\)</span> parámetros <span class="math inline">\(\phi_1, \dots, \phi_{k-1}\)</span>, y sea <span class="math inline">\(\phi_k=1-\sum_{i=1}^{k-1}\phi_i\)</span>, tal que <span class="math inline">\(\sum_{i=1}^k \phi_i = 1\)</span>. Para expresar la multinomial como una distribución de la familia exponencial, definimos</p>
<p><span class="math display">\[
T(1) = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix},
\quad
T(2) = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix},
\quad \dots, \quad
T(k-1) = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix},
\quad
T(k) = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{pmatrix}.
\]</span></p>
<p>En lo que sigue, <span class="math inline">\(\bfone\{\cdot\}\)</span> es la función indicatriz, que vale 1 si su argumento es cierto y 0 en caso contrario. Resulta</p>
<p><span class="math display">\[
\begin{align*}
p(y; \mathbf{\phi})&amp; =
\phi_1^{\bfone\{y=1\}} \phi_2^{\bfone\{y=2\}} \cdots \phi_k^{\bfone\{y=k\}}\\
&amp;= \phi_1^{(T(y))_1} \phi_2^{(T(y))_2} \cdots \phi_{k-1}^{(T(y))_{k-1}} \left(1 - \sum_{i=1}^{k-1} \phi_i\right)^{1-\sum_{i=1}^{k-1}(T(y))_i}
\\
&amp;= \exp\left((T(y))_1 \log(\phi_1) + (T(y))_2 \log(\phi_2) + \dots + \left(1 - \sum_{i=1}^{k-1}(T(y))_i\right)\log\left(1 - \sum_{i=1}^{k-1} \phi_i\right)\right).
\end{align*}
\]</span></p>
<p>Así, <span class="math inline">\(Y\)</span> se distribuye en la familia exponencial</p>
<p><span class="math display">\[
p(y; \phi) = b(y) \exp\left(\eta^T T(y) - a(\eta)\right),
\]</span></p>
<p>donde:</p>
<p><span class="math display">\[
\begin{align*}
\eta &amp;= \begin{bmatrix}
\log\left(\frac{\phi_1}{\phi_k}\right) \\
\log\left(\frac{\phi_2}{\phi_k}\right) \\
\vdots \\
\log\left(\frac{\phi_{k-1}}{\phi_k}\right)
\end{bmatrix},
\\
a(\eta) &amp;= -\log(\phi_k),
\\
b(y)&amp; = 1.
\end{align*}
\]</span></p>
<p>Esto completa nuestra formulación de la multinomial como una distribución de la familia exponencial.</p>
<p>La función que mapea () a () se llama la <strong>función softmax</strong>:</p>
</section>
<section id="función-de-enlace-y-función-de-respuesta" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="función-de-enlace-y-función-de-respuesta"><span class="header-section-number">4.2</span> Función de Enlace y Función de Respuesta</h2>
<p>La función de enlace está dada (para <span class="math inline">\(i = 1, \dots, k\)</span>) por:</p>
<p><span class="math display">\[
\eta_i = \log\left(\frac{\phi_i}{\phi_k}\right).
\]</span></p>
<p>Para conveniencia, también definimos <span class="math inline">\(\eta_k = \log(\phi_k / \phi_k) = 0\)</span>. Para invertir la función de enlace y derivar la función de respuesta, tenemos que:</p>
<p><span class="math display">\[
e^{\eta_i} = \frac{\phi_i}{\phi_k},
\]</span></p>
<p>lo que implica:</p>
<p><span class="math display">\[
\phi_k \sum_{i=1}^k e^{\eta_i} = \sum_{i=1}^k \phi_i = 1.
\]</span></p>
<p>Por lo tanto:</p>
<p><span class="math display">\[
\phi_k = \frac{1}{\sum_{i=1}^k e^{\eta_i}},
\]</span></p>
<p>y al sustituir en la ecuación obtenemos la función de respuesta:</p>
<p><span class="math display">\[
\phi_i = \frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}.
\]</span></p>
</section>
<section id="softmax-function-y-modelo-de-clasificación" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="softmax-function-y-modelo-de-clasificación"><span class="header-section-number">4.3</span> Softmax Function y Modelo de Clasificación</h2>
<p>La función que mapea de <span class="math inline">\(\eta\)</span> a <span class="math inline">\(\phi\)</span> se llama la función .</p>
<p>Para completar nuestro modelo, usamos la Asunción 3, mencionada previamente, donde los <span class="math inline">\(\eta_i\)</span> están relacionados linealmente con los <span class="math inline">\(x\)</span>’s. Así, tenemos <span class="math inline">\(\eta_i = \theta_i^T x\)</span> (para <span class="math inline">\(i = 1, \dots, k - 1\)</span>), donde <span class="math inline">\(\theta_1, \dots, \theta_{k-1} \in \mathbb{R}^{d+1}\)</span> son los parámetros de nuestro modelo. Por notación, podemos definir <span class="math inline">\(\theta_k = 0\)</span>, de modo que <span class="math inline">\(\eta_k = \theta_k^T x = 0\)</span>, como se definió anteriormente. Por lo tanto, nuestro modelo asume que la distribución condicional de <span class="math inline">\(y\)</span> dado <span class="math inline">\(x\)</span> está dada por:</p>
<p><span class="math display">\[
\begin{align*}
p(y = i | x; \theta) &amp;= \phi_i\\
&amp;= \frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}\\
&amp;= \frac{e^{\theta_i^T x}}{\sum_{j=1}^k e^{\theta_j^T x}}, \quad (5)
\end{align*}
\]</span></p>
<p>donde este modelo, que aplica a problemas de clasificación donde <span class="math inline">\(y \in \{1, \dots, k\}\)</span>, se llama . Es una generalización de la regresión logística.</p>
<section id="hipótesis-del-modelo" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="hipótesis-del-modelo"><span class="header-section-number">4.3.1</span> Hipótesis del Modelo</h3>
<p>Nuestra hipótesis producirá:</p>
<p><span class="math display">\[
\begin{align*}
h_\theta(x) &amp;= \mathbb{E}[T(y) | x; \theta]
\\
&amp;= \mathbb{E}
\begin{bmatrix}
1\{y = 1\} \\
1\{y = 2\} \\
\vdots \\
1\{y = k - 1\}
\end{bmatrix}
\\&amp;=
\begin{bmatrix}
\phi_1 \\
\phi_2 \\
\vdots \\
\phi_{k-1}
\end{bmatrix}
\\&amp;=
\begin{bmatrix}
\frac{\exp(\theta_1^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)} \\
\frac{\exp(\theta_2^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)} \\
\vdots \\
\frac{\exp(\theta_{k-1}^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)}
\end{bmatrix}.
\end{align*}
\]</span></p>
<p>En otras palabras, nuestra hipótesis producirá la probabilidad estimada de que <span class="math inline">\(p(y = i | x; \theta)\)</span> para cada valor <span class="math inline">\(i = 1, \dots, k\)</span>. (Aunque <span class="math inline">\(h_\theta(x)\)</span>, como se definió arriba, tiene solo <span class="math inline">\(k - 1\)</span> dimensiones, claramente <span class="math inline">\(p(y = k | x; \theta)\)</span> puede obtenerse como <span class="math inline">\(1 - \sum_{i=1}^{k-1} \phi_i\)</span>).</p>
</section>
</section>
<section id="ajuste-de-parámetros-1" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="ajuste-de-parámetros-1"><span class="header-section-number">4.4</span> Ajuste de Parámetros</h2>
<p>Por último, discutamos el ajuste de parámetros. Similar a nuestra derivación original de mínimos cuadrados ordinarios y regresión logística, si tenemos un conjunto de entrenamiento de <span class="math inline">\(n\)</span> ejemplos <span class="math inline">\(\{(x^{(i)}, y^{(i)}); i = 1, \dots, n\}\)</span> y deseamos aprender los parámetros <span class="math inline">\(\theta_i\)</span> de este modelo, comenzaríamos escribiendo la log-verosimilitud:</p>
<p><span class="math display">\[
\begin{align*}
\ell(\theta) &amp;= \sum_{i=1}^n \log p(y^{(i)} | x^{(i)}; \theta)
\\
&amp;= \sum_{i=1}^n \log \prod_{l=1}^k \left( \frac{e^{\theta_l^T x^{(i)}}}{\sum_{j=1}^k e^{\theta_j^T x^{(i)}}} \right)^{1\{y^{(i)} = l\}}.
\end{align*}
\]</span></p>
<p>Para obtener la segunda línea anterior, usamos la definición de <span class="math inline">\(p(y | x; \theta)\)</span> dada en la Ecuación (5). Ahora podemos obtener la estimación de máxima verosimilitud de los parámetros maximizando <span class="math inline">\(\ell(\theta)\)</span> en términos de <span class="math inline">\(\theta\)</span>, utilizando un método como ascenso de gradiente o el método de Newton.</p>
<p>ACA FALTA AJUSTE DE PARAMETROS PARA EL MODELO GLM EN GENERAL eso esta en el video de el viejo del 2008 , no esta en el nuevo. seria importante poner algo</p>
<section id="ejemplo-práctico-en-python" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="ejemplo-práctico-en-python"><span class="header-section-number">4.4.1</span> Ejemplo Práctico en Python</h3>
<p>Implementemos un ejemplo práctico para un problema de clasificación multiclasificación.</p>
<div id="3f8e9e06" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar datos simulados para clasificación multiclase</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">300</span>, n_features<span class="op">=</span><span class="dv">2</span>, n_informative<span class="op">=</span><span class="dv">2</span>, n_redundant<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    n_classes<span class="op">=</span><span class="dv">3</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar los datos</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Datos de Clasificación Multiclase"</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Característica 1"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Característica 2"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">"Clases"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Dividir los datos en entrenamiento y prueba</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar el modelo de regresión softmax</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">"multinomial"</span>, solver<span class="op">=</span><span class="st">"lbfgs"</span>, max_iter<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicciones</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Frontera de decisión</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, <span class="fl">0.01</span>),</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>                     np.arange(y_min, y_max, <span class="fl">0.01</span>))</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> model.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z, alpha<span class="op">=</span><span class="fl">0.8</span>, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, edgecolor<span class="op">=</span><span class="st">"k"</span>, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frontera de Decisión: Regresión Softmax"</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Característica 1"</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Característica 2"</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">"Clases"</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluación del modelo</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reporte de Clasificación:"</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Matriz de Confusión:"</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, y_pred))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_GLM_files/figure-html/cell-2-output-1.png" width="652" height="523" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\isaia\AppData\Local\Programs\Python\Python313\Lib\site-packages\sklearn\linear_model\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_GLM_files/figure-html/cell-2-output-3.png" width="652" height="524" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reporte de Clasificación:
              precision    recall  f1-score   support

           0       0.75      0.89      0.81        27
           1       0.92      0.89      0.91        38
           2       1.00      0.84      0.91        25

    accuracy                           0.88        90
   macro avg       0.89      0.87      0.88        90
weighted avg       0.89      0.88      0.88        90

Matriz de Confusión:
[[24  3  0]
 [ 4 34  0]
 [ 4  0 21]]</code></pre>
</div>
</div>


<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section>
</section>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../CAPITULO_2";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>