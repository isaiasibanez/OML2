---
title: "Condiciones de optimalidad en Optimización"
---

<hr style="border: 1px solid rgba(50, 0, 0, 1);">

{{< include ../macros.qmd >}}



En un problema de optimización general
$$
\min_{x} f(x)
$$
$$
\text{s.t.}\; x\in\Omega=\left\{x\in\RR^n\left|\begin{array}{rl}
g_i(x)\leq 0,& i=1,\cdots,r.\\
h_j(x)=0, & j=1,\cdots,m.
\end{array}\right.\right\},
$$

las condiciones de optimalidad definen los requisitos que deben cumplir los puntos óptimos. En lo que sigue, asumiremos que trabajamos con funciones diferenciables.



# Condiciones de optimalidad de primer orden

## Optimización sin restricciones

De cursos anteriores recordemos que, cuando se pretende optimizar una función $f$ respecto a $x\in\RR^n$, una condición necesaria para que un punto sea óptimo es que verifique 
$$
\nabla f(x)=\mathbf{0}.
$$

Pero cuidado: es **solo una condición necesaria** que todos los puntos óptimos deben cumplir, pero no implica que cualquier punto que la satisfaga sea automáticamente óptimo. En otras palabras, las soluciones de $\nabla f(x) = 0$ forman una lista de puntos candidatos para minimizar, llamados *puntos críticos*.

De inmediato surgen dos preguntas claves:

- ¿Cuál es la generalización correcta de la condición necesaria $\nabla f(x) = 0$ cuando enfrentamos un **problema de optimización con restricciones**?
- ¿Bajo qué circunstancias $\nabla f(x) = 0$ también se convierte en una condición suficiente para la optimalidad?

Antes, veamos cómo surge la condición $\nabla f(x)=\mathbf{0}$ para problemas de optimización sin restricciones.

### Prueba de condición necesaria $\nabla f(x)=\mathbf{0}$

Sea $x\in\RR^n$ es un minimizador de la función $f: \RR^n \to \RR$ y sea $d\in\RR^n$ una dirección arbitraria. Entonces se cumple

$$
f(x + t \cdot d) \geq f(x) \quad \text{para todo } t \geq 0.
$$

En consecuencia, la derivada direccional de $f$ en $x$ a lo largo de $d$ es

$$
\frac{\partial f}{\partial d}(x)= \lim_{t \to 0} \frac{f(x + t \cdot d) - f(x)}{t} \geq 0.
$$

Ahora bien, como $f$ es diferenciable, se verifica la propiedad $\frac{\partial f}{\partial d}(x)=\langle \nabla f(x),d\rangle$, por lo que la desigualdad anterior se puede reescribir como:

$$
\langle \nabla f(x), d \rangle \geq 0 \quad \forall d \in {R}^n.
$$

En particular, eligiendo $d = -\nabla f(x)$, resulta $-\|\nabla f(x)\|^2\geq 0$, lo cual es cierto si y sólo si $\nabla f(x)=\mathbf{0}$.



## Optimización con restricciones

La clave para generalizar la condición $\nabla f(x)=\mathbf{0}$ al caso de optimización con restricciones surge de la prueba anterior, más precisamente de la desigualdad $\langle\nabla f(x),d\rangle\geq 0$.

La diferencia principal con el caso sin restricciones es que, en un conjunto restringido, podríamos estar limitados en la elección de las direcciones $d$ a lo largo de las cuales podemos aproximarnos a $x$ sin salirnos del conjunto.

No obstante, para cualquier dirección $d$ tal que $x + t \cdot d \in \Omega$ para todo $t \geq 0$ suficientemente pequeño, el mismo argumento aplicado anteriormente sigue siendo válido. Por lo tanto, podemos concluir que necesariamente:

$$
\langle \nabla f(x), d \rangle \geq 0 \quad \text{para todo } d \in  {R}^n \text{ que permanezca en } \Omega \text{ desde } x.
$$

Para aplicar esta condición, se requieren dos pasos:

1. Determinar el conjunto de direcciones $d$ que permanecen en $\Omega$ desde $x$*.

2. A partir de esas direcciones, ver de qué manera imponen restricciones sobre $\nabla f(x)$. 

De estos dos pasos, el primero suele ser el más sencillo. En todos los casos de interés, podemos determinar el conjunto de direcciones permitidas simplemente considerando cualquier otro punto $y \in \Omega$ y observando la dirección de $x$ a $y$. Esta propiedad se cumple trivialmente si todos los segmentos de línea entre $x$ y cualquier punto en $\Omega$ están contenidos en $\Omega$, lo cual es siempre cierto para conjuntos convexos.


::: {.teorema}
**Teorema 1.** (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo) 
Sea $\Omega \subseteq  {R}^n$ convexo y sea $f:  {R}^n \to  {R}$ una función diferenciable. Si $x \in \Omega$ es un minimizador de $f$ sobre $\Omega$, entonces
$$
\langle \nabla f(x), y - x \rangle \geq 0 \quad \forall y \in \Omega.
$$  
:::


<details>
<summary>Interpretación geométrica</summary>
<hr>
La condición del Teorema 1 se verifica si el vector gradiente de $f$ en una solución $x\in\Omega$ forma un ángulo agudo con todas las direcciones $y-x$, donde $y\in\Omega$.

Ahora bien, a la hora de buscar un minimizador, la dirección que realmente nos importa es $-\nabla f(x)$. Así, el Teorema 1 nos dice que $-\nabla f(x)$ debe formar un ángulo obtuso con las direcciones $y-x$. En otras palabras, la condición dada es equivalente a escribir

$$
-\nabla f(x)\in N_{\Omega}(x),
$$

donde $N_{\Omega}(x)$ es el cono normal a $\Omega$ en $x$.

Es importante observar que si $x$ es un punto interior de $\Omega$, sabemos que $N_{\Omega}(x)=\{\mathbf{0}\}$ y, en consecuencia, debe ser $\nabla f(x)=\mathbf{0}$. Esto es consistente con la condición de optimalidad de los problemas sin restricciones.

No obstante, la importancia del Teorema 1 radica en cómo tratar los puntos en la frontera de $\Omega$. A partir de los ejemplos previamente estudiados sobre el cono normal, podemos ver que la interpretación del Teorema 1 es bastante intuitiva. Por ejemplo, si $\Omega$ es un polígono y $x\in\Omega$ es una solución, el vector $-\nabla f(x)$ es perpendicular a $\Omega$ y apunta hacia afuera, lo cual significa que no hay posibilidad de "moverse" en dirección opuesta al gradiente sin salirse de $\Omega$.
<hr>
</details>


¡Cuidado! La condición provista por el Teorema 1 es necesaria pero no suficiente. Podría verificarse la condición en otros puntos críticos de $\Omega$ que no sean un mínimo global de $f$ en dicho conjunto. Sin embargo, para el notable caso de las funciones convexas dicha condición sí es suficiente.


::: {.teorema}
**Teorema 2.** (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo y una función  objetivo convexa) 
Sea $\Omega \subseteq  {R}^n$ convexo y sea $f:  {R}^n \to  {R}$ una función diferenciable convexa. Entonces
$$
-\nabla f(x)\in N_{\Omega}(x)\Leftrightarrow x \text{ es un minimizador de }f\text{ en }\Omega.
$$  
:::



# Condiciones de Karush-Kuhn-Tucker (KKT)

## El caso particular de restricciones lineales

Vamos a considerar el caso en que $\Omega$ un polítopo convexo, esto es, el conjunto convexo definido por la intersección de un número finito de medios espacios (desigualdades lineales):

$$
\Omega=\{\xx\in\RR^n|A\xx\leq \bfb\},
$$

donde $A\in\RR^{m\times n}$ es una matriz, cuyas filas denotaremos con $\bfa_j$, $j=1,\cdots,m$, y $\bfb\in\RR^m$.






En el ejemplo ... (<span style="color: red;">Agregar ejemplo 3.6 de Lecture 2 a 'Intro'</span>)
hemos visto que el cono normal en un punto en la intersección de dos medios espacios es la envolvente cónica de las direcciones ortogonales a dichos subespacios.

<figure style="text-align: center;">
  <img src="figuras/conic_hull_halfspaces_intersection.png" alt="Conic Hull" width="200px">
  <figcaption>Envolvente cónica de la intersección de dos subespacios $\bfa_1^T\xx\leq b_1$ y $\bfa_2^T\xx\leq b_2$.</figcaption>
</figure>


Por otra parte, los otros casos también ya han sido vistos:

- Si $\xx$ pertenece al interior de $\Omega$, entonces $N_{\Omega}(\xx)=\{\mathbf{0}\}$.
- Si $\xx$ pertenece a la frontera de un único medio espacio, a saber $\bfa_k^T\xx=b_k$, entonces $N_{\Omega}(\xx)=\{\lambda \bfa_k:\lambda\geq 0\}$.


La generalización al caso de $m$ medios espacios se presenta en el siguiente teorema.


::: {.teorema}
**Teorema 3.** 
Sea $\Omega=\{x\in\RR^n\}$ la intersección de $m$ medios espacios $\bfa_j^T\xx\leq b_j$. Dado un punto $x\in\Omega$, se define el conjunto de índices de las *restricciones activas* mediante

$$
I(\xx):=\left\{j\in\{1,\cdots,m\}:\bfa_j^T\xx=b_j\right\}.
$$
Entonces, el cono normal en $\xx$ está dado por

$$
N_{\Omega}(\xx)=\left\{\sum_{j\in I(\xx)}\lambda_j\bfa_j:\lambda_j\geq 0\right\}.
$$
:::


<details>
<summary>Interpretación</summary>
<hr>

Si $\xx$ pertenece al interior de $\Omega$, entonces no hay restricciones activas. Esto se corresponde con el hecho de que el cono normal es $N_{\Omega}(\xx)=\{\mathbf{0}\}$.

Por su parte, si $\xx$ pertenece a la frontera de $\Omega$, entonces el cono normal es la envolvente cónica de las direcciones ortogonales a las restricciones activas.

Observar que la condición de optimalidad $-\nabla f(\xx)\in N_{\Omega}(\xx)$ se traduce como

$$
-\nabla f(\xx)=\sum_{j\in I(\xx)}\lambda_j\bfa_j,
$$

y, en consecuencia, se puede escribir

$$
\nabla f(\xx)-\sum_{j\in I(\xx)}\lambda_j \nabla g_j(\xx)=0,
$$

con $g_j(\xx)=\bfa_j^T\xx-b$. Los coeficientes $\lambda_j$ se denominan tipicamente *multiplicadores de Lagrange*.
<hr>
</details>


La suma en la expresión del cono normal puede ser reescrita sin restringir $j\in I(\xx)$, simplemente imponiendo $\lambda_j=0$ para todo $j\notin I(\xx)$. Esta imposición queda ímplicita de forma inmediata si se escribe

$$
\sum_{j=1}^m\lambda_j\left(\bfa_j^T\xx-b_j\right)=0.
$$

En forma vectorial, esto es $\bflambda^T\left(A\xx-\bfb\right)=0$, donde $\bflambda=(\lambda_1,\cdots,\lambda_m)^T$. Con esta notación, el resultado del Teorema 3 puede reescribirse como

$$
N_{\Omega}(\xx)=\left\{A^T\bflambda:\bflambda^T(A\xx-\bfb)=0,\bflambda\in\RR^m_{\geq 0}\right\}.
$$


Para concluir este análisis, y teniendo en cuenta lo expuesto hasta aquí, podemos hacer énfasis en tres condiciones necesarias para que una solución sea óptima en este caso particular de restricciones lineales.

::: {.highlight}

Para que $\xx\in\Omega$ sea un minimizador de $f$ sobre $\Omega$, debe cumplir:


- **Estacionariedad**: El gradiente debe ser una combinación lineal de los gradientes de las restricciones activas.
$$
\nabla f(\xx)-\sum_{j=1}^{m}\lambda_j(\bfa_j^T\xx-b_j).
$$

- **Factibilidad dual**: Los multiplicadores de Lagrange asociados a las restricciones de desigualdad deben ser no negativos.
$$
\lambda_j\geq 0 \quad \forall j=1,\cdots,m.
$$

- **Holgura complementaria**: Los multiplicadores de Lagrange solo pueden ser positivos si la restricción está activa.
$$
\lambda_j\left(\bfa_j^T\xx-b_j\right)=0 \quad \forall j=1,\cdots,m.
$$
:::


<br>
Las condiciones mencionadas se conocen como **condiciones de Karush-Kuhn-Tucker** y son una consecuencia de la caracterización del cono normal para conjuntos definidos como interseccion de restricciones lineales, provista por el Teorema 3. Ya estamos en condiciones de abordar el problema de optimización general.


## Generalización

Consideremos el problema de optimización general
$$
\min_{x} f(x)
$$
$$
\text{s.t.}\; x\in\Omega=\left\{x\in\RR^n\left|\begin{array}{rl}
h_i(x)= 0,& i=1,\cdots,r.\\
g_j(x)\leq 0, & j=1,\cdots,m.
\end{array}\right.\right\},
$$

donde $\Omega$ está definido como una intersección de restricciones funcionales diferenciables.


Supongamos que $\xx^*$ es un punto óptimo en la frontera del conjunto factible $\Omega$ correspondiente a tres condiciones de desigualdad $g_i(x) \le 0$ para $i=1,2,3$ (ver figura abajo). La idea principal es la siguiente:

> *El conjunto de direcciones que forma un ángulo obtuso con todas las direcciones desde $\xx^*$ que permanecen en $\Omega$ coincide con el cono normal de la linearización de las restricciones activas en $\xx^*$.*

<figure style="text-align: center;">
  <img src="figuras/conic_hull_generalization.png" alt="Conic Hull" width="400px">
  <figcaption>Envolvente cónica de la intersección de restricciones $g_i(\xx)\leq 0$, para $i=1,2,3$.</figcaption>
</figure>


Si aplicamos la idea anterior a $-\nabla f(\xx)$ y consideramos el Teorema 3, obtenemos la generalización de las condiciones de optimalidad de Karush-Kuhn-Tucker (KKT). Denominemos $\tilde{\Omega}$ la linearización de $\Omega$, dado por la linearización de las restricciones en un punto óptimo $\xx^*$:

$$
h_i(\xx^*)+\nabla h_i(\xx^*)\cdot (\xx-\xx^*)=0,
$$

$$
g_i(\xx^*)+\nabla g_i(\xx^*)\cdot (\xx-\xx^*)\leq 0.
$$

Entonces, por Teorema 3, resulta

$$
N_{\tilde{\Omega}}(\xx^*)=\left\{\sum_{i=1}^m\lambda_i\nabla h_i(\xx^*)+\sum_{j\in I(\xx^*)}\mu_j\nabla g_j(\xx^*): \lambda_i\in\RR, \mu_j\in\RR_{\geq 0}\right\},
$$

donde $I(\xx^*):=\left\{j\in\{1,\cdots,m\}: g_j(\xx^*)=0\right\}$. Por supuesto, puede reformularse la condición $j\in I(\xx^*) utilizando holgura complementaria, tal como antes.

Si bien no estamos aún en condiciones de extender el Teorema 3, puesto que el desarrollo previo fue más bien intuitivo, podemos establecer las condiciones KKT mediante una definición formal de la siguiente manera.


::: {.definicion}
**Definición 1.** (Condiciones de Karush-Kuhn-Tucker (KKT) 
Sea un problema de optimización no lineal con función objetivo diferenciable y restricciones funcionales, de la forma
$$
\text{s.t.}\; x\in\Omega=\left\{x\in\RR^n\left|\begin{array}{rl}
h_i(x)= 0,& i=1,\cdots,r.\\
g_j(x)\leq 0, & j=1,\cdots,m.
\end{array}\right.\right\},
$$

y sea $\xx\in\Omega$ (**factibilidad primal**). Las *condiciones KKT* en $\xx$ están dadas por:

- **Estacionariedad**:
$$
-\nabla f(\xx)=\sum_{i=1}^r\lambda_i\nabla h_i(\xx)+\sum_{j=1}^m\mu_j\nabla g_j(\xx).
$$

- **Factibilidad dual**:
$$
\lambda_i\in\RR, \mu_j\in\RR_{\geq 0}\quad\forall i=1,\cdots,r, \forall j=1,\cdots, m.
$$

- **Holgura complementaria**:
$$
\mu_j g_j(\xx)=0\quad \forall j=1,\cdots,m.
$$
:::

Es importante remarcar que:

- Las condiciones KKT indican que -$\nabla f(\xx)$ debe estar en el cono normal a la linearización del conjunto de restricciones.

- La condición de holgura compelementaria se resume en "si la restricción $g_j(\xx)\leq 0$ no está activa, entonces $\mu_j=0$".

- Las condiciones KKT a menudo son necesarias para la optimalidad, pero no siempre. 


A continuación, veremos un ejemplo donde las condiciones KKT fallan. Luego, en la siguiente sección veremos en qué escenarios las condiciones KKT son efectivamente una condición necesaria de optimalidad.









## Cualificación de restricciones




# Dualidad

La teoría de la dualidad juega un papel fundamental en la optimización, permitiendo reformular problemas en términos de funciones duales que pueden proporcionar información valiosa sobre la solución óptima.

## Función dual de Lagrange

::: {.definicion}
**Definición 2.** (Lagrangiano) Sea el problema de optimización general
$$
\min f(\xx)
$$
$$
\text{sujeto a}\; \xx\in\Omega=\left\{\xx\in\RR^p\left|\begin{array}{rl}
g_i(\xx)\leq 0,& i=1,\cdots,q\\
h_j(\xx)= 0, & j=1,\cdots,r
\end{array}\right.\right\}.
$$

Se denomina *Lagrangiano* a la función $\calL:\RR^p\times\RR^q\times\RR^r\to\RR$ definida por
$$
\calL(\xx,\bflambda,\bfnu)=f(\xx)+\sum_{i=1}^q\lambda_i g_i(\xx)+\sum_{j=1}^r\nu_j h_j(\xx).
$$
:::


Los vectores $\bflambda$ y $\bfnu$, cuyas componentes son multiplicadores de Lagrange, se denominan *variables duales* del problema de optimización y son el argumento de la función definida a continuación. A su vez, al problema de optimización original se lo denomina **problema primal**.


::: {.definicion}
**Definición 3.** (Función dual) Sea $\calL$ el Lagrangiano de la Definición 2. Se denomina *función dual de Lagrange* a $\calG:\RR^q\times\RR^r\to\RR$ definida por
$$
\calG(\bflambda,\bfmu)=\inf_{\xx}\calL(\xx,\bflambda,\bfnu).
$$

Cuando el Lagrangiano no está acotado inferiormente en $\xx$, se asume el valor $-\infty$.
:::

Dado que la función dual es el ínfimo puntual de una familia de funciones afínes de $(\bflambda,\bfnu)$, es cóncava, aún cuando el problema primal no sea convexo <span style="color: #800020;">[ver Ejercicio ...]</span>.

La propiedad más importante de la función dual es que es una cota inferior del valor óptimo $p^*$ del problema primal. Es decir, para todo $\bflambda\geq 0$ y cualquier $\bfnu$, resulta
$$
\calG(\bflambda,\bfnu)\leq p^*.
$$

<details>
<summary>Verificación</summary>
<hr>
Sea $\tilde{\xx}$ un punto factible del problema primal. Entonces $g_i(\tilde{\xx})\leq 0$ y $h_j(\tilde{\xx})=0$ para todo $i=1,\cdots,q$ y $j=1,\cdots,r$, respectivamente. Por lo tanto, para $\bflambda\geq 0$ se tiene que
$$
\sum_{i=1}^q\lambda_ig_i(\tilde{\xx})+\sum_{j=1}^r\nu_j h_j(\tilde{\xx})\geq 0.
$$

Sumando $f(\tilde{\xx})$ a ambos miembros, se obtiene $\calL(\xx,\bflambda,\bfnu)\leq f(\tilde{\xx})$. Luego, por propiedad del ínfimo, resulta 
$$
\calG(\bflambda,\bfnu)\leq f(\tilde{\xx}).
$$

Finalmente, dado que $\tilde{\xx}$ es cualquier punto factible, en particular la desigualdad anterior es cierta para un punto óptimo $\xx^*$ tal que $f(\xx^*)=p^*$.

<hr>
</details>


## El problema dual de Lagrange

Inmediatamente nos podemos preguntar: ¿cual es el valor máximo $d^*$ de $\calG(\bflambda,\bfnu)$ si asumimos $\bflambda\geq 0$? Esto da lugar al problema que definiremos a continuación. Observar que la desigualdad $\calG(\bflambda,\bfnu)\leq p^*$ implica
$$
d^*\leq p^*.
$$


::: {.definicion}
**Definición 3.** (Problema dual) Sea $\calG$ la función dual de Lagrange asociado al problema primal de la Definición 2. El *problema dual de Lagrange* es
$$
\max \calG(\bflambda,\bfnu)
$$
$$
\text{sujeto a }\; \bflambda\geq 0.
$$
:::

En línea con la notación anterior, denominaremos *multiplicadores óptimos* a un par $(\bflambda^*,\bfnu^*)$ que es solución del problema dual. Es decir, verifican $\calG(\bflambda^*,\bfnu^*)=d^*$.

El problema dual de Lagrange es un problema de optimización convexo, independientemente de que el problema primal sea convexo o no. Esto se debe a que la función a maximizar es cóncava y la restricción es un conjunto convexo.



## Suboptimalidad y criterio de parada

Los puntos factibles duales nos permiten acotar cuán subóptimo es un punto factible dado, sin conocer el valor exacto de $p^{*}$. De hecho, si $\xx$ es factible primal y $(\bflambda, \bfnu)$ es factible dual, entonces se cumple la siguiente desigualdad:
$$
f(\xx) - p^{*} \leq f(\xx)-\calG(\bflambda, \bfnu).
$$

En particular, esto establece que $\xx$ es $\epsilon$-subóptimo, con 
$$\epsilon = f(\xx) - g(\bflambda, \bfnu).
$$

La brecha $\epsilon$ se conoce como *brecha de dualidad* para los puntos factibles $\xx$ y $(\bflambda,\bfnu)$. Para dichos puntos, los valores óptimos de los problemas primal y dual verifican
$$
p^*,d^*\in\left[g(\bflambda,\bfnu), f(\xx)\right],
$$
donde el ancho del intervalo es justamente la brecha de dualidad. Observar que si $\epsilon=0$, entonces $\xx$ es óptimo primal y $(\bflambda,\bfnu)$ es óptimo dual.

El concepto de brecha de dualidad puede usarse en algoritmos de optimización para proporcionar criterios de parada no heurísticos. Supongamos que un algoritmo produce una secuencia de puntos factibles primales $\xx^{(k)}$ y puntos factibles duales $(\bflambda^{(k)}, \bfnu^{(k)})$, para $k = 1, 2, \ldots$, y sea $\epsilon_{\text{abs}} > 0$ una precisión absoluta requerida. Entonces, el criterio de parada
$$
f(\xx^{(k)}) - g(\bflambda^{(k)}, \bfnu^{(k)}) \leq \epsilon_{\text{abs}}
$$

**garantiza** que, cuando el algoritmo termina, $\xx^{(k)}$ es $\epsilon_{\text{abs}}$-subóptimo. Por supuesto, la dualidad fuerte debe cumplirse si se pretende que este método funcione para tolerancias $\epsilon_{\text{abs}}$ arbitrariamente pequeñas.


## Holgura complementaria

Supongamos que los valores óptimos primal y dual se alcanzan y son iguales. Esto es, se cumple la desigualdad fuerte $p^*=d^*$. Esto significa que para puntos óptimos $\xx^*$ y $(\bflambda^*,\bfnu^*)$ se verifica
$$
\begin{align*}
f(\xx^{*}) &= \calG(\bflambda^{*}, \bfnu^{*}) \\
&= \inf_{x} \left( f(\xx) + \sum_{i=1}^{q} \lambda_{i}^{*} g_{i}(x) + \sum_{j=1}^{r} \nu_{j}^{*} h_{j}(\xx) \right)\\
& \leq f(\xx^{*}) + \sum_{i=1}^{q} \lambda_{i}^{*} g_{i}(\xx^{*}) + \sum_{j=1}^{r} \nu_{j}^{*} h_{j}(\xx^{*}) \\&\leq f(\xx^{*}).
\end{align*}
$$

La justificación de cada uno los pasos es sencilla <span style="color: #800020;">[Ejercicio ...]</span>. Concluimos que las dos desigualdades en esta cadena se cumplen con igualdad. En particular, la última igualdad

$$
f(\xx^*)+ \sum_{i=1}^{q} \lambda_{i}^{*} g_{i}(\xx^{*}) + \sum_{j=1}^{r} \nu_{j}^{*} h_{j}(\xx^{*})=f(\xx^*)
$$

implica que 

$$
\sum_{i=1}^{q} \lambda_{i}^{*} g_{i}(\xx^{*}) = 0.
$$

Pero cada término en esta suma es no positivo, por lo tanto debe verificarse

$$
\boxed{\lambda_{i}^{*} g_{i}(\xx^{*}) = 0, \quad \forall i = 1, \ldots, q.}
$$

Esta es la *condición de holgura complementaria* que hemos visto en la sección anterior. Se cumple para cualquier punto óptimo primal $\xx^{*}$ y cualquier punto óptimo dual $(\bflambda^{*}, \bfnu^{*})$ bajo dualidad fuerte. Recordemos que, en términos generales, esta condición significa que el $i$-ésimo multiplicador de Lagrange óptimo es cero salvo que la $i$-ésima restricción esté activa. 



## Relación entre dualidad y KKT

Los conceptos de Lagrangiano y su función dual han permitido caracterizar la relación entre los valores óptimos $p^*$ y $d^*$. En particular, las condiciones de *factibilidad dual* y de *holgura complementaria* de la Definición 1 (Condiciones de Karush-Kuhn-Tucker) han permitido primero escribir la desigualdad $\calG(\bflambda,\bfmu)\leq p^*$ y luego analizar qué sucede cuando $p^*=q^*$.

Veamos ahora cómo surge la *estacionariedad* en este contexto. Podemos afirmar que

$$
f(\xx^*)\leq f(\xx)+\sum_{i=1}^{q} \lambda_{i}^{*} g_{i}(\xx) + \sum_{j=1}^{r} \nu_{j}^{*} h_{j}(\xx)
$$

para todo punto factible $\xx$, con igualdad si $\xx=\xx^*$. El lado derecho es el Lagrangiano $L(\xx,\bflambda^*,\bfnu^*)$, del cual podemos afirmar que $\xx$ es un minimizador. En consecuencia, debe verificarse

$$
\begin{align*}
  \nabla L(\xx^*,\bflambda^*,\bfnu^*)&=0\\
  \nabla f(\xx^*)+\sum_{i=1}^q\lambda_i^*\nabla g_i(\xx^*)+\sum_{j=1}^r\nu_j^*\nabla h_j(\xx^*)&=0.
\end{align*}
$$


::: {.teorema}
**Teorema 4.** (Dualidad y KKT) 
Sea $\xx^*$ un punto óptimo primal y $(\bflambda^*,\bfnu^*)$ un punto óptimo dual. Si $p^*=q^*$, entonces $(\xx^*,\bflambda^*,\bfnu^*)$ satisfacen las condiciones de Karush-Kuhn-Tucker.
:::





<br>
<hr style="border: 2.5px solid black;">

<h2>Ejercicios</h2>

1. Considere el problema
$$
\min x^2\quad\text{sujeto a}\quad 2-x\leq 0.
$$
Obtenga la función dual de Lagrange y verifique graficamente su convexidad. ¿Cuál es el valor de $d^*$?


1. Probar que la función dual de Lagrange $\calG(\bflambda,\bfmu)$ es cóncava.

1. Mostrar que, si $\xx$ es factible primal y $(\bflambda,\bfnu)$ es factible dual, entonces $(\bflambda,\bfnu)$ es $\epsilon$-subóptimo para el problema dual.