[
  {
    "objectID": "macros.html",
    "href": "macros.html",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "",
    "text": "\\[\n\\def\\RR{\\mathbb{R}}\n\\def\\media{\\mathbb{E}}\n\\def\\calL{\\mathcal{L}}\n\\def\\calG{\\mathcal{G}}\n\\def\\bb{{\\bf b}}\n\\def\\xx{{\\bf x}}\n\\def\\yy{{\\bf y}}\n\\def\\vv{{\\bf v}}\n\\def\\XX{{\\bf X}}\n\\def\\TT{{\\bf T}}\n\\def\\SS{{\\bf S}}\n\\def\\bfa{\\boldsymbol{a}}\n\\def\\bfb{\\boldsymbol{b}}\n\\def\\bftheta{\\boldsymbol{\\theta}}\n\\def\\bflambda{\\boldsymbol{\\lambda}}\n\\def\\bfeta{\\boldsymbol{\\eta}}\n\\def\\bfmu{\\boldsymbol{\\mu}}\n\\def\\bfnu{\\boldsymbol{\\nu}}\n\\def\\bfSigma{\\boldsymbol{\\Sigma}}\n\\def\\bfone{\\mathbf{1}}\n\\def\\argmin{\\mathop{\\mathrm{arg\\,min\\,}}}\n\\def\\argmax{\\mathop{\\mathrm{arg\\,max\\,}}}\n\\]"
  },
  {
    "objectID": "CAPITULO_1/A3_metodos_optimizacion.html",
    "href": "CAPITULO_1/A3_metodos_optimizacion.html",
    "title": "Métodos de optimización",
    "section": "",
    "text": "Comenzaremos explorando métodos de optimización de primer orden para problemas no lineales. En principio, consideraremos el caso sin restricciones \\[\n\\min_{\\xx\\in\\RR^n} f(\\xx),\n\\]\ncon \\(f\\) una función diferenciable. En este caso, ya hemos visto que \\(\\xx^*\\in\\RR^n\\) resuelve el problema de optimización solo si \\(\\nabla f(\\xx^*)=\\mathbf{0}\\). Más aún, cuando \\(f\\) es convexa, la condición es también suficiente.\nUna idea fundamental para construir un algoritmo de optimización es aproximar \\(f\\) con modelos más simples y manejables. En particular, los métodos de primer orden se basan en la aproximación de Taylor de primer orden, alrededor de un punto \\(\\xx_t\\), a saber: \\[\nf(\\xx) \\approx f(\\xx_{t}) + \\langle \\nabla f(\\xx_{t}), \\xx - \\xx_{t} \\rangle.\n\\]"
  },
  {
    "objectID": "CAPITULO_1/A3_metodos_optimizacion.html#condición-de-lipschitz-para-el-gradiente",
    "href": "CAPITULO_1/A3_metodos_optimizacion.html#condición-de-lipschitz-para-el-gradiente",
    "title": "Métodos de optimización",
    "section": "1.1 Condición de Lipschitz para el gradiente",
    "text": "1.1 Condición de Lipschitz para el gradiente\nEspecíficamente, requeriremos que el gradiente \\(\\nabla f(x)\\) sea \\(L\\)-Lipschitz continuo para alguna constante \\(L \\geq 0\\). Esta condición a menudo se llama \\(L\\)-suavidad en la literatura. La presentamos ahora para funciones generales con dominios convexos arbitrarios \\(\\Omega\\); hoy solo nos importará el caso \\(\\Omega = \\mathbb{R}^{n}\\).\n\nDefinición 1. (\\(L\\)-suavidad) Sea \\(\\Omega\\) un conjunto convexo. Una función diferenciable \\(f: \\Omega \\to \\RR\\) es \\(L\\)-suave si su gradiente es \\(L\\)-Lipschitz continuo. Es decir, se verifica \\[\n\\|\\nabla f(\\xx_1) - \\nabla f(\\xx_2)\\|_{2} \\leq L \\|\\xx_1 - \\xx_2\\|_{2}, \\qquad \\forall \\xx_1, \\xx_2 \\in \\Omega.\n\\]\n\nUna consecuencia inmediata de la \\(L\\)-suavidad es que la función admite una cota superior cuadrática. Esta propiedad será extremadamente útil en el análisis.\nTeorema 1.12.1 (Cota superior cuadrática). Sea \\(f: \\Omega \\to \\mathbb{R}\\) una función \\(L\\)-suave en un dominio convexo \\(\\Omega\\). Entonces, podemos acotar superiormente la función \\(f\\) como:\n\\[\nf(y) \\leq f(x) + \\langle \\nabla f(x), y - x \\rangle + \\frac{L}{2} \\|y - x\\|_{2}^{2} \\quad \\forall x, y \\in \\Omega. \\quad \\text{(2)}\n\\]\nDemostración. La idea es simple: expresamos el crecimiento \\(f(y) - f(x)\\) como la integral del gradiente en la línea que conecta \\(x\\) con \\(y\\), y luego usamos el límite de Lipschitz en el crecimiento del gradiente \\(\\nabla f\\) para acotar el crecimiento:\n\\[\\begin{align*}\nf(y) - f(x) &= \\int_{0}^{1} \\langle \\nabla f(x + t \\cdot (y - x)), y - x \\rangle \\, \\mathrm{d}t\\\\&\n= \\left( \\int_{0}^{1} \\langle \\nabla f(x + t \\cdot (y - x)) - \\nabla f(x), y - x \\rangle \\, \\mathrm{d}t \\right) + \\langle \\nabla f(x), y - x \\rangle\\\\\n&\n\\leq \\left( \\int_{0}^{1} \\|\\nabla f(x + t \\cdot (y - x)) - \\nabla f(x)\\|_{2} \\cdot \\|y - x\\|_{2} \\, \\mathrm{d}t \\right) + \\langle \\nabla f(x), y - x \\rangle\\\\\n&\n\\leq \\left( \\int_{0}^{1} t L \\|y - x\\|_{2}^{2} \\, \\mathrm{d}t \\right) + \\langle \\nabla f(x), y - x \\rangle\\\\\n&= \\frac{L}{2} \\|y - x\\|_{2}^{2} + \\langle \\nabla f(x), y - x \\rangle.\n\\end{align*}\\] Reordenando, obtenemos el enunciado. \\(\\blacksquare\\)\nTambién mencionamos la siguiente caracterización.\nTeorema 1.12.2. Para funciones dos veces diferenciables \\(f: \\Omega \\to \\mathbb{R}\\) definidas en un conjunto abierto \\(\\Omega \\subseteq \\mathbb{R}^{n}\\), una condición equivalente de \\(L\\)-suavidad es:\n\\[\n-L I \\preceq \\nabla^{2} f(x) \\preceq L I \\quad \\forall x \\in \\Omega,\n\\]\no equivalentemente,\n\\[\n|v^{\\top} \\nabla^{2} f(x) v| \\leq L \\quad \\forall x \\in \\Omega, v \\in \\mathbb{R}^{n}: \\|v\\|_{2} = 1.\n\\]"
  },
  {
    "objectID": "CAPITULO_1/A1_intro_optimizacion.html#definiciones-básicas",
    "href": "CAPITULO_1/A1_intro_optimizacion.html#definiciones-básicas",
    "title": "Introducción a la Optimización",
    "section": "1.1 Definiciones básicas",
    "text": "1.1 Definiciones básicas\nEn esta sección introduciremos tres tipos fundamentales de conjuntos que aparecen en optimización: conjuntos afines, conjuntos convexos y conos. Antes, es necesario recordar la forma parámetrica de rectas y segmentos de recta.\nSean \\(\\xx_{1} \\neq \\xx_{2}\\) dos puntos en \\(\\RR^{n}\\). La recta que pasa por \\(\\xx_1\\) y \\(\\xx_2\\) queda determinada por \\[\n\\yy = \\theta \\xx_{1} + (1 - \\theta) \\xx_{2},\\qquad \\theta\\in\\RR.\n\\]\nMientras que, si restringimos el valor del parámetro a \\(0\\leq \\theta\\leq 1\\), obtenemos el segmento de recta (cerrado) entre ambos puntos. Una expresión alternativa es\n\\[\n\\yy=\\xx_2+\\theta(\\xx_1-\\xx_2),\n\\]\nla cual permite interpretar a \\(\\yy\\) en términos del punto inicial \\(\\xx_2\\) y la dirección \\(\\xx_1-\\xx_2\\). Así, \\(\\theta\\) indica la fracción del camino desde \\(\\xx_2\\) hasta \\(\\xx_1\\) donde se encuentra \\(\\yy\\).\n\n\n\nRecta que pasa por dos puntos.\n\n\n\n\n1.1.1 Conjuntos afines\n\nDefinición 1. (Conjunto afín) Un conjunto \\(C \\subseteq \\RR^{n}\\) es afín si la línea que pasa por cualquier par de puntos distintos en \\(C\\) está contenida en \\(C\\). Es decir, si se verifica \\[\n\\theta \\xx_1+(1-\\theta)\\xx_2\\in C\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall\\theta\\in\\RR.\n\\]\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nLa expresión \\(\\theta \\xx_1+(1-\\theta)\\xx_2\\) es una combinación lineal entre los puntos \\(\\xx_1\\) y \\(\\xx_2\\) que verifica que la suma de sus coeficientes sea uno. Esta idea se puede generalizar a más de dos puntos: un punto de la forma \\[\n\\theta_1\\xx_1+\\cdots+\\theta_k\\xx_k,\\qquad \\sum_{i=1}^k\\theta_i=1\n\\] se denomina combinación afín de los puntos \\(\\xx_1,\\ldots,\\xx_k\\). Es fácil ver que un conjunto afín \\(C\\) contiene todas las combinaciones afines de sus puntos.\nDado un conjunto afín \\(C\\) y un punto \\(\\xx_0\\in C\\), el conjunto \\[\nV:= C-\\xx_0=\\{\\xx-\\xx_0 \\mid \\xx\\in C\\}\n\\] es un subespacio vectorial, que permite expresar el conjunto afín \\(C\\) como \\[\nC=V+\\xx_0=\\{v+\\xx_0 \\mid v\\in V\\}.\n\\] El subespacio \\(V\\) asociado con el conjunto afín \\(C\\) no depende de la elección de \\(x_{0}\\), por lo que \\(x_{0}\\) puede elegirse como cualquier punto en \\(C\\). Definimos la dimensión de \\(C\\) como \\[\n\\dim C:=\\dim V=\\dim C-\\xx_0,\\quad \\xx_0\\in C.\n\\]\n\n\n\n\n\n\n\n1.1.2 Conjuntos convexos\n\nDefinición 1. (Conjunto convexo) Un conjunto \\(C \\subseteq \\RR^{n}\\) es convexo si el segmento de línea entre cualquier par de puntos distintos en \\(C\\) está contenido en \\(C\\). Es decir, si se verifica \\[\n\\theta \\xx_1+(1-\\theta)\\xx_2\\in C\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall\\theta\\in[0,1].\n\\]\n\nClaramente, todo conjunto afín también es convexo, ya que contiene toda la recta que pasa por cualquier par de puntos distintos en él y, por lo tanto, también el segmento de línea entre los puntos.\n\n\n\nConjuntos en \\(\\RR^2\\). Únicamente el hexágono, que incluye su frontera, es convexo.\n\n\n\nLlamamos combinación convexa a un punto de la forma \\[\n\\theta_{1} \\xx_{1} + \\cdots + \\theta_{k} \\xx_{k},\\qquad \\sum_{i=1}^k\\theta_i = 1, \\theta_{i} \\geq 0.\n\\]\nA diferencia de una combinación afín, una combinación convexa requiere la no negatividad de los coeficientes \\(\\theta_i\\), lo cual significa que puede ser interpretada como un promedio ponderado de los puntos \\(\\xx_i\\).\n\nDefinición 1. (Envolvente convexa) La envolvente convexa de un conjunto \\(C\\) es el conjunto de todas las combinaciones convexas de puntos en \\(C\\). Esto es \\[\n\\text{conv}\\, C = \\left\\{\\theta_{1} x_{1} + \\cdots + \\theta_{k} x_{k}\\;\\Big|\\; x_{i} \\in C, \\theta_{i} \\geq 0, \\sum_{i=1}^k\\theta_{i} = 1\\right\\}.\n\\]\n\nComo su nombre lo indica, la envolvente convexa \\(\\text{conv}\\, C\\) es siempre un conjunto convexo. Más aún, es el conjunto convexo más pequeño que contiene a \\(C\\): si \\(B\\) es cualquier conjunto convexo que contiene a \\(C\\), entonces \\(\\text{conv}\\, C \\subseteq B\\).\n\n\n\nEnvolvente convexa de dos conjuntos: (Izq.) La envolvente convexa de un numero finito de puntos. (Der.) La envolvente convexa de un conjunto infinito no convexo.\n\n\n\n\n\n1.1.3 Conos\n\nDefinición 1. (Cono) Un conjunto \\(C\\in\\RR^n\\) se denomina cono si verifica \\[\n\\theta\\xx\\in C,\\qquad\\forall \\xx\\in C, \\forall \\theta\\geq 0.\n\\]\n\nUn conjunto \\(C\\) es un cono convexo si es convexo y es un cono, lo que significa que \\[\n\\theta_1\\xx_1+\\theta_2\\xx_2\\in C,\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall \\theta_1, \\theta_2\\geq 0.\n\\]\n\n\n\nConjunto de puntos de la forma \\(\\theta_1\\xx_1+\\theta_2\\xx_2\\) para \\(\\xx_1,\\xx_2\\in\\RR^2\\).\n\n\n\nLlamamos combinación cónica a un punto de la forma \\[\n\\theta_1\\xx_1+\\cdot+\\theta_k\\xx_j,\\qquad \\theta_i\\geq 0.\n\\]\n\nDefinición 1. (Envolvente cónica) La envolvente cónica de un conjunto \\(C\\) es el conjunto de todas las combinaciones cónicas de puntos en \\(C\\). Esto es \\[\n\\text{cone}\\, C = \\left\\{\\theta_{1} \\xx_{1} + \\cdots + \\theta_{k} \\xx_{k}\\;\\Big|\\; x_{i} \\in C, \\theta_{i} \\geq 0\\right\\}.\n\\]\n\nDe manera análoga a la envolvente convexa, la envolvente cónica de un conjunto \\(C\\) es el conjunto de todas las combinación cónicas de puntos en \\(C\\) y, además, es el cono convexo más pequeño que contiene a \\(C\\).\n\n\n\nEnvolvente cónica de dos conjuntos: (Izq.) La envolvente convexa de un numero finito de puntos. (Der.) La envolvente convexa de un conjunto infinito no convexo."
  },
  {
    "objectID": "CAPITULO_1/A1_intro_optimizacion.html#operaciones-que-preservan-convexidad",
    "href": "CAPITULO_1/A1_intro_optimizacion.html#operaciones-que-preservan-convexidad",
    "title": "Introducción a la Optimización",
    "section": "1.2 Operaciones que preservan convexidad",
    "text": "1.2 Operaciones que preservan convexidad\nEn esta sección describimos algunas operaciones que preservan la convexidad de conjuntos o nos permiten construir conjuntos convexos a partir de otros. Estas operaciones, junto con los ejemplos simples descritos anteriormente, forman un cálculo de conjuntos convexos que es útil para determinar o establecer la convexidad de conjuntos. Las verificaciones se dejan como ejercicio.\n\nIntersección. Si \\(S_{1}\\) y \\(S_{2}\\) son convexos, entonces \\(S_{1} \\cap S_{2}\\) es convexo. Esta propiedad se extiende a la intersección de un número infinito de conjuntos: si \\(S_{\\alpha}\\) es convexo para cada \\(\\alpha \\in \\mathcal{A}\\), entonces \\(\\bigcap_{\\alpha \\in \\mathcal{A}} S_{\\alpha}\\) es convexo. Como ejemplo simple, un poliedro es la intersección de semiespacios e hiperplanos (que son convexos), y por lo tanto es convexo.\nFunciones afínes. Si \\(S\\subset \\RR^{n}\\) es convexo y \\(f: \\mathbf{R}^{n} \\to \\mathbf{R}^{m}\\) es una función afín, entonces, la imagen de \\(S\\) bajo \\(f\\), \\(f(S) := \\{f(\\xx) \\mid \\xx \\in S\\}\\), es convexa. De manera similar, si \\(f: \\RR^{k} \\to \\RR^{n}\\) es una función afín, la imagen inversa de \\(S\\) bajo \\(f\\), \\(f^{-1}(S) := \\{\\xx \\mid f(\\xx) \\in S\\}\\), es convexa.\n\n\n\\(f:\\RR^n\\to\\RR^m\\) es afín si es de la forma \\(f(\\xx)=A\\xx+\\bb\\), con \\(A\\in\\RR^{n\\times m}\\) y \\(\\bb\\in\\RR^m\\).\n\n\nSuma. Si \\(S_1\\) y \\(S_2\\) son conjuntos convexos de \\(\\RR^n\\), entonces \\[\nS_{1} + S_{2} := \\{\\xx_1 + \\xx_2 \\mid \\xx \\in S_{1}, \\xx_2 \\in S_{2}\\}\n\\] es un conjunto convexo."
  },
  {
    "objectID": "CAPITULO_1/A1_intro_optimizacion.html#condiciones-de-convexidad",
    "href": "CAPITULO_1/A1_intro_optimizacion.html#condiciones-de-convexidad",
    "title": "Introducción a la Optimización",
    "section": "2.1 Condiciones de convexidad",
    "text": "2.1 Condiciones de convexidad\nPara verificar si una función es convexa, además de recurrir a la definición, existen criterios basados en sus derivadas. Estos permiten caracterizar la convexidad en términos del comportamiento local de la función, ya sea a través del gradiente (primera derivada) o de la matriz hessiana (segunda derivada). Para ello, debemos imponer condiciones a \\(f\\) en relación con su diferenciabilidad.\nImportante Diremos que \\(f\\) es diferenciable si su gradiente \\(\\nabla f\\) existe en todo su dominio, y que es dos veces diferenciable si además su hessiana \\(\\nabla^2 f\\) existe en todo el dominio. En ambos casos, asumimos que dicho dominio es un conjunto abierto.\n\nTeorema 1. (Condición de primer orden para convexidad) Sea \\(f:\\RR^n\\to\\RR\\) una función diferenciable. \\(f\\) es convexa si y solo si \\(\\text{dom}\\,f\\) es convexo y \\[\nf(\\xx_2)\\geq f(\\xx_1)+\\langle\\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle,\\qquad\\forall\\xx_1,\\xx_2\\in\\text{dom}\\,f.\n\\]\n\n\n\nMostrar detalles\n\n\nInterpretación geométricaObservacionesDemostración\n\n\nLa función afín de \\(\\xx_2\\), definida por \\(f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\\), es la aproximación lineal de \\(f\\) cerca de \\(\\xx_1\\). En consecuencia, la desigualdad del teorema implica que la aproximación lineal de \\(f\\) en \\(\\xx_1\\) es un subestimador global de \\(f\\).\n\n\n\nGrafo de una función convexa \\(f\\) y su aproximación lineal.\n\n\n\n\n\nObservar que, si \\(\\nabla f(\\xx_1) = 0\\), entonces la desigualdad del teorema implica \\(f(\\xx_2) \\geq f(\\xx_1)\\) para todo \\(\\xx_2 \\in \\text{dom} f\\). Es decir, en tal caso \\(\\xx_1\\) es un minimizador global de la función \\(f\\).\nLa convexidad estricta también puede caracterizarse por una condición de primer orden: \\(f\\) es estrictamente convexa si y solo si \\(\\text{dom} f\\) es convexo y \\[\nf(\\xx_2) &gt; f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\n\\] para todo \\(\\xx_1, \\xx_2 \\in \\text{dom} f\\), con \\(\\xx_1 \\neq \\xx_2\\).\nPara funciones cóncavas, tenemos la caracterización correspondiente: \\(f\\) es cóncava si y solo si \\(\\text{dom} f\\) es convexo y \\[\nf(\\xx_2) \\leq f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\n\\] para todo \\(\\xx_1, \\xx_2 \\in \\text{dom} f\\).\n\n\n\nSupongamos que \\(f\\) es convexa y sean \\(\\xx_1,\\xx_2\\in\\text{dom}\\,f\\). Entonces, por definición, \\(\\text{dom}\\,f\\) es convexo; en consecuencia \\(\\xx_1+t(\\xx_2-\\xx_1)\\in\\text{dom}\\,f\\) para todo \\(0&lt;t\\leq 1\\). La convexidad de \\(f\\) nos permite escribir\n\\[\nf(\\xx_1+t(\\xx_2-\\xx_1))=f((1-t)\\xx_1+t\\xx_2)\\leq (1-t)f(\\xx_1)+tf(\\xx_2).\n\\]\nDiviendo ambos lados de la desigualdad por \\(t\\), resulta\n\\[\nf(\\xx_2)\\geq f(\\xx_1)+\\frac{f(\\xx_1+t(\\xx_2-\\xx_1))-f(\\xx_1)}{t}.\n\\]\nAl tomar límite cuando \\(t\\to 0\\), el cociente incremental del lado derecho es la derivada direccional de \\(f\\) en \\(\\xx_1\\) en la dirección del vector \\(\\xx_2-\\xx_1\\), lo cual es equivalente a \\(\\langle \\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle\\) en virtud de la diferenciabilidad de \\(f\\). Luego,\n\\[\nf(\\xx_2)\\geq f(\\xx_1)+\\langle\\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle.\n\\]\nPara probar la suficiencia, vamos a asumir que sí se cumple para funciones de una variable (se deja como ejercicio). Sean \\(\\xx_1,\\xx_2\\in\\text{dom}\\,f\\) y \\(t,\\tilde{t}\\in(0,1]\\). Partimos de la desigualdad\n\\[\nf(t\\xx_2+(1-t)\\xx_1)\\geq f(\\tilde{t}\\xx_2+(1-\\tilde{t})\\xx_1)+\\langle \\nabla f(\\tilde{t}\\xx_2+(1-\\tilde{t})\\xx_1),(\\xx_2-\\xx_1)\\rangle (t-\\tilde{t}).\n\\]\nSi restringimos \\(f\\) a la recta entre \\(\\xx_1\\) y \\(\\xx_2\\), tenemos la función de una variable \\(g(t)=f(t\\xx_2+(1-t)\\xx_1)\\). Por regla de la cadena, tenemos \\(g'(t)\\langle \\nabla f(t\\xx_2+(1-t)\\xx_1),\\xx_2-\\xx_1\\rangle\\). En consecuencia, la desigualdad anterior puede reescribirse como\n\\[\ng(t)\\geq g(\\tilde{t})+g'(\\tilde{t})(t-\\tilde{t}).\n\\]\nLuego, \\(g\\) es convexa y, dado que la restricción sobre una recta es arbitraria (ver observaciones de la definición de funciones convexas), \\(f\\) es convexa. \\(\\blacksquare\\)\n\n\n\n\n\nTeorema 2. (Condición de segundo orden para convexidad) Sea \\(f:\\RR^n\\to\\RR\\) una función dos veces diferenciable. \\(f\\) es convexa si y solo si \\(\\text{dom}\\,f\\) es convexo y \\[\n\\nabla^2 f(\\xx)\\succeq 0,\\qquad\\forall\\xx\\in\\text{dom}\\,f.\n\\]\n\n\n\\(A\\succeq 0\\) significa que \\(A\\) es semidefinida positiva. Esto es, \\(\\xx^T A\\xx\\geq 0\\) para todo \\(\\xx\\in\\RR^n\\).\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nPara funciones de una variable, la condición se reduce a \\(f''(x)\\geq 0\\), lo cual implica que la derivada \\(f'(x)\\) es no decreciente.\nLa convexidad estricta también puede caracterizarse por una condición de primer orden, pero de manera parcial: si \\(\\text{dom}\\,f\\) es convexo y \\(\\nabla^2 f\\succ 0\\) para todo \\(\\xx\\in\\text{dom}\\,f\\), entonces \\(f\\) es estrictamente convexa. El recíproco no es cierto: por ejemplo, \\(f(x)=x^4\\) es estrictamente convexa pero \\(f''(0)=0\\).\nPara funciones cóncavas, tenemos la caracterización correspondiente: \\(f\\) es cóncava si y solo si \\(\\text{dom} f\\) es convexo y \\(\\nabla^2 f(\\xx)\\preceq 0\\) para todo \\(\\xx\\in\\text{dom}\\,f\\).\n\n\n\n\n\n\nEjemplo 1 Consideremos la función cuadrática \\(f:\\RR^n\\to\\RR\\) definida por\n\\[\nf(\\xx)=\\frac{1}{2}\\xx^TA\\xx+\\bb^T\\xx+c,\n\\]\ndonde \\(A\\in\\SS^n:=\\{X\\in\\RR^{n\\times n} \\mid X=X^T\\}\\), \\(\\bb\\in\\RR^n\\) y \\(c\\in\\RR\\). Dado que \\(\\nabla^2 f(\\xx)=A\\) para todo \\(\\xx\\), podemos afirmar que \\(f\\) es convexa si y sólo si \\(A\\succeq 0\\).\nAsí, por ejemplo, la función \\(f:\\RR^2\\to\\RR\\) definida por\n\\[\nf(x,y)=\\frac{1}{2}\\begin{pmatrix}x&y\\end{pmatrix}\\begin{pmatrix}2&1\\\\1&3\\end{pmatrix}\\begin{pmatrix}x\\\\ y\\end{pmatrix}=\\frac{1}{2}(2x^2+2xy+3y^2)\n\\]\nes convexa, ya que \\(\\xx^TA\\xx=2x^2+2xy+3y^2=x^2+(x+y)^2+2y^2\\geq 0\\) para todo \\(\\xx\\in\\RR^n\\), lo cual significa que \\(A\\succeq 0\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D  # para 3D\n\n# Definir la matriz A (simétrica)\nA = np.array([[2, 1],\n              [1, 3]])\n\n# Crear una malla de puntos en R^2\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\n\n# Evaluar la función f(x) = 1/2 x^T A x\nZ = 0.5 * (A[0,0]*X**2 + (A[0,1] + A[1,0])*X*Y + A[1,1]*Y**2)\n\n# Graficar\nfig = plt.figure(figsize=(8,6))\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()"
  },
  {
    "objectID": "CAPITULO_1/A1_intro_optimizacion.html#operaciones-que-preservan-convexidad-1",
    "href": "CAPITULO_1/A1_intro_optimizacion.html#operaciones-que-preservan-convexidad-1",
    "title": "Introducción a la Optimización",
    "section": "2.2 Operaciones que preservan convexidad",
    "text": "2.2 Operaciones que preservan convexidad\nEn esta sección describimos algunas operaciones que preservan la convexidad o concavidad de funciones, o que permiten construir nuevas funciones convexas y cóncavas. Las verificaciones se dejan como ejercicio.\n\nSumas ponderadas no negativas. Si \\(f\\) es una función convexa y \\(\\alpha \\geq 0\\), entonces la función \\(\\alpha f\\) es convexa. Si \\(f_1\\) y \\(f_2\\) son ambas funciones convexas, entonces su suma \\(f_1 + f_2\\) también lo es. Combinando estas dos propiedades, se obtiene que el conjunto de funciones convexas es en sí mismo un cono convexo: una suma ponderada no negativa de funciones convexas, \\[\nf = w_1 f_1 + \\cdots + w_m f_m,\n\\] es convexa. De manera similar, una suma ponderada no negativa de funciones cóncavas es cóncava.\nComposición con una aplicación afín. Sean \\(f:\\RR^n\\to\\RR\\), \\(A\\in\\RR^{n\\times m}\\) y \\(\\bb\\in\\RR^n\\). Definimos \\(g:\\RR^m\\to\\RR\\) como \\[\ng(\\xx):=f(A\\xx+\\bb)\n\\] con \\(\\text{dom}\\,g = \\{\\xx \\mid A\\xx + \\bb \\in \\text{dom}\\, f\\}\\). Entonces, \\(g\\) conserva la convexidad o concavidad de \\(f\\).\nMáximo puntual. Si \\(f_1\\) y \\(f_2\\) son funciones convexas, entonces su máximo puntual \\(f\\), definido por \\[\nf(\\xx) = \\max\\{f_1(\\xx), f_2(\\xx)\\},\n\\] con \\(\\text{dom}\\,f = \\text{dom}\\,f_1 \\cap \\text{dom}\\,f_2\\), también es convexa. Además, este resultado se puede extender a: si \\(f_1,\\dots,f_m\\) son funciones convexas, entonces su máximo puntual, definido por \\(f(\\xx)=\\max\\{f_1(\\xx), \\ldots, f_m(\\xx)\\}\\), también lo es.\nSupremo puntual. La propiedad del máximo puntual se extiende al supremo puntual sobre un conjunto infinito de funciones convexas. Si para $i, donde \\(\\mathcal{A}\\) es un conjunto de índices, se tiene que \\(f_i(\\xx)\\) es convexa, entonces la función \\(f\\) definida por \\[\nf(\\xx) = \\sup_{i \\in \\mathcal{A}} f_i(\\xx)\n\\] también es convexa en \\(\\xx\\). Aquí, el dominio de \\(f\\) es \\[\n\\text{dom}\\, f = \\{\\xx \\mid \\xx \\in \\text{dom}\\, f_i \\text{ para todo } i \\in \\mathcal{A}, \\sup_{i \\in \\mathcal{A}} f_i(\\xx) &lt; \\infty\\}.\n\\] De manera similar, el ínfimo puntual de un conjunto de funciones cóncavas es una función cóncava."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html",
    "href": "CAPITULO_1/A2_optimalidad.html",
    "title": "Condiciones de optimalidad",
    "section": "",
    "text": "En un problema de optimización general \\[\n\\min_{x} f(x)\n\\] \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\ng_i(x)\\leq 0,& i=1,\\cdots,r.\\\\\nh_j(x)=0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\nlas condiciones de optimalidad definen los requisitos que deben cumplir los puntos óptimos. En lo que sigue, asumiremos que trabajamos con funciones diferenciables."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#optimización-sin-restricciones",
    "href": "CAPITULO_1/A2_optimalidad.html#optimización-sin-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "1.1 Optimización sin restricciones",
    "text": "1.1 Optimización sin restricciones\nDe cursos anteriores recordemos que, cuando se pretende optimizar una función \\(f\\) respecto a \\(x\\in\\RR^n\\), una condición necesaria para que un punto sea óptimo es que verifique \\[\n\\nabla f(x)=\\mathbf{0}.\n\\]\nPero cuidado: es solo una condición necesaria que todos los puntos óptimos deben cumplir, pero no implica que cualquier punto que la satisfaga sea automáticamente óptimo. En otras palabras, las soluciones de \\(\\nabla f(x) = 0\\) forman una lista de puntos candidatos para minimizar, llamados puntos críticos.\nDe inmediato surgen dos preguntas claves:\n\n¿Cuál es la generalización correcta de la condición necesaria \\(\\nabla f(x) = 0\\) cuando enfrentamos un problema de optimización con restricciones?\n¿Bajo qué circunstancias \\(\\nabla f(x) = 0\\) también se convierte en una condición suficiente para la optimalidad?\n\nAntes, veamos cómo surge la condición \\(\\nabla f(x)=\\mathbf{0}\\) para problemas de optimización sin restricciones.\n\n1.1.1 Prueba de condición necesaria \\(\\nabla f(x)=\\mathbf{0}\\)\nSea \\(x\\in\\RR^n\\) es un minimizador de la función \\(f: \\RR^n \\to \\RR\\) y sea \\(d\\in\\RR^n\\) una dirección arbitraria. Entonces se cumple\n\\[\nf(x + t \\cdot d) \\geq f(x) \\quad \\text{para todo } t \\geq 0.\n\\]\nEn consecuencia, la derivada direccional de \\(f\\) en \\(x\\) a lo largo de \\(d\\) es\n\\[\n\\frac{\\partial f}{\\partial d}(x)= \\lim_{t \\to 0} \\frac{f(x + t \\cdot d) - f(x)}{t} \\geq 0.\n\\]\nAhora bien, como \\(f\\) es diferenciable, se verifica la propiedad \\(\\frac{\\partial f}{\\partial d}(x)=\\langle \\nabla f(x),d\\rangle\\), por lo que la desigualdad anterior se puede reescribir como:\n\\[\n\\langle \\nabla f(x), d \\rangle \\geq 0 \\quad \\forall d \\in {R}^n.\n\\]\nEn particular, eligiendo \\(d = -\\nabla f(x)\\), resulta \\(-\\|\\nabla f(x)\\|^2\\geq 0\\), lo cual es cierto si y sólo si \\(\\nabla f(x)=\\mathbf{0}\\)."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#optimización-con-restricciones",
    "href": "CAPITULO_1/A2_optimalidad.html#optimización-con-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "1.2 Optimización con restricciones",
    "text": "1.2 Optimización con restricciones\nLa clave para generalizar la condición \\(\\nabla f(x)=\\mathbf{0}\\) al caso de optimización con restricciones surge de la prueba anterior, más precisamente de la desigualdad \\(\\langle\\nabla f(x),d\\rangle\\geq 0\\).\nLa diferencia principal con el caso sin restricciones es que, en un conjunto restringido, podríamos estar limitados en la elección de las direcciones \\(d\\) a lo largo de las cuales podemos aproximarnos a \\(x\\) sin salirnos del conjunto.\nNo obstante, para cualquier dirección \\(d\\) tal que \\(x + t \\cdot d \\in \\Omega\\) para todo \\(t \\geq 0\\) suficientemente pequeño, el mismo argumento aplicado anteriormente sigue siendo válido. Por lo tanto, podemos concluir que necesariamente:\n\\[\n\\langle \\nabla f(x), d \\rangle \\geq 0 \\quad \\text{para todo } d \\in  {R}^n \\text{ que permanezca en } \\Omega \\text{ desde } x.\n\\]\nPara aplicar esta condición, se requieren dos pasos:\n\nDeterminar el conjunto de direcciones \\(d\\) que permanecen en \\(\\Omega\\) desde \\(x\\)*.\nA partir de esas direcciones, ver de qué manera imponen restricciones sobre \\(\\nabla f(x)\\).\n\nDe estos dos pasos, el primero suele ser el más sencillo. En todos los casos de interés, podemos determinar el conjunto de direcciones permitidas simplemente considerando cualquier otro punto \\(y \\in \\Omega\\) y observando la dirección de \\(x\\) a \\(y\\). Esta propiedad se cumple trivialmente si todos los segmentos de línea entre \\(x\\) y cualquier punto en \\(\\Omega\\) están contenidos en \\(\\Omega\\), lo cual es siempre cierto para conjuntos convexos.\n\nTeorema 1. (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo) Sea \\(\\Omega \\subseteq  {R}^n\\) convexo y sea \\(f:  {R}^n \\to  {R}\\) una función diferenciable. Si \\(x \\in \\Omega\\) es un minimizador de \\(f\\) sobre \\(\\Omega\\), entonces \\[\n\\langle \\nabla f(x), y - x \\rangle \\geq 0 \\quad \\forall y \\in \\Omega.\n\\]\n\n\n\nInterpretación geométrica\n\n\nLa condición del Teorema 1 se verifica si el vector gradiente de \\(f\\) en una solución \\(x\\in\\Omega\\) forma un ángulo agudo con todas las direcciones \\(y-x\\), donde \\(y\\in\\Omega\\).\nAhora bien, a la hora de buscar un minimizador, la dirección que realmente nos importa es \\(-\\nabla f(x)\\). Así, el Teorema 1 nos dice que \\(-\\nabla f(x)\\) debe formar un ángulo obtuso con las direcciones \\(y-x\\). En otras palabras, la condición dada es equivalente a escribir\n\\[\n-\\nabla f(x)\\in N_{\\Omega}(x),\n\\]\ndonde \\(N_{\\Omega}(x)\\) es el cono normal a \\(\\Omega\\) en \\(x\\).\nEs importante observar que si \\(x\\) es un punto interior de \\(\\Omega\\), sabemos que \\(N_{\\Omega}(x)=\\{\\mathbf{0}\\}\\) y, en consecuencia, debe ser \\(\\nabla f(x)=\\mathbf{0}\\). Esto es consistente con la condición de optimalidad de los problemas sin restricciones.\nNo obstante, la importancia del Teorema 1 radica en cómo tratar los puntos en la frontera de \\(\\Omega\\). A partir de los ejemplos previamente estudiados sobre el cono normal, podemos ver que la interpretación del Teorema 1 es bastante intuitiva. Por ejemplo, si \\(\\Omega\\) es un polígono y \\(x\\in\\Omega\\) es una solución, el vector \\(-\\nabla f(x)\\) es perpendicular a \\(\\Omega\\) y apunta hacia afuera, lo cual significa que no hay posibilidad de “moverse” en dirección opuesta al gradiente sin salirse de \\(\\Omega\\).\n\n\n¡Cuidado! La condición provista por el Teorema 1 es necesaria pero no suficiente. Podría verificarse la condición en otros puntos críticos de \\(\\Omega\\) que no sean un mínimo global de \\(f\\) en dicho conjunto. Sin embargo, para el notable caso de las funciones convexas dicha condición sí es suficiente.\n\nTeorema 2. (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo y una función objetivo convexa) Sea \\(\\Omega \\subseteq  {R}^n\\) convexo y sea \\(f:  {R}^n \\to  {R}\\) una función diferenciable convexa. Entonces \\[\n-\\nabla f(x)\\in N_{\\Omega}(x)\\Leftrightarrow x \\text{ es un minimizador de }f\\text{ en }\\Omega.\n\\]"
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#el-caso-particular-de-restricciones-lineales",
    "href": "CAPITULO_1/A2_optimalidad.html#el-caso-particular-de-restricciones-lineales",
    "title": "Condiciones de optimalidad",
    "section": "2.1 El caso particular de restricciones lineales",
    "text": "2.1 El caso particular de restricciones lineales\nVamos a considerar el caso en que \\(\\Omega\\) un polítopo convexo, esto es, el conjunto convexo definido por la intersección de un número finito de medios espacios (desigualdades lineales):\n\\[\n\\Omega=\\{\\xx\\in\\RR^n|A\\xx\\leq \\bfb\\},\n\\]\ndonde \\(A\\in\\RR^{m\\times n}\\) es una matriz, cuyas filas denotaremos con \\(\\bfa_j\\), \\(j=1,\\cdots,m\\), y \\(\\bfb\\in\\RR^m\\).\nEn el ejemplo … (Agregar ejemplo 3.6 de Lecture 2 a ‘Intro’) hemos visto que el cono normal en un punto en la intersección de dos medios espacios es la envolvente cónica de las direcciones ortogonales a dichos subespacios.\n\n\n\nEnvolvente cónica de la intersección de dos subespacios \\(\\bfa_1^T\\xx\\leq b_1\\) y \\(\\bfa_2^T\\xx\\leq b_2\\).\n\n\nPor otra parte, los otros casos también ya han sido vistos:\n\nSi \\(\\xx\\) pertenece al interior de \\(\\Omega\\), entonces \\(N_{\\Omega}(\\xx)=\\{\\mathbf{0}\\}\\).\nSi \\(\\xx\\) pertenece a la frontera de un único medio espacio, a saber \\(\\bfa_k^T\\xx=b_k\\), entonces \\(N_{\\Omega}(\\xx)=\\{\\lambda \\bfa_k:\\lambda\\geq 0\\}\\).\n\nLa generalización al caso de \\(m\\) medios espacios se presenta en el siguiente teorema.\n\nTeorema 3. Sea \\(\\Omega=\\{x\\in\\RR^n\\}\\) la intersección de \\(m\\) medios espacios \\(\\bfa_j^T\\xx\\leq b_j\\). Dado un punto \\(x\\in\\Omega\\), se define el conjunto de índices de las restricciones activas mediante\n\\[\nI(\\xx):=\\left\\{j\\in\\{1,\\cdots,m\\}:\\bfa_j^T\\xx=b_j\\right\\}.\n\\] Entonces, el cono normal en \\(\\xx\\) está dado por\n\\[\nN_{\\Omega}(\\xx)=\\left\\{\\sum_{j\\in I(\\xx)}\\lambda_j\\bfa_j:\\lambda_j\\geq 0\\right\\}.\n\\]\n\n\n\nInterpretación\n\n\nSi \\(\\xx\\) pertenece al interior de \\(\\Omega\\), entonces no hay restricciones activas. Esto se corresponde con el hecho de que el cono normal es \\(N_{\\Omega}(\\xx)=\\{\\mathbf{0}\\}\\).\nPor su parte, si \\(\\xx\\) pertenece a la frontera de \\(\\Omega\\), entonces el cono normal es la envolvente cónica de las direcciones ortogonales a las restricciones activas.\nObservar que la condición de optimalidad \\(-\\nabla f(\\xx)\\in N_{\\Omega}(\\xx)\\) se traduce como\n\\[\n-\\nabla f(\\xx)=\\sum_{j\\in I(\\xx)}\\lambda_j\\bfa_j,\n\\]\ny, en consecuencia, se puede escribir\n\\[\n\\nabla f(\\xx)-\\sum_{j\\in I(\\xx)}\\lambda_j \\nabla g_j(\\xx)=0,\n\\]\ncon \\(g_j(\\xx)=\\bfa_j^T\\xx-b\\). Los coeficientes \\(\\lambda_j\\) se denominan tipicamente multiplicadores de Lagrange.\n\n\nLa suma en la expresión del cono normal puede ser reescrita sin restringir \\(j\\in I(\\xx)\\), simplemente imponiendo \\(\\lambda_j=0\\) para todo \\(j\\notin I(\\xx)\\). Esta imposición queda ímplicita de forma inmediata si se escribe\n\\[\n\\sum_{j=1}^m\\lambda_j\\left(\\bfa_j^T\\xx-b_j\\right)=0.\n\\]\nEn forma vectorial, esto es \\(\\bflambda^T\\left(A\\xx-\\bfb\\right)=0\\), donde \\(\\bflambda=(\\lambda_1,\\cdots,\\lambda_m)^T\\). Con esta notación, el resultado del Teorema 3 puede reescribirse como\n\\[\nN_{\\Omega}(\\xx)=\\left\\{A^T\\bflambda:\\bflambda^T(A\\xx-\\bfb)=0,\\bflambda\\in\\RR^m_{\\geq 0}\\right\\}.\n\\]\nPara concluir este análisis, y teniendo en cuenta lo expuesto hasta aquí, podemos hacer énfasis en tres condiciones necesarias para que una solución sea óptima en este caso particular de restricciones lineales.\n\nPara que \\(\\xx\\in\\Omega\\) sea un minimizador de \\(f\\) sobre \\(\\Omega\\), debe cumplir:\n\nEstacionariedad: El gradiente debe ser una combinación lineal de los gradientes de las restricciones activas. \\[\n\\nabla f(\\xx)-\\sum_{j=1}^{m}\\lambda_j(\\bfa_j^T\\xx-b_j).\n\\]\nFactibilidad dual: Los multiplicadores de Lagrange asociados a las restricciones de desigualdad deben ser no negativos. \\[\n\\lambda_j\\geq 0 \\quad \\forall j=1,\\cdots,m.\n\\]\nHolgura complementaria: Los multiplicadores de Lagrange solo pueden ser positivos si la restricción está activa. \\[\n\\lambda_j\\left(\\bfa_j^T\\xx-b_j\\right)=0 \\quad \\forall j=1,\\cdots,m.\n\\]\n\n\n Las condiciones mencionadas se conocen como condiciones de Karush-Kuhn-Tucker y son una consecuencia de la caracterización del cono normal para conjuntos definidos como interseccion de restricciones lineales, provista por el Teorema 3. Ya estamos en condiciones de abordar el problema de optimización general."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#generalización",
    "href": "CAPITULO_1/A2_optimalidad.html#generalización",
    "title": "Condiciones de optimalidad",
    "section": "2.2 Generalización",
    "text": "2.2 Generalización\nConsideremos el problema de optimización general \\[\n\\min_{x} f(x)\n\\] \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\nh_i(x)= 0,& i=1,\\cdots,r.\\\\\ng_j(x)\\leq 0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\ndonde \\(\\Omega\\) está definido como una intersección de restricciones funcionales diferenciables.\nSupongamos que \\(\\xx^*\\) es un punto óptimo en la frontera del conjunto factible \\(\\Omega\\) correspondiente a tres condiciones de desigualdad \\(g_i(x) \\le 0\\) para \\(i=1,2,3\\) (ver figura abajo). La idea principal es la siguiente:\n\nEl conjunto de direcciones que forma un ángulo obtuso con todas las direcciones desde \\(\\xx^*\\) que permanecen en \\(\\Omega\\) coincide con el cono normal de la linearización de las restricciones activas en \\(\\xx^*\\).\n\n\n\n\nEnvolvente cónica de la intersección de restricciones \\(g_i(\\xx)\\leq 0\\), para \\(i=1,2,3\\).\n\n\nSi aplicamos la idea anterior a \\(-\\nabla f(\\xx)\\) y consideramos el Teorema 3, obtenemos la generalización de las condiciones de optimalidad de Karush-Kuhn-Tucker (KKT). Denominemos \\(\\tilde{\\Omega}\\) la linearización de \\(\\Omega\\), dado por la linearización de las restricciones en un punto óptimo \\(\\xx^*\\):\n\\[\nh_i(\\xx^*)+\\nabla h_i(\\xx^*)\\cdot (\\xx-\\xx^*)=0,\n\\]\n\\[\ng_i(\\xx^*)+\\nabla g_i(\\xx^*)\\cdot (\\xx-\\xx^*)\\leq 0.\n\\]\nEntonces, por Teorema 3, resulta\n\\[\nN_{\\tilde{\\Omega}}(\\xx^*)=\\left\\{\\sum_{i=1}^m\\lambda_i\\nabla h_i(\\xx^*)+\\sum_{j\\in I(\\xx^*)}\\mu_j\\nabla g_j(\\xx^*): \\lambda_i\\in\\RR, \\mu_j\\in\\RR_{\\geq 0}\\right\\},\n\\]\ndonde \\(I(\\xx^*):=\\left\\{j\\in\\{1,\\cdots,m\\}: g_j(\\xx^*)=0\\right\\}\\). Por supuesto, puede reformularse la condición $jI(^*) utilizando holgura complementaria, tal como antes.\nSi bien no estamos aún en condiciones de extender el Teorema 3, puesto que el desarrollo previo fue más bien intuitivo, podemos establecer las condiciones KKT mediante una definición formal de la siguiente manera.\n\nDefinición 1. (Condiciones de Karush-Kuhn-Tucker (KKT) Sea un problema de optimización no lineal con función objetivo diferenciable y restricciones funcionales, de la forma \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\nh_i(x)= 0,& i=1,\\cdots,r.\\\\\ng_j(x)\\leq 0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\ny sea \\(\\xx\\in\\Omega\\) (factibilidad primal). Las condiciones KKT en \\(\\xx\\) están dadas por:\n\nEstacionariedad: \\[\n-\\nabla f(\\xx)=\\sum_{i=1}^r\\lambda_i\\nabla h_i(\\xx)+\\sum_{j=1}^m\\mu_j\\nabla g_j(\\xx).\n\\]\nFactibilidad dual: \\[\n\\lambda_i\\in\\RR, \\mu_j\\in\\RR_{\\geq 0}\\quad\\forall i=1,\\cdots,r, \\forall j=1,\\cdots, m.\n\\]\nHolgura complementaria: \\[\n\\mu_j g_j(\\xx)=0\\quad \\forall j=1,\\cdots,m.\n\\]\n\n\nEs importante remarcar que:\n\nLas condiciones KKT indican que -\\(\\nabla f(\\xx)\\) debe estar en el cono normal a la linearización del conjunto de restricciones.\nLa condición de holgura compelementaria se resume en “si la restricción \\(g_j(\\xx)\\leq 0\\) no está activa, entonces \\(\\mu_j=0\\)”.\nLas condiciones KKT a menudo son necesarias para la optimalidad, pero no siempre.\n\nA continuación, veremos un ejemplo donde las condiciones KKT fallan. Luego, en la siguiente sección veremos en qué escenarios las condiciones KKT son efectivamente una condición necesaria de optimalidad."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#cualificación-de-restricciones",
    "href": "CAPITULO_1/A2_optimalidad.html#cualificación-de-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "2.3 Cualificación de restricciones",
    "text": "2.3 Cualificación de restricciones"
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#función-dual-de-lagrange",
    "href": "CAPITULO_1/A2_optimalidad.html#función-dual-de-lagrange",
    "title": "Condiciones de optimalidad",
    "section": "3.1 Función dual de Lagrange",
    "text": "3.1 Función dual de Lagrange\n\nDefinición 2. (Lagrangiano) Sea el problema de optimización general \\[\n\\min f(\\xx)\n\\] \\[\n\\text{sujeto a}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^p\\left|\\begin{array}{rl}\ng_i(\\xx)\\leq 0,& i=1,\\cdots,q\\\\\nh_j(\\xx)= 0, & j=1,\\cdots,r\n\\end{array}\\right.\\right\\}.\n\\]\nSe denomina Lagrangiano a la función \\(\\calL:\\RR^p\\times\\RR^q\\times\\RR^r\\to\\RR\\) definida por \\[\n\\calL(\\xx,\\bflambda,\\bfnu)=f(\\xx)+\\sum_{i=1}^q\\lambda_i g_i(\\xx)+\\sum_{j=1}^r\\nu_j h_j(\\xx).\n\\]\n\nLos vectores \\(\\bflambda\\) y \\(\\bfnu\\), cuyas componentes son multiplicadores de Lagrange, se denominan variables duales del problema de optimización y son el argumento de la función definida a continuación. A su vez, al problema de optimización original se lo denomina problema primal.\n\nDefinición 3. (Función dual) Sea \\(\\calL\\) el Lagrangiano de la Definición 2. Se denomina función dual de Lagrange a \\(\\calG:\\RR^q\\times\\RR^r\\to\\RR\\) definida por \\[\n\\calG(\\bflambda,\\bfmu)=\\inf_{\\xx}\\calL(\\xx,\\bflambda,\\bfnu).\n\\]\nCuando el Lagrangiano no está acotado inferiormente en \\(\\xx\\), se asume el valor \\(-\\infty\\).\n\nDado que la función dual es el ínfimo puntual de una familia de funciones afínes de \\((\\bflambda,\\bfnu)\\), es cóncava, aún cuando el problema primal no sea convexo [ver Ejercicio …].\nLa propiedad más importante de la función dual es que es una cota inferior del valor óptimo \\(p^*\\) del problema primal. Es decir, para todo \\(\\bflambda\\geq 0\\) y cualquier \\(\\bfnu\\), resulta \\[\n\\calG(\\bflambda,\\bfnu)\\leq p^*.\n\\]\n\n\nVerificación\n\n\nSea \\(\\tilde{\\xx}\\) un punto factible del problema primal. Entonces \\(g_i(\\tilde{\\xx})\\leq 0\\) y \\(h_j(\\tilde{\\xx})=0\\) para todo \\(i=1,\\cdots,q\\) y \\(j=1,\\cdots,r\\), respectivamente. Por lo tanto, para \\(\\bflambda\\geq 0\\) se tiene que \\[\n\\sum_{i=1}^q\\lambda_ig_i(\\tilde{\\xx})+\\sum_{j=1}^r\\nu_j h_j(\\tilde{\\xx})\\geq 0.\n\\]\nSumando \\(f(\\tilde{\\xx})\\) a ambos miembros, se obtiene \\(\\calL(\\xx,\\bflambda,\\bfnu)\\leq f(\\tilde{\\xx})\\). Luego, por propiedad del ínfimo, resulta \\[\n\\calG(\\bflambda,\\bfnu)\\leq f(\\tilde{\\xx}).\n\\]\nFinalmente, dado que \\(\\tilde{\\xx}\\) es cualquier punto factible, en particular la desigualdad anterior es cierta para un punto óptimo \\(\\xx^*\\) tal que \\(f(\\xx^*)=p^*\\)."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#el-problema-dual-de-lagrange",
    "href": "CAPITULO_1/A2_optimalidad.html#el-problema-dual-de-lagrange",
    "title": "Condiciones de optimalidad",
    "section": "3.2 El problema dual de Lagrange",
    "text": "3.2 El problema dual de Lagrange\nInmediatamente nos podemos preguntar: ¿cual es el valor máximo \\(d^*\\) de \\(\\calG(\\bflambda,\\bfnu)\\) si asumimos \\(\\bflambda\\geq 0\\)? Esto da lugar al problema que definiremos a continuación. Observar que la desigualdad \\(\\calG(\\bflambda,\\bfnu)\\leq p^*\\) implica \\[\nd^*\\leq p^*.\n\\]\n\nDefinición 3. (Problema dual) Sea \\(\\calG\\) la función dual de Lagrange asociado al problema primal de la Definición 2. El problema dual de Lagrange es \\[\n\\max \\calG(\\bflambda,\\bfnu)\n\\] \\[\n\\text{sujeto a }\\; \\bflambda\\geq 0.\n\\]\n\nEn línea con la notación anterior, denominaremos multiplicadores óptimos a un par \\((\\bflambda^*,\\bfnu^*)\\) que es solución del problema dual. Es decir, verifican \\(\\calG(\\bflambda^*,\\bfnu^*)=d^*\\).\nEl problema dual de Lagrange es un problema de optimización convexo, independientemente de que el problema primal sea convexo o no. Esto se debe a que la función a maximizar es cóncava y la restricción es un conjunto convexo."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#suboptimalidad-y-criterio-de-parada",
    "href": "CAPITULO_1/A2_optimalidad.html#suboptimalidad-y-criterio-de-parada",
    "title": "Condiciones de optimalidad",
    "section": "3.3 Suboptimalidad y criterio de parada",
    "text": "3.3 Suboptimalidad y criterio de parada\nLos puntos factibles duales nos permiten acotar cuán subóptimo es un punto factible dado, sin conocer el valor exacto de \\(p^{*}\\). De hecho, si \\(\\xx\\) es factible primal y \\((\\bflambda, \\bfnu)\\) es factible dual, entonces se cumple la siguiente desigualdad: \\[\nf(\\xx) - p^{*} \\leq f(\\xx)-\\calG(\\bflambda, \\bfnu).\n\\]\nEn particular, esto establece que \\(\\xx\\) es \\(\\epsilon\\)-subóptimo, con \\[\\epsilon = f(\\xx) - g(\\bflambda, \\bfnu).\n\\]\nLa brecha \\(\\epsilon\\) se conoce como brecha de dualidad para los puntos factibles \\(\\xx\\) y \\((\\bflambda,\\bfnu)\\). Para dichos puntos, los valores óptimos de los problemas primal y dual verifican \\[\np^*,d^*\\in\\left[g(\\bflambda,\\bfnu), f(\\xx)\\right],\n\\] donde el ancho del intervalo es justamente la brecha de dualidad. Observar que si \\(\\epsilon=0\\), entonces \\(\\xx\\) es óptimo primal y \\((\\bflambda,\\bfnu)\\) es óptimo dual.\nEl concepto de brecha de dualidad puede usarse en algoritmos de optimización para proporcionar criterios de parada no heurísticos. Supongamos que un algoritmo produce una secuencia de puntos factibles primales \\(\\xx^{(k)}\\) y puntos factibles duales \\((\\bflambda^{(k)}, \\bfnu^{(k)})\\), para \\(k = 1, 2, \\ldots\\), y sea \\(\\epsilon_{\\text{abs}} &gt; 0\\) una precisión absoluta requerida. Entonces, el criterio de parada \\[\nf(\\xx^{(k)}) - g(\\bflambda^{(k)}, \\bfnu^{(k)}) \\leq \\epsilon_{\\text{abs}}\n\\]\ngarantiza que, cuando el algoritmo termina, \\(\\xx^{(k)}\\) es \\(\\epsilon_{\\text{abs}}\\)-subóptimo. Por supuesto, la dualidad fuerte debe cumplirse si se pretende que este método funcione para tolerancias \\(\\epsilon_{\\text{abs}}\\) arbitrariamente pequeñas."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#holgura-complementaria",
    "href": "CAPITULO_1/A2_optimalidad.html#holgura-complementaria",
    "title": "Condiciones de optimalidad",
    "section": "3.4 Holgura complementaria",
    "text": "3.4 Holgura complementaria\nSupongamos que los valores óptimos primal y dual se alcanzan y son iguales. Esto es, se cumple la desigualdad fuerte \\(p^*=d^*\\). Esto significa que para puntos óptimos \\(\\xx^*\\) y \\((\\bflambda^*,\\bfnu^*)\\) se verifica \\[\n\\begin{align*}\nf(\\xx^{*}) &= \\calG(\\bflambda^{*}, \\bfnu^{*}) \\\\\n&= \\inf_{x} \\left( f(\\xx) + \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(x) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx) \\right)\\\\\n& \\leq f(\\xx^{*}) + \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx^{*}) \\\\&\\leq f(\\xx^{*}).\n\\end{align*}\n\\]\nLa justificación de cada uno los pasos es sencilla [Ejercicio …]. Concluimos que las dos desigualdades en esta cadena se cumplen con igualdad. En particular, la última igualdad\n\\[\nf(\\xx^*)+ \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx^{*})=f(\\xx^*)\n\\]\nimplica que\n\\[\n\\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) = 0.\n\\]\nPero cada término en esta suma es no positivo, por lo tanto debe verificarse\n\\[\n\\boxed{\\lambda_{i}^{*} g_{i}(\\xx^{*}) = 0, \\quad \\forall i = 1, \\ldots, q.}\n\\]\nEsta es la condición de holgura complementaria que hemos visto en la sección anterior. Se cumple para cualquier punto óptimo primal \\(\\xx^{*}\\) y cualquier punto óptimo dual \\((\\bflambda^{*}, \\bfnu^{*})\\) bajo dualidad fuerte. Recordemos que, en términos generales, esta condición significa que el \\(i\\)-ésimo multiplicador de Lagrange óptimo es cero salvo que la \\(i\\)-ésima restricción esté activa."
  },
  {
    "objectID": "CAPITULO_1/A2_optimalidad.html#relación-entre-dualidad-y-kkt",
    "href": "CAPITULO_1/A2_optimalidad.html#relación-entre-dualidad-y-kkt",
    "title": "Condiciones de optimalidad",
    "section": "3.5 Relación entre dualidad y KKT",
    "text": "3.5 Relación entre dualidad y KKT\nLos conceptos de Lagrangiano y su función dual han permitido caracterizar la relación entre los valores óptimos \\(p^*\\) y \\(d^*\\). En particular, las condiciones de factibilidad dual y de holgura complementaria de la Definición 1 (Condiciones de Karush-Kuhn-Tucker) han permitido primero escribir la desigualdad \\(\\calG(\\bflambda,\\bfmu)\\leq p^*\\) y luego analizar qué sucede cuando \\(p^*=q^*\\).\nVeamos ahora cómo surge la estacionariedad en este contexto. Podemos afirmar que\n\\[\nf(\\xx^*)\\leq f(\\xx)+\\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx)\n\\]\npara todo punto factible \\(\\xx\\), con igualdad si \\(\\xx=\\xx^*\\). El lado derecho es el Lagrangiano \\(L(\\xx,\\bflambda^*,\\bfnu^*)\\), del cual podemos afirmar que \\(\\xx\\) es un minimizador. En consecuencia, debe verificarse\n\\[\n\\begin{align*}\n  \\nabla L(\\xx^*,\\bflambda^*,\\bfnu^*)&=0\\\\\n  \\nabla f(\\xx^*)+\\sum_{i=1}^q\\lambda_i^*\\nabla g_i(\\xx^*)+\\sum_{j=1}^r\\nu_j^*\\nabla h_j(\\xx^*)&=0.\n\\end{align*}\n\\]\n\nTeorema 4. (Dualidad y KKT) Sea \\(\\xx^*\\) un punto óptimo primal y \\((\\bflambda^*,\\bfnu^*)\\) un punto óptimo dual. Si \\(p^*=q^*\\), entonces \\((\\xx^*,\\bflambda^*,\\bfnu^*)\\) satisfacen las condiciones de Karush-Kuhn-Tucker.\n\n\n\n\nEjercicios\n\n\nConsidere el problema \\[\n\\min x^2\\quad\\text{sujeto a}\\quad 2-x\\leq 0.\n\\] Obtenga la función dual de Lagrange y verifique graficamente su convexidad. ¿Cuál es el valor de \\(d^*\\)?\nProbar que la función dual de Lagrange \\(\\calG(\\bflambda,\\bfmu)\\) es cóncava.\nMostrar que, si \\(\\xx\\) es factible primal y \\((\\bflambda,\\bfnu)\\) es factible dual, entonces \\((\\bflambda,\\bfnu)\\) es \\(\\epsilon\\)-subóptimo para el problema dual."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Página de Inicio",
    "section": "",
    "text": "Bienvenidos al curso de Optimización. Aquí encontrarás los capítulos y secciones.\n\n\n\nSección 1: A1_intro_optimizacion\nSección 2: A2_optimalidad\nSección 3: A3_metodos_optimizacion"
  },
  {
    "objectID": "index.html#capítulo-1",
    "href": "index.html#capítulo-1",
    "title": "Página de Inicio",
    "section": "",
    "text": "Sección 1: A1_intro_optimizacion\nSección 2: A2_optimalidad\nSección 3: A3_metodos_optimizacion"
  }
]