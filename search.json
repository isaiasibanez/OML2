[
  {
    "objectID": "macros.html",
    "href": "macros.html",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "",
    "text": "\\[\n\\def\\NN{\\mathbb{N}}\n\\def\\RR{\\mathbb{R}}\n\\def\\media{\\mathbb{E}}\n\\def\\calL{\\mathcal{L}}\n\\def\\calG{\\mathcal{G}}\n\\def\\aa{{\\bf a}}\n\\def\\bb{{\\bf b}}\n\\def\\cc{{\\bf c}}\n\\def\\dd{{\\bf d}}\n\\def\\hh{{\\bf h}}\n\\def\\qq{{\\bf q}}\n\\def\\xx{{\\bf x}}\n\\def\\yy{{\\bf y}}\n\\def\\zz{{\\bf z}}\n\\def\\uu{{\\bf u}}\n\\def\\vv{{\\bf v}}\n\\def\\XX{{\\bf X}}\n\\def\\TT{{\\bf T}}\n\\def\\SS{{\\bf S}}\n\\def\\bfg{{\\bf g}}\n\\def\\bftheta{\\boldsymbol{\\theta}}\n\\def\\bflambda{\\boldsymbol{\\lambda}}\n\\def\\bfeta{\\boldsymbol{\\eta}}\n\\def\\bfmu{\\boldsymbol{\\mu}}\n\\def\\bfnu{\\boldsymbol{\\nu}}\n\\def\\bfSigma{\\boldsymbol{\\Sigma}}\n\\def\\bfone{\\mathbf{1}}\n\\def\\argmin{\\mathop{\\mathrm{arg\\,min\\,}}}\n\\def\\argmax{\\mathop{\\mathrm{arg\\,max\\,}}}\n\\]"
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html",
    "title": "Métodos de optimización",
    "section": "",
    "text": "En general, los problemas de optimización que surgen en el área de estadística y machine learning involucran funciones complejas, no lineales y/o de alta dimensión. Como consecuencia, obtener una solución exacta suele ser inalcanzable o innecesario. Esto último sucede, por ejemplo, cuando la solución exacta es costosa computacionalmente.\nAquí es cuando entran en juego los métodos de optimización numérica: algoritmos iterativos que aproximan una solución al problema de optimización. Su objetivo es construir una secuencia de puntos \\(\\{\\xx_t \\mid t\\in\\mathbb{N}_0\\}\\) que converja al punto óptimo \\(\\xx^*\\), o lo suficientemente cerca de él.\nLos métodos de optimización se definen a partir de las propiedades analíticas de la función objetivo. En esta sección, presentaremos algunos de los métodos fundamentales, construidos bajo distintas suposiciones de diferenciabilidad de \\(f\\), ya sea utilizando información de primer orden (gradiente), o incorporando información de segundo orden (matriz Hessiana).",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente",
    "title": "Métodos de optimización",
    "section": "1.1 Método de descenso por gradiente",
    "text": "1.1 Método de descenso por gradiente\nUna propiedad fundamental del vector gradiente \\(\\nabla f(\\xx)\\) es que es la dirección de máximo crecimiento de \\(f\\) a partir del punto \\(\\xx\\). Por lo tanto, una idea básica para minimizar \\(f\\) es moverse en la dirección opuesta, \\(-\\nabla f(\\xx)\\), una determinada distancia, para luego volver a calcular el vector gradiente y repetir el descenso. Esto deriva en el primer método de optimización que estudiaremos: descenso por gradiente.\n\nMétodo de descenso por gradiente\n\nDado un punto inicial \\(\\xx_0\\in\\text{dom}\\,f\\) y una tasa de aprendizaje \\(\\eta\\):\n\nrepetir para \\(t = 0,1,2,\\dots\\):\n\n1° Calcular dirección \\(-\\nabla f(\\xx_t)\\)\n2° Actualizar \\(\\xx_{t+1} := \\xx_t - \\eta \\nabla f(\\xx_t)\\).\n\nhasta que el criterio de parada se satisfaga.\n\n\n\n\n\nImportante\nComo criterio de parada, se puede fijar una cantidad máxima de iteraciones, aunque en general también se utilizan condiciones de convergencia, como que la norma del gradiente sea menor que un umbral prefijado, o que el cambio entre iteraciones sucesivas sea suficientemente pequeño. En fórmulas: \\[\n\\|\\nabla f(\\xx_t)\\|_2&lt;\\varepsilon_1\\qquad\\text{o}\\qquad\\|\\xx_{t}-\\xx_{t-1}\\|_2&lt;\\varepsilon_2.\n\\]\n\n A continuación mostraremos una función en Python que implementa el algoritmo básico de descenso por gradiente, con los siguientes argumentos:\n\nf: función objetivo.\ngrad_f: función gradiente de \\(f\\).\nx_inicial: punto inicial.\nlr: (learning rate) tasa de aprendizaje \\(\\eta\\).\nmax_iter: cantidad máxima de iteraciones.\ntol_grad: tolerancia para norma del gradiente (opcional).\ntol_x: tolerancia para norma de diferencia entre iteraciones (opcional).\n\nLa salida es una lista con los puntos obtenidos en las iteraciones (x_iter), y los valores de la función (f_iter).\n\nimport numpy as np\n\ndef gradient_descent(f, grad_f, x_inicial, lr=0.1, max_iter=100,\n                      tol_grad=None, tol_x=None, verbose=True):\n   \n    x = np.array(x_inicial, dtype=float)\n    x_iter = [x.copy()]\n    f_iter = [f(x)]\n\n    for t in range(1, max_iter + 1):\n      \n      grad = grad_f(x)\n\n      # Criterio de parada por norma del gradiente:\n      if tol_grad is not None and np.linalg.norm(grad) &lt; tol_grad:\n        if verbose:\n          print(f\"Parada en iteración {t}: |grad_f| &lt; {tol_grad}\")\n        t = t-1\n        break\n\n      x_new = x - lr * grad\n\n      # Criterio de parada por norma de diferencia entre iteraciones:\n      if tol_x is not None and np.linalg.norm(x_new - x) &lt; tol_x:\n        if verbose:\n          print(f\"Parada en iteración {t}: |x_t - x_(t+1)| &lt; {tol_x}\")\n        x = x_new\n        x_iter.append(x.copy())\n        f_iter.append(f(x))\n        break\n\n      x = x_new\n      x_iter.append(x.copy())\n      f_iter.append(f(x))\n  \n    if verbose:\n      print(f\"Iteración final: {t}\")\n      print(f\"Último punto: {x}\")\n      print(f\"Valor de f: {f(x)}\")  \n\n    return x_iter, f_iter\n\n\n\nEjemplo 1 Vamos a utilizar el método de descenso por gradiente para aproximarnos al valor mínimo de\n\\[\nf(x,y)=2(x-2)^2+5(y-3)^2,\n\\]\nel cual sabemos que ocurre en \\((2,3)\\) (vértice del paraboloide elíptico). Necesitamos proporcionar el gradiente de \\(f\\), el cual es \\[\n\\nabla f(x,y)=\\left(4(x-2), 10(y-3)\\right).\n\\]\n\n\nMostrar código\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Función y gradiente:\ndef f(x):\n    return 2*(x[0] - 2)**2 + 5*(x[1] - 3)**2\n\ndef grad_f(x):\n    return np.array([4 * (x[0] - 2), 10 * (x[1] - 3)])\n\n# Parámetros:\nx_inicial = (0, 0)\nlr = 0.05               \nmax_iter = 100\ntol_grad = 1e-3\ntol_x = 1e-3\n\n# Ejecutar GD:\nx_iter, f_iter = gradient_descent(f, grad_f, x_inicial, lr, max_iter, tol_grad, tol_x)\n\n\nParada en iteración 28: |x_t - x_(t+1)| &lt; 0.001\nIteración final: 28\nÚltimo punto: [1.99613144 2.99999999]\nValor de f: 2.9931553533161224e-05\n\n\nLa secuencia de valores obtenidas es:\n\n\nMostrar código\nx_arr = np.array(x_iter)\nx_vals = x_arr[:, 0]\ny_vals = x_arr[:, 1]\ntabla = pd.DataFrame({'x': x_vals, 'y': y_vals})\nprint(tabla)\n\n\n           x         y\n0   0.000000  0.000000\n1   0.400000  1.500000\n2   0.720000  2.250000\n3   0.976000  2.625000\n4   1.180800  2.812500\n5   1.344640  2.906250\n6   1.475712  2.953125\n7   1.580570  2.976562\n8   1.664456  2.988281\n9   1.731565  2.994141\n10  1.785252  2.997070\n11  1.828201  2.998535\n12  1.862561  2.999268\n13  1.890049  2.999634\n14  1.912039  2.999817\n15  1.929631  2.999908\n16  1.943705  2.999954\n17  1.954964  2.999977\n18  1.963971  2.999989\n19  1.971177  2.999994\n20  1.976942  2.999997\n21  1.981553  2.999999\n22  1.985243  2.999999\n23  1.988194  3.000000\n24  1.990555  3.000000\n25  1.992444  3.000000\n26  1.993955  3.000000\n27  1.995164  3.000000\n28  1.996131  3.000000\n\n\nPor último, vamos a realizar la gráfica en el dominio \\(\\RR^2\\) de la función.\n\n\nMostrar código\n# Grilla para graficar:\nx = np.linspace(-0.5, 7, 100)\ny = np.linspace(-0.5, 5, 100)\nX, Y = np.meshgrid(x, y)\ndef f_xy(x, y):\n    return f(np.array([x, y]))\nZ = f_xy(X, Y)\n\n\n# GRAFICA:\nplt.figure(figsize=(10, 6))\n# Curvas de nivel:\ncontours = plt.contour(X, Y, Z, levels=30, cmap='viridis')\nplt.clabel(contours, inline=True, fontsize=8)\n# Ruta de descenso por gradiente:\nplt.plot(x_vals, y_vals, marker='o', linestyle='--', color='red', label='Iteraciones')\nplt.scatter(2, 3, color='blue', label='Mínimo', zorder=5)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xlim(-0.2, 4)\nplt.ylim(-0.2, 5)\nplt.legend(loc='upper right', facecolor='white', framealpha=1)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.1.1 Condición de Lipschitz para el gradiente\nDado que el descenso por gradiente opera considerando la aproximación de primer orden de \\(f\\), una gran clave sea preguntarse qué tan rápido deja de ser precisa dicha aproximación. Una respuesta natural a esta pregunta viene dada por la suavidad de \\(f\\).\nAsí, una vía estándar es imponer una cota sobre qué tan rápido puede cambiar el gradiente de la función al moverse ligeramente en cualquier dirección. Como consecuencia, al movernos en dirección de \\(-\\nabla f(\\xx_t)\\) desde \\(\\xx_t\\), los nuevos gradientes que encontraremos en el camino seguirán estando mayormente alineados con \\(\\nabla f(\\xx_t)\\), lo cual significa que \\(-\\nabla f(\\xx_t)\\) seguirá siendo una buena dirección de descenso durante algún tiempo.\nEspecíficamente, requeriremos que el gradiente \\(\\nabla f(x)\\) sea \\(L\\)-Lipschitz continuo para alguna constante \\(L \\geq 0\\). Esta condición a menudo se llama \\(L\\)-suavidad en la literatura. La presentamos ahora para funciones generales con dominios convexos arbitrarios \\(\\Omega\\); hoy solo nos importará el caso \\(\\Omega = \\mathbb{R}^{n}\\).\n\nDefinición 1. (\\(L\\)-suavidad) Sea \\(\\Omega\\) un conjunto convexo. Una función diferenciable \\(f: \\Omega \\to \\RR\\) es \\(L\\)-suave si su gradiente es \\(L\\)-Lipschitz continuo, esto es, \\[\n\\|\\nabla f(\\xx) - \\nabla f(\\yy)\\|_{2} \\leq L \\|\\xx - \\yy\\|_{2}, \\qquad \\forall \\xx, \\yy \\in \\Omega.\n\\]\n\nUna consecuencia inmediata de la \\(L\\)-suavidad es que la función admite una cota superior cuadrática. A continuación, esta propiedad será extremadamente útil para cuantificar la mejora de un paso del algoritmo de descenso por gradiente, lo cual a menudo se denomina lema del descenso del gradiente.\n\nTeorema 1. (Cota superior cuadrática). Sea \\(f: \\Omega \\to \\mathbb{R}\\) una función \\(L\\)-suave en un dominio convexo \\(\\Omega\\). Entonces, podemos acotar superiormente la función \\(f\\) como \\[\nf(\\yy) \\leq f(\\xx) + \\langle \\nabla f(\\xx), \\yy - \\xx \\rangle + \\frac{L}{2} \\|\\yy - \\xx\\|_{2}^{2} \\quad \\forall \\xx, \\yy \\in \\Omega.\n\\tag{2}\n\\]\n\n\n\nMostrar detalles\n\n\nDemostración\n\n\nDefinamos la recta que conecta \\(\\xx\\) con \\(\\yy\\) como \\(\\gamma(t):=t\\yy+(1-t)\\xx\\) y la restricción de \\(f\\) sobre dicha recta como \\(h(t):=f(\\gamma(t))\\). El teorema fundamental del cálculo permite escribir \\[\nh(1)-h(0)=\\int_0^1h'(t)\\, dt.\n\\]\nPero \\(h(1)=f(\\yy)\\), \\(h(0)=f(\\xx)\\) y \\[\nh'(t)=\\nabla f(\\gamma(t))\\cdot \\gamma'(t)=f(t\\yy+(1-t)\\xx)\\cdot (\\yy-\\xx).\n\\]\nReemplazando resulta \\[\n\\begin{align*}\n  f(\\yy)-f(\\xx)&=\\int_0^1\\nabla f(t\\yy+(1-t)\\xx)\\cdot (\\yy-\\xx)\\,dt\\\\\n  &=\\int_0^1\\left(\\nabla f(t\\yy+(1-t)\\xx)-\\nabla f(\\xx)\\right)\\cdot (\\yy-\\xx)\\,dt+\\nabla f(\\xx)\\cdot (\\yy-\\xx)\\\\\n  &\\leq \\int_0^1\\|\\nabla f(t\\yy+(1-t)\\xx)-\\nabla f(\\xx)\\|_2\\|\\yy-\\xx\\|_2\\,dt+\\nabla f(\\xx)\\cdot (\\yy-\\xx),\n\\end{align*}\n\\]\ndonde en el último paso se utilizó la desigualdad de Cauchy-Schwarz. Observar que el primer factor del integrando es el cambio de gradiente entre dos puntos, lo cual puede ser acotado en virtud de la \\(L\\)-suavidad; es decir \\[\n\\|\\nabla f(t\\yy+(1-t)\\xx)-\\nabla f(\\xx)\\|_2\\leq L\\|t\\yy+(1-t)\\xx-\\xx\\|_2=tL\\|\\yy-\\xx\\|_2.\n\\]\nFinalmente nos queda \\[\n\\begin{align*}\nf(\\yy)-f(\\xx)&\\leq L\\|\\yy-\\xx\\|_2^2\\int_0^1 t\\,dt++\\nabla f(\\xx)\\cdot (\\yy-\\xx)\\\\\n&=\\frac{L}{2}\\|\\yy-\\xx\\|_2^2++\\nabla f(\\xx)\\cdot (\\yy-\\xx).\n\\end{align*}\n\\]\n\n\\(\\blacksquare\\)\n\n\n\n\n\n\nTeorema 2. (Lema del descenso por gradiente) Sea \\(f:\\RR^n\\to\\RR\\) una función \\(L\\)-suave. Entonces, para cualquier \\(0 &lt; \\eta \\leq \\frac{1}{L}\\), cada paso del método de descenso por gradiente garantiza\n\\[\nf(\\xx_{t+1}) \\leq f(\\xx_{t}) - \\frac{\\eta}{2} \\|\\nabla f(\\xx_{t})\\|_{2}^{2}.\n\\]\n\n\n\nMostrar detalles\n\n\nObservacionesDemostración\n\n\n\nEl lema nos asegura que para funciones \\(L\\)-suaves, existe una buena elección de la tasa de aprendizaje que permite garantizar que con cada paso del método de descenso por gradiente se mejorará el valor de la función, siempre que el punto actual no tenga un gradiente nulo.\nEs importante remarcar que el resultado anterior no requiere que \\(f\\) sea convexa.\nAdemás, si \\(f\\) está acotada inferiormente, el lema asegura que, en promedio, los gradientes de los puntos producidos por el método eventualmente deben volverse pequeños. En efecto, para la \\(T\\)-ésima iteración, la aplicación sucesiva del lema resulta en \\[\nf(\\xx_T)\\leq f(\\xx_0)-\\frac{\\eta}{2}\\sum_{t=0}^{T-1}\\|\\nabla f(\\xx_t)\\|_2^2.\n\\] Entonces, para \\(f^\\star:=\\inf f\\) debe ocurrir \\[\n\\sum_{t=0}^{T-1}\\|\\nabla f(\\xx_t)\\|_2^2\\leq \\frac{2}{\\eta T}\\left(f(\\xx_0)-f^\\star\\right),\n\\] tal que al menos algún valor del conjunto \\(\\left\\{\\|\\nabla f (\\xx_t)\\|_2^2\\right\\} \\mid 0\\leq t\\leq T-1\\}\\) está acotado superiormente por \\(\\tfrac{2}{\\eta T}\\left(f(\\xx_0)-f^\\star\\right)\\).\nEn la observación anterior, es importante notar que la cota obtenida depende del punto inicial \\(\\xx_0\\). Cuanto más cercano esté a un punto óptimo, menor será el valor de \\(f(\\xx_0)-f^\\star\\) y, por lo tanto, de la cota. Esto resalta la importancia de una buena elección del punto inicial para acelerar la convergencia del método.\n\n\n\nLa cota superior cuadrática del Teorema 1 para \\(\\xx=\\xx_t\\) y \\(\\yy=\\xx_{t+1}\\) es \\[\nf(\\xx_{t+1})\\leq f(\\xx_t)+\\nabla f(\\xx_t)\\cdot(\\xx_{t+1}-\\xx_t)+\\frac{L}{2}\\|\\xx_{t+1}-\\xx_t\\|_2^2.\n\\]\nBasta utilizar en el lado derecho la fórmula de descenso por gradiente \\(\\xx_{t+1}=\\xx_t+\\eta\\nabla f(\\xx_t)\\): \\[\n\\begin{align*}\n  f(\\xx_{t+1})&\\leq f(\\xx_t)-\\eta\\underbrace{\\nabla f(\\xx_{t})\\cdot\\nabla f(\\xx_t)}_{\\|\\nabla f(\\xx_t)\\|_2^2}+\\frac{L}{2}\\eta^2\\|\\nabla f(\\xx_t)\\|_2^2\\\\\n  &=f(\\xx_t)-\\eta \\left(1-\\frac{L}{2}\\eta\\right)\\|\\nabla f(\\xx_t)\\|_2^2.\n\\end{align*}\n\\]\nCuando \\(\\eta\\leq\\frac{1}{L}\\), el paréntesis es \\(1-\\frac{L}{2}\\eta\\geq\\frac{1}{2}\\). Realizando este cambio, se obtiene el resultado.\n\n\\(\\blacksquare\\)\n\n\n\n\n\n\n\n1.1.2 Convergencia para funciones objetivos convexas\nEl Teorema 2 solo garantiza una tasa de convergencia para la norma del gradiente de la función objetivo, pero no dice nada acerca de la brecha \\(f(\\xx_t)-f^\\star\\). En otras palabras, aunque el gradiente pequeño es una necesidad para pensar en optimalidad, no es suficiente para asegurar que el valor de la función esté efectivamente cerca del óptimo.\nSin embargo, para funciones objetivo convexas, sí se puede establecer una razón de convergencia. Para ello, primero necesitamos enunciar el siguiente resultado.\n\nLema 3. Sea \\(f:\\RR^n\\to\\RR\\) una función convexa y diferenciable. Entonces, para cualquier elección del tamaño de paso \\(\\eta\\), cualquier par de puntos consecutivos \\((\\xx_t,\\xx_{t+1})\\) del método de descenso por gradiente satisfacen \\[\nf(\\xx_{t}) \\leq f(\\xx) + \\frac{1}{2\\eta} \\left( \\|\\xx - \\xx_{t}\\|_{2}^{2} - \\|\\xx - \\xx_{t+1}\\|_{2}^{2} + \\|\\xx_{t+1} - \\xx_{t}\\|_{2}^{2} \\right) \\qquad \\forall \\xx \\in \\mathbb{R}^{n}.\n\\]\n\n\nTeorema 4. Sea \\(f:\\RR^n\\to\\RR\\) una función convexa y \\(L\\)-suave, con minimizador \\(\\xx^\\star \\in \\RR^n\\), y sea \\(0 &lt; \\eta \\leq \\frac{1}{L}\\). El método de descenso por gradiente verifica \\[\nf(\\xx_{t}) - f(\\xx^{*}) \\leq \\frac{\\|\\xx^\\star - \\xx_{0}\\|_{2}^{2}}{2 t \\eta} \\qquad \\forall t\\in\\NN.\n\\]\n\n\n\nMostrar detalles\n\n\nObservaciónDemostración\n\n\n\nAunque el método de descenso por gradiente garantiza que el valor de la función se acerque al óptimo, no siempre asegura que los puntos iterados converjan rápidamente al punto óptimo \\(\\xx^\\star\\). Para obtener garantías más fuertes sobre la rapidez con la que las iteraciones se acercan al punto óptimo, se requieren condiciones adicionales.\n\n\n\nSean \\((\\xx_t,\\xx_{t+1})\\) dos puntos consecutivos de la iteración de descenso por gradiente. Entonces \\(\\|\\xx_{t+1}-\\xx_{t}\\|_2^2=\\eta\\|\\nabla f(\\xx_t)\\|_2^2\\). Por Teorema 3, resulta \\[\nf(\\xx_{t}) \\leq f(\\xx) + \\frac{1}{2\\eta} \\left( \\|\\xx - \\xx_{t}\\|_{2}^{2} - \\|\\xx - \\xx_{t+1}\\|_{2}^{2}\\right)+\\frac{\\eta}{2}\\|\\nabla f(\\xx_t)\\|_2^2, \\qquad \\forall \\xx \\in \\mathbb{R}^{n}.\n\\]\nPero la \\(L\\)-suavidad de \\(f\\) nos permite usar el Teorema 2; para \\(0\\leq\\eta\\leq\\frac{1}{L}\\) se cumple \\(\\frac{\\eta}{2}\\|\\nabla f(\\xx_t)\\|_2^2\\leq f(\\xx_t)-f(\\xx_{t+1})\\). Reemplazando en la expresión anterior, resulta \\[\nf(\\xx_{t+1})\\leq f(\\xx)+ \\frac{1}{2\\eta} \\left( \\|\\xx - \\xx_{t}\\|_{2}^{2} - \\|\\xx - \\xx_{t+1}\\|_{2}^{2}\\right),\\qquad\\forall\\xx\\in\\RR^n.\n\\]\nSumando sobre \\(t=0,1,\\cdot,T-1\\), y teniendo en cuenta que el lado derecho es telescópico, obtenemos \\[\n\\sum_{t=0}^{T-1}f(\\xx_{t+1})\\leq Tf(\\xx)+\\frac{1}{2\\eta}\\left(\\|\\xx-\\xx_0\\|_2^2-\\|\\xx-\\xx_T\\|_2^2\\right).\n\\]\nAhora bien, vamos a aplicar esta última desigualdad a \\(\\xx=\\xx^\\star\\) y descartar el término \\(\\|\\xx-\\xx_T\\|_2^2\\) (esto último se puede hacer porque está restando):\n\\[\n\\sum_{t=0}^{T-1}f(\\xx_{t+1})\\leq Tf(\\xx^{\\star})+\\frac{1}{2\\eta}\\|\\xx^{\\star}-\\xx_0\\|_2^2.\n\\]\nPor último, vamos a usar el hecho que \\(Tf(\\xx_T)\\leq\\sum_{t=0}^{T-1}f(\\xx_{t+1})\\); esto debido a que el Teorema 2 asegura que \\(f(\\xx_t)\\) es no creciente en \\(t\\). Así, finalmente obtenemos \\[\nT(f(\\xx_T)-f(\\xx^{\\star}))\\leq \\frac{1}{2\\eta}\\|\\xx^{\\star}-\\xx_0\\|_2^2.\n\\]\n\n\\(\\blacksquare\\)",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente-proyectado",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente-proyectado",
    "title": "Métodos de optimización",
    "section": "1.2 Método de descenso por gradiente proyectado",
    "text": "1.2 Método de descenso por gradiente proyectado\nVamos a ver ahora como adaptar el método de descenso por gradiente a problemas de optimización con restricciones de la forma\n\\[\n\\min_{\\xx \\in \\Omega} f(\\xx).\n\\]\nEn este caso, supondremos que \\(f\\) es diferenciable y que el conjunto factible \\(\\Omega\\) es cerrado y convexo. La forma natural de extender el método de descenso por gradiente consiste en proyectar los puntos obtenidos sobre \\(\\Omega\\), de manera tal de asegurarnos que la sucesión \\(\\{\\xx_t\\mid t\\in\\mathbb{N}_0\\}\\subset\\Omega\\).\n\nMétodo de descenso por gradiente proyectado\n\nDado un punto inicial \\(\\xx_0\\in\\Omega\\) y una tasa de aprendizaje \\(\\eta &gt; 0\\):\n\nrepetir para \\(t = 0,1,2,\\dots\\):\n\n1° Calcular dirección \\(-\\nabla f(\\xx_t)\\).\n2° Calcular paso de gradiente: \\(\\yy_{t+1} := \\xx_t - \\eta \\nabla f(\\xx_t)\\).\n3° Proyectar sobre \\(\\Omega\\): \\(\\xx_{t+1} := \\Pi_{\\Omega}(\\yy_{t+1})\\).\n\nhasta que se satisfaga el criterio de parada.\n\n\n\n\nLa proyección ortogonal de un punto \\(\\yy\\in \\RR^n\\) sobre un conjunto \\(\\Omega\\) se define como\n\\[\n\\Pi_{\\Omega}(\\yy) := \\arg\\min_{\\yy \\in \\Omega} \\|\\xx - \\yy\\|_2.\n\\]\nCuando \\(\\Omega\\) es cerrado y convexo, la proyección ortogonal existe y es única.\n\n\nVamos a implementar en Python este método. Cabe destacar que el paso de proyección es por sí mismo un problema de optimización, cuyo objetivo es hallar el punto más cercano dentro del conjunto factible \\(\\Omega\\). En algunos casos, como por ejemplo \\(\\Omega=[0,1]^n\\), el conjunto factible tiene una forma especial que permite resolver la proyección de forma explícita y eficiente.\nPor lo tanto, en relación al método de descenso por gradiente, se agrega un nuevo argumento:\n\nproy: función de proyección sobre el conjunto factible.\n\n\nimport numpy as np\n\ndef projected_gradient_descent(f, grad_f, x_inicial, proy,\n                               lr=0.1, max_iter=100,\n                               tol_grad=None, tol_x=None,\n                               verbose=True):\n  \n    x = np.array(x_inicial, dtype=float)\n    x_iter = [x.copy()]\n    f_iter = [f(x)]\n\n    for t in range(1, max_iter + 1):\n      \n      grad = grad_f(x)\n\n      # Criterio de parada por norma del gradiente:\n      if tol_grad is not None and np.linalg.norm(grad) &lt; tol_grad:\n        if verbose:\n          print(f\"Parada en iteración {t}: |grad_f| &lt; {tol_grad}\")\n        t = t-1\n        break\n\n      y = x - lr * grad\n      x_new = proy(y)\n\n      # Criterio de parada por norma de diferencia entre iteraciones:\n      if tol_x is not None and np.linalg.norm(x_new - x) &lt; tol_x:\n        if verbose:\n          print(f\"Parada en iteración {t}: |x_t - x_(t+1)| &lt; {tol_x}\")\n        x = x_new\n        x_iter.append(x.copy())\n        f_iter.append(f(x))\n        break\n\n      x = x_new\n      x_iter.append(x.copy())\n      f_iter.append(f(x))\n\n    if verbose:\n      print(f\"Iteración final: {t}\")\n      print(f\"Último punto: {x}\")\n      print(f\"Valor de f: {f(x)}\")\n\n    return x_iter, f_iter\n\n\nEjemplo 2 Vamos a utilizar el método de descenso por gradiente proyectado para aproximarnos al valor mínimo de\n\\[\nf(x,y)=2(x-2)^2+5(y-3)^2,\n\\]\nsobre el conjunto factible \\(\\Omega=[0,1]\\times[0,1]\\). En este caso la función de proyección es sencilla: consiste en recortar cada coordenada al intervalo correspondiente; es decir \\[\n\\Pi_{[0,1]\\times[0,1]}(x,y):=\\left(\\min(\\max(x,0),1),\\min(\\max(y,0),1)\\right).\n\\]\nEsto se calcula rápidamente con la función np.clip de NumPy.\n\n\nMostrar código\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Función y gradiente:\ndef f(x):\n    return 2*(x[0] - 2)**2 + 5*(x[1] - 3)**2\n\ndef grad_f(x):\n    return np.array([4 * (x[0] - 2), 10 * (x[1] - 3)])\n\n# Proyección:\ndef proy(x):\n    return np.clip(x, 0, 1)\n\n# Parámetros:\nx_inicial = (0, 0)\nlr = 0.01             \nmax_iter = 20\ntol_grad = 1e-3\ntol_x = 1e-3\n\n# Ejecutar PGD:\nx_iter, f_iter = projected_gradient_descent(f, grad_f, x_inicial, proy, lr, max_iter, tol_grad, tol_x)\n\n\nParada en iteración 18: |x_t - x_(t+1)| &lt; 0.001\nIteración final: 18\nÚltimo punto: [1. 1.]\nValor de f: 22.0\n\n\nLa secuencia de valores obtenidas es:\n\n\nMostrar código\nx_arr = np.array(x_iter)\nx_vals = x_arr[:, 0]\ny_vals = x_arr[:, 1]\ntabla = pd.DataFrame({'x': x_vals, 'y': y_vals})\nprint(tabla)\n\n\n           x      y\n0   0.000000  0.000\n1   0.080000  0.300\n2   0.156800  0.570\n3   0.230528  0.813\n4   0.301307  1.000\n5   0.369255  1.000\n6   0.434484  1.000\n7   0.497105  1.000\n8   0.557221  1.000\n9   0.614932  1.000\n10  0.670335  1.000\n11  0.723521  1.000\n12  0.774580  1.000\n13  0.823597  1.000\n14  0.870653  1.000\n15  0.915827  1.000\n16  0.959194  1.000\n17  1.000000  1.000\n18  1.000000  1.000\n\n\nPor último, vamos a realizar la gráfica en el dominio \\(\\RR^2\\) de la función.\n\n\nMostrar código\n# Grilla para graficar:\nx = np.linspace(-0.5, 1.5, 100)\ny = np.linspace(-0.5, 1.5, 100)\nX, Y = np.meshgrid(x, y)\nZ = f(np.array([X, Y]))\n\n# GRAFICA:\nplt.figure(figsize=(10, 6))\n# Curvas de nivel:\ncontours = plt.contour(X, Y, Z, levels=10, cmap='viridis')\nplt.clabel(contours, inline=True, fontsize=8)\n# Ruta de descenso por gradiente proyectado:\nplt.plot(x_vals, y_vals, marker='o', linestyle='--', color='red', label='Iteraciones')\nplt.scatter(2, 3, color='blue', label='Mínimo sin restricciones', zorder=5)\n\n# Caja [0,1]^2 en azul:\ncaja_x = [0, 1, 1, 0, 0]\ncaja_y = [0, 0, 1, 1, 0]\nplt.plot(caja_x, caja_y, color='blue', linewidth=2, linestyle='-', label='$\\Omega = [0,1]^2$')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend(loc='upper right', facecolor='white', framealpha=1)\nplt.grid(True)\nplt.xlim(-0.5, 1.5)\nplt.ylim(-0.5, 1.5)\nplt.show()\n\n\n&lt;&gt;:19: SyntaxWarning: invalid escape sequence '\\O'\n&lt;&gt;:19: SyntaxWarning: invalid escape sequence '\\O'\nC:\\Users\\isaias\\AppData\\Local\\Temp\\ipykernel_32704\\151874914.py:19: SyntaxWarning: invalid escape sequence '\\O'\n  plt.plot(caja_x, caja_y, color='blue', linewidth=2, linestyle='-', label='$\\Omega = [0,1]^2$')\n\n\n\n\n\n\n\n\n\n\n\n1.2.1 Resultados de convergencia\nBajo condiciones similares a las del método sin restricciones, el método proyectado también garantiza convergencia del valor de la función objetivo.\n\nTeorema 5. (Lema del descenso por gradiente proyectado) Sea \\(f:\\RR^n\\to\\RR\\) una función \\(L\\)-suave. Entonces, para cualquier \\(0 &lt; \\eta \\leq \\frac{1}{L}\\), cada paso del método de descenso por gradiente proyectado garantiza\n\\[\nf(\\xx_{t+1}) \\leq f(\\xx_{t}) - \\frac{\\eta}{2} \\|\\nabla f(\\xx_{t})\\|_{2}^{2}+\\frac{1}{2\\eta}\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2.\n\\]\n\n\n\nMostrar detalles\n\n\nDemostración\n\n\nComo en la demostración del Teorema 2, partimos de la cota superior cuadrática del Teorema 1 para \\(\\xx=\\xx_t\\) y \\(\\yy=\\xx_{t+1}\\): \\[\nf(\\xx_{t+1})\\leq f(\\xx_t)+\\nabla f(\\xx_t)\\cdot(\\xx_{t+1}-\\xx_t)+\\frac{L}{2}\\|\\xx_{t+1}-\\xx_t\\|_2^2.\n\\]\nEn este caso, utilizaremos la fórmula \\(\\yy_{t+1}=\\xx_t+\\eta\\nabla f(\\xx_t)\\) para sustituir \\(\\nabla f(\\xx_t)\\) en el segundo término de la suma, obteniendo\n\\[\nf(\\xx_{t+1})\\leq f(\\xx_t)-\\frac{1}{\\eta}(\\yy_{t+1}-\\xx_t)\\cdot(\\xx_{t+1}-\\xx_t)+\\frac{L}{2}\\|\\xx_{t+1}-\\xx_t\\|_2^2.\n\\]\nAhora, en \\((\\yy_{t+1}-\\xx_t)\\cdot(\\xx_{t+1}-\\xx_t)\\) usaremos la identidad \\(\\uu\\cdot\\vv=\\frac{1}{2}\\left(\\|\\uu\\|_2^2+\\|\\vv\\|_2^2-\\|\\uu-\\vv\\|_2^2\\right)\\). Además, para el último término usaremos que \\(L\\leq \\frac{1}{\\eta}\\). Resulta\n\\[\n\\begin{align*}\nf(\\xx_{t+1})&\\leq f(\\xx_t)-\\frac{1}{2\\eta}\\left(\\|\\yy_{t+1}-\\xx_t\\|_2^2+\\|\\xx_{t+1}-\\xx_t\\|_2^2-\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2\\right)+\\frac{1}{2\\eta}\\|\\xx_{t+1}-\\xx_t\\|_2^2\\\\\n&=f(\\xx_t)-\\frac{1}{2\\eta}\\left(\\|\\yy_{t+1}-\\xx_t\\|_2^2-\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2\\right)\\\\\n&\\leq f(\\xx_t)-\\frac{1}{2\\eta}\\left(\\eta^2\\|\\nabla f(\\xx_t)\\|_2^2-\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2\\right)\\\\\n&=f(\\xx_t)-\\frac{\\eta}{2}\\|\\nabla f(\\xx_t)\\|_2^2+\\frac{1}{2\\eta}\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2.\n\\end{align*}\n\\]\n\n\\(\\blacksquare\\)\n\n\n\n\n\nA pesar de que en este lema, en relación con el lema del descenso por gradiente (Teorema 2), aparece el término adicional \\(\\frac{1}{2\\eta}\\|\\yy_{t+1}-\\xx_{t+1}\\|_2^2\\), este puede ser cancelado al hacer la suma sobre \\(t\\), derivando en el mismo resultado de convergencia del Teorema 4 para este método:\n\nTeorema 6. Sea \\(f:\\RR^n\\to\\RR\\) una función convexa y \\(L\\)-suave, con minimizador \\(\\xx^\\star\\in\\Omega\\), donde \\(\\Omega\\subset\\RR^n\\) es un conjunto cerrado y convexo, y sea \\(0&lt;\\eta\\leq\\frac{1}{L}\\). El método de descenso por gradiente proyectado verifica\n\\[\nf(\\xx_t) - f(\\xx^\\star) \\leq \\frac{\\|\\xx_0 - \\xx^\\star\\|_2^2}{2\\eta t}, \\qquad \\forall t\\in\\NN.\n\\]",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente-estocástico",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-descenso-por-gradiente-estocástico",
    "title": "Métodos de optimización",
    "section": "1.3 Método de descenso por gradiente estocástico",
    "text": "1.3 Método de descenso por gradiente estocástico\nPresentaremos una variante del descenso por gradiente que resulta particularmente útil cuando la función objetivo se expresa como una suma de muchas funciones, es decir,\n\\[\nf(\\xx) = \\frac{1}{N} \\sum_{i=1}^{N} f_i(\\xx).\n\\]\nEsto sucede habitualmente en problemas de aprendizaje supervisado, donde la función a optimizar es un costo que puede definirse como suma de los costos individuales de cada dato.\nEl método de descenso por gradiente requiere calcular el gradiente completo \\(\\nabla f(\\xx)\\) en cada paso. En cambio, la versión estocástica reemplaza ese gradiente por una estimación basada en una muestra, lo cual reduce drásticamente el costo computacional por iteración. Esto lo vuelve especialmente atractivo en contextos con grandes volúmenes de datos (big data), donde calcular el gradiente total puede ser inviable.\n\n\nMétodo de descenso por gradiente estocástico\n\nDado un punto inicial \\(\\xx_0\\) y una tasa de aprendizaje \\(\\eta\\):\n\nrepetir para \\(t = 0,1,2,\\dots\\):\n\n1° Elegir un índice \\(i_t\\) al azar de \\(\\{1,\\dots,N\\}\\).\n2° Calcular el gradiente estocástico \\(\\nabla f_{i_t}(\\xx_t)\\).\n3° Actualizar \\(\\xx_{t+1} := \\xx_t - \\eta \\nabla f_{i_t}(\\xx_t)\\).\n\nhasta que se satisfaga un criterio de parada.\n\n\n\n\nImportante\nOtra variante ampliamente utilizada en la práctica es el descenso por gradiente mini-batch, donde en lugar de usar un único índice \\(i_t\\), se toma un subconjunto aleatorio (mini-batch) de índices para estimar el gradiente mediante el promedio de los gradientes evaluados en ese lote. Es decir, el 2° paso del algoritmo anterior adopta la forma\n\\[\n\\frac{1}{\\#(B_t)}\\sum_{i\\in B_t}\\nabla f_i(\\xx_t),\n\\]\ndonde \\(\\#(B_t)\\) denota el tamaño del mini-batch.\nEsto permite un equilibrio entre la alta varianza del método estocástico y el alto costo computacional del método de descenso por gradiente completo. Además, el uso de mini-batches es especialmente adecuado para estrategias computacionales tales como la programación paralela.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-newton",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html#método-de-newton",
    "title": "Métodos de optimización",
    "section": "2.1 Método de Newton",
    "text": "2.1 Método de Newton\nPara el caso sin restricciones,\n\\[\n\\min_{x\\in\\RR^n} f(x),\n\\]\nasumimos que \\(f\\) es una función dos veces diferenciable. En este caso, podemos analizar qué sucede si, en lugar de la aproximación de Taylor de primer orden, usamos la expansión de segundo orden alrededor de un punto \\(\\xx_t\\):\n\\[f(\\xx)\\sim f(\\xx_t)+\\nabla f(\\xx_t)\\cdot(\\xx-\\xx_t)+\\frac{1}{2}(\\xx-\\xx_t)\\cdot \\nabla^2 f(\\xx_t)(\\xx-\\xx_t),\\]\ndonde \\(\\nabla^2 f(\\xx_t)\\) es la matriz Hessiana de \\(f\\) en \\(\\xx_t\\).\nTeniendo en cuenta que la aproximación anterior es una función de \\(\\xx\\), al analizar \\(\\nabla f(\\xx)=\\mathbf{0}\\) se obtiene inmediatamente la ecuación \\[\n\\nabla f(\\xx_t)+\\nabla^2 f(\\xx_t)(\\xx-\\xx_t)=\\mathbf{0},\n\\]\ntal que\n\\[\n\\xx=\\xx_t-\\left[\\nabla^2f(\\xx_t)\\right]^{-1}\\nabla f(\\xx_t).\n\\]\nComparando esto con el método de descenso por gradiente, vemos que al usar una aproximación de Taylor de segundo orden la dirección de descenso cambia a \\(-\\left[\\nabla^2f(\\xx_t)\\right]^{-1}\\nabla f(\\xx_t)\\), lo cual requiere la suposición de que la matriz Hessiana \\(\\nabla^2 f(\\xx_t)\\) sea invertible.\nEl cambio de \\(-\\nabla f(\\xx_t)\\) del método de descenso por gradiente a \\(-\\left[\\nabla^2f(\\xx_t)\\right]^{-1}\\nabla f(\\xx_t)\\) se conoce como precondicionamiento del gradiente por la Hessiana. Esto permite definir la generalización natural del método de descenso por gradiente al contexto de segundo orden.\n\nMétodo de Newton (de paso reducido)\n\nDado un punto inicial \\(\\xx_0 \\in \\mathrm{dom}\\, f\\) y una tasa de aprendizaje \\(\\eta &gt;0\\):\n\nrepetir para \\(t=0,1,2,\\dots\\):\n\n1° Calcular la matriz Hessiana \\(\\nabla^2 f(\\xx_t)\\) y el gradiente \\(\\nabla f(\\xx_t)\\).\n2° Actualizar \\(\\xx_{t+1} := \\xx_t-\\eta\\left[\\nabla^2 f(\\xx_t)\\right]^{-1}\\nabla f(\\xx_t)\\).\n\nhasta que se cumpla un criterio de parada.\n\n\nSi \\(\\eta=1\\), se denomina simplemente método de Newton.\n\n\nEn este caso, la implementación en Python requiere el argumento adicional:\n\nhess_f: función Hessiana de \\(f\\).\n\n\ndef newton_method(f, grad_f, hess_f, x_inicial, lr=0.1,         \n                  max_iter=100, tol_grad=None, tol_x=None, verbose=True):\n    \n    x = np.array(x_inicial, dtype=float)\n    x_iter = [x.copy()]\n    f_iter = [f(x)]\n\n    for t in range(1, max_iter + 1):\n      grad = grad_f(x)\n      hess = hess_f(x)\n\n      # Criterio de parada por norma del gradiente:\n      if tol_grad is not None and np.linalg.norm(grad) &lt; tol_grad:\n        if verbose:\n          print(f\"Parada en iteración {t}: |grad_f| &lt; {tol_grad}\")\n        t = t-1\n        break\n\n      try:\n        p = -np.linalg.solve(hess, grad) \n      except np.linalg.LinAlgError:\n        if verbose:\n          print(f\"Hessiana no invertible en iteración {t}\")\n        break\n\n      x_new = x + lr * p\n\n      # Criterio de parada por norma de diferencia entre iteraciones:\n      if tol_x is not None and np.linalg.norm(x_new - x) &lt; tol_x:\n        if verbose:\n          print(f\"Parada en iteración {t}: |x_t - x_(t+1)| &lt; {tol_x}\")\n        x = x_new\n        x_iter.append(x.copy())\n        f_iter.append(f(x))\n        break\n\n      x = x_new\n      x_iter.append(x.copy())\n      f_iter.append(f(x))\n\n    if verbose:\n      print(f\"Iteración final: {t}\")\n      print(f\"Último punto: {x}\")\n      print(f\"Valor de f: {f(x)}\")\n\n    return x_iter, f_iter\n\n\nEjemplo 3 Vamos a utilizar el método de Newton para aproximarnos al valor mínimo de\n\\[\nf(x,y)=2(x-2)^2+5(y-3)^2,\n\\]\npara poder comparar con el Ejemplo 1. La Hessiana es\n\\[\n\\nabla^2 f(x,y) = \\begin{pmatrix} 4&0\\\\0&10 \\end{pmatrix}.\n\\]\n\n\nMostrar código\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Función y gradiente:\ndef f(x):\n    return 2*(x[0] - 2)**2 + 5*(x[1] - 3)**2\n\ndef grad_f(x):\n    return np.array([4 * (x[0] - 2), 10 * (x[1] - 3)])\n\ndef hess_f(x):\n    return np.array([[4, 0], [0, 10]]) \n\n# Parámetros:\nx_inicial = (0, 0)\nlr = 0.05               \nmax_iter = 100\ntol_grad = 1e-3\ntol_x = 1e-3\n\n# Ejecutar Newton:\nx_iter, f_iter = newton_method(f, grad_f, hess_f, x_inicial, lr, max_iter, tol_grad, tol_x)\n\n\nIteración final: 100\nÚltimo punto: [1.98815894 2.98223841]\nValor de f: 0.0018577913111879544\n\n\nLa secuencia de valores obtenidas es:\n\n\nMostrar código\nx_arr = np.array(x_iter)\nx_vals = x_arr[:, 0]\ny_vals = x_arr[:, 1]\ntabla = pd.DataFrame({'x': x_vals, 'y': y_vals})\nprint(tabla)\n\n\n            x         y\n0    0.000000  0.000000\n1    0.100000  0.150000\n2    0.195000  0.292500\n3    0.285250  0.427875\n4    0.370988  0.556481\n..        ...       ...\n96   1.985462  2.978193\n97   1.986189  2.979284\n98   1.986880  2.980320\n99   1.987536  2.981304\n100  1.988159  2.982238\n\n[101 rows x 2 columns]\n\n\nPor último, vamos a realizar la gráfica en el dominio \\(\\RR^2\\) de la función.\n\n\nMostrar código\n# Grilla para graficar:\nx = np.linspace(-0.5, 7, 100)\ny = np.linspace(-0.5, 5, 100)\nX, Y = np.meshgrid(x, y)\ndef f_xy(x, y):\n    return f(np.array([x, y]))\nZ = f_xy(X, Y)\n\n\n# GRAFICA:\nplt.figure(figsize=(10, 6))\n# Curvas de nivel:\ncontours = plt.contour(X, Y, Z, levels=30, cmap='viridis')\nplt.clabel(contours, inline=True, fontsize=8)\n# Ruta de descenso por gradiente:\nplt.plot(x_vals, y_vals, marker='o', linestyle='--', color='red', label='Iteraciones')\nplt.scatter(2, 3, color='blue', label='Mínimo', zorder=5)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xlim(-0.2, 4)\nplt.ylim(-0.2, 5)\nplt.legend(loc='upper right', facecolor='white', framealpha=1)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nObservar que los puntos iterados son colineales. Esto ocurre en problemas cuadráticos, debido a que la matriz Hessiana es constante. Veamos qué pasa si aplicamos el método de Newton clásico (\\(eta=1\\)).\n\n\nMostrar código\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Función y gradiente:\ndef f(x):\n    return 2*(x[0] - 2)**2 + 5*(x[1] - 3)**2\n\ndef grad_f(x):\n    return np.array([4 * (x[0] - 2), 10 * (x[1] - 3)])\n\ndef hess_f(x):\n    return np.array([[4, 0], [0, 10]]) \n\n# Parámetros:\nx_inicial = (0, 0)\nlr = 1            \nmax_iter = 100\ntol_grad = 1e-3\ntol_x = 1e-3\n\n# Ejecutar Newton:\nx_iter, f_iter = newton_method(f, grad_f, hess_f, x_inicial, lr, max_iter, tol_grad, tol_x)\n\n\nParada en iteración 2: |grad_f| &lt; 0.001\nIteración final: 1\nÚltimo punto: [2. 3.]\nValor de f: 0.0\n\n\n\n\nMostrar código\nx_arr = np.array(x_iter)\nx_vals = x_arr[:, 0]\ny_vals = x_arr[:, 1]\ntabla = pd.DataFrame({'x': x_vals, 'y': y_vals})\nprint(tabla)\n\n\n     x    y\n0  0.0  0.0\n1  2.0  3.0\n\n\n\n\n2.1.1 Garantías de convergencia local",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A5_metodos_optimizacion.html#variantes-y-extensiones-del-método-de-newton",
    "href": "CAPITULO_1/A5_metodos_optimizacion.html#variantes-y-extensiones-del-método-de-newton",
    "title": "Métodos de optimización",
    "section": "2.2 Variantes y extensiones del método de Newton",
    "text": "2.2 Variantes y extensiones del método de Newton\nAdemás del método de Newton clásico, existen otras variantes y extensiones importantes que vale la pena mencionar:\n\nMétodos Quasi-Newton, como BFGS o L-BFGS, evitan calcular e invertir la matriz Hessiana directamente. En su lugar, construyen una aproximación a la Hessiana (o su inversa) utilizando información de los gradientes computados en iteraciones previas. Estos métodos ofrecen un equilibrio entre eficiencia computacional y velocidad de convergencia, especialmente en problemas de gran dimensión.\nMétodos de segundo orden con restricciones, como el método de Newton proyectado o los métodos de barrera, están diseñados para problemas con restricciones sobre el dominio. Aunque requieren un tratamiento más sofisticado, representan una extensión natural de los métodos de segundo orden al caso restringido. Su análisis y aplicación se exploran habitualmente en cursos avanzados de optimización convexa.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.5 Métodos de optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A3_resolucion_computacional.html",
    "href": "CAPITULO_1/A3_resolucion_computacional.html",
    "title": "Resolución computacional de problemas clásicos de optimización",
    "section": "",
    "text": "Una vez que hemos definido qué es un problema de optimización convexa, es natural preguntarse cómo se abordan estos problemas en la práctica. Afortunadamente, existen herramientas computacionales accesibles que permiten resolver problemas convexos de forma eficiente. En particular, en este curso utilizaremos dos librerías utilizadas en Python:\nA través de ejemplos concretos, veremos cómo utilizar estas herramientas para formular y resolver problemas de optimización. Esto también nos ayudará a motivar tanto el estudio de las condiciones de optimalidad como los métodos de optimización, que abordaremos en las proximas secciones, lo cual permitirá justificar porqué y cómo estas herramientas funcionan.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.3 Herramientas computacionales para optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A3_resolucion_computacional.html#cvxpy",
    "href": "CAPITULO_1/A3_resolucion_computacional.html#cvxpy",
    "title": "Resolución computacional de problemas clásicos de optimización",
    "section": "1.1 cvxpy",
    "text": "1.1 cvxpy\n\nPasos a seguir:\nEl uso básico de la librería cargada como cp es:\n\nDefinir las variables independientes con la clase cp.Variable.\nDefinir las restricciones.\nDefinir la función objetivo dentro de la clase cp.Minimize o cp.Maximize.\nDefinir el problema de optimización prob con la clase cp.Problem.\nResolver el problema con el método prob.solve().\n\n\nLos siguientes ejemplos se encuentran disponibles en la guía de usuario de la librería.\n\nEjemplo 1 Resolveremos el problema de optimización convexa:\n\\[\n\\min_{(x,y)}\\, (x-y)^2\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^2\\left|\\begin{array}{rl}\n\\, y-x+1\\leq 0\\\\\n\\, x+y-1=0\n\\end{array}\\right.\\right\\}.\n\\]\n\nimport cvxpy as cp\n\n# 1. Creamos dos variables:\nx = cp.Variable()\ny = cp.Variable()\n\n# 2. Definimos dos restricciones:\nconstraints = [x + y == 1,\n               x - y &gt;= 1]\n\n# 3. Definimos la función objetivo:\nobj = cp.Minimize((x - y)**2)\n\n# 4. Definimos el problema de optimización:\nprob = cp.Problem(obj, constraints)\n\n# 5. Resolvemos:\nprob.solve() \nprint(\"Estado:\", prob.status)\nprint(\"Valor objetivo óptimo:\", prob.value)\nprint(\"Punto óptimo\", x.value, y.value)\n\nEstado: optimal\nValor objetivo óptimo: 1.0\nPunto óptimo 1.0 1.570086213240983e-22\n\n\nA continuación, vamos a representar geométricamente este problema: del lado izquierdo, el grafo en \\(\\RR^3\\) de la función objetivo; del lado derecho, el conjunto factible como intersección de las restricciones dadas.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\n\n# Función:\ndef f(x, y):\n    return (x - y)**2\n\n# Grid:\nx = np.linspace(-2, 3, 100)\ny = np.linspace(-2, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\n# Solución del problema:\nsolucion = 1,0\nvalor_optimo = f(solucion[0],solucion[1])\n\n\n# GRÁFICAS:\nfig = plt.figure(figsize=(10, 4))\n\n## Funcion objetivo:\nax1 = fig.add_subplot(121, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)\nax1.scatter(solucion[0], solucion[1], valor_optimo, color='red', edgecolors='black', s=50)\nax1.set_title('Superficie y punto solución')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\n\n## Conjunto factible:\nax2 = fig.add_subplot(122)\nax2.set_xlim(-2, 3); ax2.set_ylim(-2, 3)\nx_line = np.linspace(-2, 3, 100)\n# Restricción de igualdad:\nax2.plot(x_line, 1-x_line, color = 'lightgreen', label='$x + y - 1 = 0$')\n# Restricción de desigualdad:\nyy, xx = np.meshgrid(np.linspace(-2, 3, 100), np.linspace(-2, 3, 100))\nax2.contourf(xx, yy, yy &lt;= xx - 1, levels=[0.5, 1], colors=['lightblue'], alpha=0.5)\nax2.plot(x_line, x_line-1, color='lightblue', linestyle='-')\npatch = Patch(facecolor='lightblue', edgecolor='none', alpha=0.5, label=r'$y \\leq x - 1$')\n# Intersección de restricciones:\nx_aux = np.linspace(1,3,100)\nax2.plot(x_aux, 1-x_aux, color = 'black', linewidth = 3, label = 'Conjunto factible')\n# Punto solución:\nax2.scatter(solucion[0], solucion[1], color='red', edgecolors='black', s=50, zorder=10, label='Punto solución (1,0)')\n#\nax2.set_title('Región factible en plano xy')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.legend()\nax2.legend(handles=[patch] + ax2.get_legend_handles_labels()[0])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEjemplo 2 Resolveremos el problema de optimización convexa:\n\\[\n\\min_{\\xx}\\, \\|A\\xx-\\bb\\|_2^2\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\n\\, 0\\leq x_i\\leq 1,\\quad i=1,\\cdots,n\\end{array}\\right.\\right\\},\n\\]\ncon \\(A\\in\\RR^{n\\times m}\\) y \\(\\bb\\in\\RR^m\\) aleatorios, para \\(n,m\\in\\mathbb{N}\\) fijos.\n\nimport cvxpy as cp\nimport numpy as np\n\n# Datos:\nm = 10; n = 5\nnp.random.seed(1)\nA = np.random.randn(m, n)\nb = np.random.randn(m)\n\n# 1. Creamos variables:\nx = cp.Variable(n)\n\n# 2. Definimos restricciones:\nconstraints = [0 &lt;= x, x &lt;= 1]\n\n# 3. Definimos la función objetivo:\nobj = cp.Minimize(cp.sum_squares(A @ x - b))\n\n# 4. Definimos el problema de optimización:\nprob = cp.Problem(obj, constraints)\n\n# 5. Resolvemos:\nprob.solve()\nprint(\"Valor objetivo óptimo:\", prob.value)\nprint(\"Punto óptimo:\", x.value)\n\nValor objetivo óptimo: 4.141338603672535\nPunto óptimo: [-4.95922264e-21  6.07571976e-21  1.34643668e-01  1.24976681e-01\n -4.57130806e-21]",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.3 Herramientas computacionales para optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A3_resolucion_computacional.html#scipy.optimize",
    "href": "CAPITULO_1/A3_resolucion_computacional.html#scipy.optimize",
    "title": "Resolución computacional de problemas clásicos de optimización",
    "section": "1.2 scipy.optimize",
    "text": "1.2 scipy.optimize\n\nPasos a seguir:\nEl uso básico de la librería scipy.optimize es:\n\nDefinir la función objetivo como una función de Python.\nDefinir las restricciones con las clases Bounds y LinearConstraint.\nProponer un punto inicial (guess) para las variables.\nResolver el problema con el método minimize.\n\n\nEl siguiente ejemplo se encuentra disponible en la documentación de la librería.\n\nEjemplo 3 La función de Rosenbrock es una función no convexa que se utiliza para evaluar el rendimiento de métodos de optimización numérica, debido a la dificultad para converger al valor mínimo. Para dos variables, está definida por \\[\nf(x,y)=(a-x)^2+b(y-x^2)^2,\n\\]\ncon \\(a,b\\in\\RR\\). En este ejemplo, consideraremos \\(a=1\\) y \\(b=100\\) y resolveremos el problema de optimización convexa:\n\\[\n\\min_{\\xx}\\, (1-x)^2+100(y-x^2)^2\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\n\\, x+2y\\leq 1\\\\\n\\, x^2+y\\leq 1\\\\\n\\, x^2-y\\leq 1\\\\\n\\, 2x+y=1\\\\\n\\, 0\\leq x\\leq 1\\\\\n\\, -0.5\\leq y\\leq 2\n\\end{array}\\right.\\right\\}.\n\\]\nLas restricciones se pueden separar en:\n\nCotas: \\(0\\leq x\\leq 1\\), \\(-0.5\\leq y\\leq 2\\).\nRestricciones lineales: \\(x+2y\\leq 1\\), \\(2x+y=1\\). Pueden reescribirse como: \\[\n\\begin{pmatrix}\n-\\infty\\\\1\n\\end{pmatrix}\n\\leq\n\\begin{pmatrix}\n1&2 \\\\\n2&1 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\nx\\\\ y\n\\end{pmatrix}\n\\leq\n\\begin{pmatrix}\n1\\\\1\n\\end{pmatrix}\n\\]\nRestricciones no lineales: \\(x^2+y\\leq 1\\), \\(x^2-y\\leq 1\\). Pueden reescribirse como: \\[\n\\begin{pmatrix}\n-\\infty\\\\-\\infty\n\\end{pmatrix}\n\\leq\n\\begin{pmatrix}\nx^2+y \\\\\nx+y^2 \\\\\n\\end{pmatrix}\n\\leq\n\\begin{pmatrix}\n1\\\\1\n\\end{pmatrix}\n\\]\n\n\nfrom scipy.optimize import minimize\nfrom scipy.optimize import Bounds\nfrom scipy.optimize import LinearConstraint\nfrom scipy.optimize import NonlinearConstraint\nimport numpy as np\n\n# 1. Definimos la función objetivo:\ndef rosen2d(x):\n    \"\"\"Función de Rosenbrock para dos variables\"\"\"\n    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n\n# 2. Definimos las restricciones:\n## Cotas:\nbounds = Bounds([0, -0.5], [1, 2])\n## Restricciones lineales:\nlinear_constraint = LinearConstraint([[1, 2], [2, 1]], lb=[-np.inf, 1], ub=[1, 1])\n## Restricciones no lineales:\ndef cons_f(x):\n    return [x[0]**2 + x[1], x[0]**2 - x[1]]\nnonlinear_constraint = NonlinearConstraint(cons_f, lb=-np.inf, ub=1)\n\n# 3. Punto inicial:\nx0 = np.array([0.5, 0])\n\n# 4. Resolvemos:\nres = minimize(rosen2d, x0, method='trust-constr',\n               constraints=[linear_constraint, nonlinear_constraint],\n               options={'verbose': 1}, bounds=bounds)\nprint(\"Éxito en optimización:\", res.success)\nprint(\"Valor objetivo óptimo:\", res.fun)\nprint(\"Punto óptimo:\", res.x)\n\n`gtol` termination condition is satisfied.\nNumber of iterations: 12, function evaluations: 24, CG iterations: 7, optimality: 4.48e-09, constraint violation: 0.00e+00, execution time: 0.026 s.\nÉxito en optimización: True\nValor objetivo óptimo: 0.3427175756443014\nPunto óptimo: [0.41494531 0.17010937]",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.3 Herramientas computacionales para optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A3_resolucion_computacional.html#programación-lineal",
    "href": "CAPITULO_1/A3_resolucion_computacional.html#programación-lineal",
    "title": "Resolución computacional de problemas clásicos de optimización",
    "section": "2.1 Programación lineal",
    "text": "2.1 Programación lineal\nCuando tanto la función objetivo como todas las restricciones son afines, el problema de optimización se llama programa lineal (LP).\n\nForma básica\n\\[\n\\min_{\\xx}\\,\\cc^\\top\\xx+d\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\nG\\xx\\preceq \\hh\\\\\nA\\xx=\\bb\n\\end{array}\\right.\\right\\},\n\\] donde \\(\\cc\\in\\RR^n\\), \\(G\\in\\RR^{r\\times n}\\), \\(\\hh\\in\\RR^r\\), \\(A\\in\\RR^{m\\times n}\\) y \\(\\bb\\in\\RR^m\\).\n\n\n\nMostrar detalles\n\n\nIntepretación geométricaObservaciones\n\n\nEl conjunto factible de un LP es un poliedro \\(\\mathcal{P}\\). Los conjuntos de nivel de la función objetivo son hiperplanos ortogonales a la dirección \\(\\cc\\). En consecuencia, el punto óptimo \\(x^{\\star}\\) es aquel punto de \\(\\mathcal{P}\\) lo más alejado posible en la dirección de \\(-\\cc\\).\n\n\n\nInterpretación geométrica de un LP.\n\n\n\n\n\n\nLos programas lineales son, por supuesto, problemas de optimización convexa. Observar que, si \\(\\bfg_i\\) es la \\(i\\)-ésima fila de \\(G\\), escribir \\(G\\xx\\preceq \\hh\\) es equivalente a escribir \\[g_i(\\xx)=\\bfg_i\\xx-h_i\\leq 0,\\quad i=1,\\cdots,r.\\]\n\nLo mismo ocurre con las restricciones de igualdad.\n\nDos casos especiales de LP son tan comunes que se les ha dado nombres específicos. En un LP en forma estándar, las desigualdades son restricciones de no negatividad sobre las componentes de \\(\\xx\\); es decir, \\(\\xx\\succeq 0\\). Por otra parte, si un LP no tiene restricciones de igualdad, se dice que está en forma de desigualdad.\n\n\n\n\n\nEn lo que sigue dejo PROBLEMAS TÍPICOS de LP provistos en Boyd. Lo que está escrito es la formulación general. La idea es proponer algun/os caso/s con números para que los estudiantes resuelvan con las librerías.\n\n\n\n\n\n\nLa dieta\n\n\n\nUna dieta saludable contiene \\(m\\) nutrientes diferentes en cantidades al menos iguales a \\(b_1, \\ldots, b_m\\). Podemos componer tal dieta eligiendo cantidades no negativas \\(x_1, \\ldots, x_n\\) de \\(n\\) alimentos diferentes. Una unidad de cantidad del alimento \\(j\\) contiene una cantidad \\(a_{ij}\\) del nutriente \\(i\\) y tiene un costo de \\(c_j\\). Queremos determinar la dieta más barata que satisfaga los requisitos nutricionales. Esto conduce al siguiente LP: \\[\n\\min_{\\xx}\\,\\cc^\\top\\xx\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\nA\\xx\\succeq \\bb\\\\\n\\xx\\succeq \\mathbf{0}\n\\end{array}\\right.\\right\\}.\n\\]\nVarias variaciones de este problema también se pueden formular como LPs. Por ejemplo, podemos insistir en una cantidad exacta de un nutriente en la dieta (lo que da una restricción de igualdad lineal), o podemos imponer un límite superior en la cantidad de un nutriente, además del límite inferior como se indicó anteriormente.\n\nEjemplo: PROPONER\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl centro de Chebyshev\n\n\n\nConsideremos el problema de encontrar la bola euclidiana más grande que se encuentra contenida en un poliedro descrito por desigualdades lineales: \\[\n\\mathcal{P} = \\{\\xx \\in \\mathbb{R}^n \\mid \\aa_i^\\top\\xx \\leq b_i,\\quad i = 1, \\ldots, m\\}.\n\\]\nEl centro de la bola óptima se llama centro de Chebyshev del poliedro. Para poder formular el problema, debemos representar la bola mediante \\[\n\\mathcal{B}(\\xx,r) = \\{\\xx + \\uu \\mid \\|\\uu\\|_2 \\leq r\\}.\n\\]\nLas variables en el problema son el centro \\(\\xx\\in\\RR^n\\) y el radio \\(r\\in\\RR\\). El objetivo, por lo tanto, es maximizar \\(r\\) sujeto a la restricción \\(\\mathcal{B}(\\xx,r)\\subset\\mathcal{P}\\).\nPara definir las restricciones, vamos a usar el hecho que \\[\n\\sup\\{\\aa_i^\\top\\uu \\mid \\|\\uu\\|_2\\leq r\\}=r\\|\\aa_i\\|_2\\qquad\\text{¿Porqué?}\n\\]\nEn consecuencia, el requisito de que \\(\\mathcal{B}(\\xx,r)\\) pertenezca a cada subespacio \\(\\aa_i^\\top \\xx\\leq b_i\\) puede escribirse como \\[\n\\aa_i^\\top(\\xx+\\uu)=\\aa_i^\\top\\xx+r\\|\\aa_i\\|_2\\leq b_i,\n\\] lo cual es una desigualdad lineal. En conclusión, hallar el centro de Chebyshev es el siguiente LP en forma de desigualdad: \\[\n\\max_{\\xx}\\,r\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\n\\aa_i^\\top\\xx+r\\|\\aa_i\\|_2\\leq b_i,\\quad i=1,\\cdots, m\n\\end{array}\\right.\\right\\}.\n\\]\n\nEjemplo: PROPONER",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.3 Herramientas computacionales para optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A3_resolucion_computacional.html#programación-cuadrática",
    "href": "CAPITULO_1/A3_resolucion_computacional.html#programación-cuadrática",
    "title": "Resolución computacional de problemas clásicos de optimización",
    "section": "2.2 Programación cuadrática",
    "text": "2.2 Programación cuadrática\nCuando la función objetivo es cuadrática (convexa) y las restricciones son afines, el problema de optimización se llama programa cuadrático (QP).\n\nForma básica\n\\[\n\\min_{\\xx}\\,\\frac{1}{2}\\xx^\\top P \\xx+\\qq^\\top\\xx+r\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\nG\\xx\\preceq \\hh\\\\\nA\\xx=\\bb\n\\end{array}\\right.\\right\\},\n\\] donde \\(P\\in\\mathbf{S}_{+}^n\\), \\(\\qq\\in\\RR^n\\), \\(r\\in\\RR\\), \\(G\\in\\RR^{r\\times n}\\), \\(\\hh\\in\\RR^r\\), \\(A\\in\\RR^{m\\times n}\\) y \\(\\bb\\in\\RR^m\\).\n\n\n\nMostrar detalles\n\n\nIntepretación geométricaObservaciones\n\n\nEl conjunto factible de un QP es un poliedro \\(\\mathcal{P}\\). La figura muestra el punto óptimo \\(x^{\\star}\\) y el vector gradiente \\(-\\nabla f(\\xx^{\\star}\\), perpendicular tanto al conjunto de nivel (propiedad del vector gradiente) como a uno de las caras del poliedro.\n\n\n\nInterpretación geométrica de un QP.\n\n\n\n\n\n\nLos programas cuadráticos son, por supuesto, problemas de optimización convexa. Si la restricción de desigualdad también es cuadrática, el problema se denomina programa cuadrático con restricción cuadrática (QCQP).\n\n\n\n\n\n\n\n\n\n\n\nDistancia entre poliedros\n\n\n\nLa distancia euclidiana entre los poliedros \\(\\mathcal{P}_1 = \\{\\xx \\mid A_1 \\xx \\preceq \\bb_1\\}\\) y \\(\\mathcal{P}_2 = \\{\\xx \\mid A_2 \\xx \\preceq \\bb_2\\}\\) en \\(\\RR^n\\) se define como\n\\[\n\\text{dist}\\,(\\mathcal{P}_1, \\mathcal{P}_2) = \\inf \\{ \\|\\xx_1 - \\xx_2\\|_2 \\mid \\xx_1 \\in \\mathcal{P}_1, \\xx_2 \\in \\mathcal{P}_2 \\}.\n\\]\nSi los poliedros se intersecan, la distancia es cero.\nPara encontrar la distancia entre \\(\\mathcal{P}_1\\) y \\(\\mathcal{P}_2\\), podemos resolver el QP con variables \\(\\xx_1\\) y \\(\\xx_2\\) definido como \\[\n\\min_{\\xx_1, \\xx_2}\\,\\|\\xx_1-\\xx_2\\|_2^2\n\\] \\[\n\\text{s.t.}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\nA_1\\xx_1\\preceq \\bb_1\\\\\nA_2\\xx_2\\preceq \\bb_2\n\\end{array}\\right.\\right\\},\n\\]\nEl único caso en que este problema no tiene solución es si uno de los poliedros está vacío. Por otro lado, el valor óptimo es cero si y solo si los poliedros se intersecan, en cuyo caso \\(\\xx_1=\\xx2\\). En cualquier otro caso, los puntos óptimos \\(\\xx_1\\) y \\(\\xx_\"\\) son los puntos en \\(\\mathcal{P}_1\\) y \\(\\mathcal{P}_2\\), respectivamente, que están más cerca el uno del otro.\n\nEjemplo: PROPONER",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.3 Herramientas computacionales para optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A1_intro_optimizacion.html",
    "href": "CAPITULO_1/A1_intro_optimizacion.html",
    "title": "Introducción a la optimización",
    "section": "",
    "text": "\\[\n\\def\\NN{\\mathbb{N}}\n\\def\\RR{\\mathbb{R}}\n\\def\\media{\\mathbb{E}}\n\\def\\calL{\\mathcal{L}}\n\\def\\calG{\\mathcal{G}}\n\\def\\aa{{\\bf a}}\n\\def\\bb{{\\bf b}}\n\\def\\cc{{\\bf c}}\n\\def\\dd{{\\bf d}}\n\\def\\hh{{\\bf h}}\n\\def\\qq{{\\bf q}}\n\\def\\xx{{\\bf x}}\n\\def\\yy{{\\bf y}}\n\\def\\zz{{\\bf z}}\n\\def\\uu{{\\bf u}}\n\\def\\vv{{\\bf v}}\n\\def\\XX{{\\bf X}}\n\\def\\TT{{\\bf T}}\n\\def\\SS{{\\bf S}}\n\\def\\bfg{{\\bf g}}\n\\def\\bftheta{\\boldsymbol{\\theta}}\n\\def\\bflambda{\\boldsymbol{\\lambda}}\n\\def\\bfeta{\\boldsymbol{\\eta}}\n\\def\\bfmu{\\boldsymbol{\\mu}}\n\\def\\bfnu{\\boldsymbol{\\nu}}\n\\def\\bfSigma{\\boldsymbol{\\Sigma}}\n\\def\\bfone{\\mathbf{1}}\n\\def\\argmin{\\mathop{\\mathrm{arg\\,min\\,}}}\n\\def\\argmax{\\mathop{\\mathrm{arg\\,max\\,}}}\n\\]\n\nLa optimización es una herramienta fundamental en matemática aplicada, ciencia de datos y otras disciplinas. En términos generales, el objetivo de un problema de optimización es encontrar el valor de una variable (o conjunto de variables) que minimice o maximice una determinada función, posiblemente bajo ciertas restricciones.\n\n1 Optimización matemática\n\nDefinición 1. (Problema de optimización) Un problema de optimización matemática tiene la forma \\[\n\\begin{array}{ll}\n\\text{minimizar } & f(\\xx)\\\\\n\\text{sujeto a } & \\xx\\in\\Omega.\n\\end{array}\n\\tag{1}\n\\]\ndonde:\n\n\\(f:\\RR^n\\to\\RR\\) es la función objetivo.\n\\(\\xx=(x_1,\\ldots, x_n)\\) son las variables de optimización.\n\\(\\Omega\\subset\\RR^n\\) es el conjunto factible o conjunto de restricciones.\n\nUn vector \\(\\xx^\\star\\in\\Omega\\) se denomina punto óptimo del problema (1) si allí \\(f\\) alcanza su valor más pequeño en \\(\\Omega\\). A dicho valor lo denominaremos valor óptimo, y denotaremos \\(f^\\star:=f(\\xx^\\star)\\).\n\n\nEn general, se asume que la función objetivo \\(f\\) es continua. Además, a menudo se suele imponer la condición de que también sea diferenciable, ya que facilita el análisis teórico y permite el diseño de métodos de optimización.\nPor otra parte, son de especial interés los problemas con restricciones funcionales, que son aquellos en los cuales el conjunto factible es de la forma\n\\[\n\\Omega=\\left\\{\\xx\\in\\RR^n\\left|\\begin{array}{rl}\n\\; g_i(\\xx)\\leq 0,& i=1,\\cdots,r\\\\\n\\; h_j(\\xx)=0, & j=1,\\cdots,m\n\\end{array}\\right.\\right\\}.\n\\]\nEs decir, \\(\\Omega\\) queda definido a partir de un conjunto de funciones de restricción, tanto de desigualdad (\\(g_i:\\RR^n\\to\\RR\\)) como de igualdad (\\(h_j:\\RR^n\\to\\RR\\)). En función de las características de estas funciones, el conjunto factible puede adquirir ciertas propiedades geométricas fundamentales.\nLas preguntas que surgen de un problema de optimización son:\n\n\n\n\n¿Existe una solución?\nEn caso afirmativo, ¿podemos calcularla?\n\n\nGeneralmente, consideramos familias o clases de problemas de optimización, caracterizadas por formas particulares de las funciones objetivo y de las funciones de restricción. Algunos ejemplos importantes son:\n\nPrograma lineal: Un problema de optimización es un programa lineal si tanto la función objetivo \\(f\\) como las funciones de restricción \\(g_i\\) y \\(h_j\\) son funciones lineales; esto es, son funciones \\(\\varphi:\\RR^n\\to\\RR\\) que satisfacen la igualdad: \\[\n\\varphi(\\alpha\\xx+\\beta\\yy)=\\alpha\\,\\varphi(\\xx)+\\beta\\,\\varphi(\\yy),\n\\] para todo \\(\\xx,\\yy\\in\\RR^n\\) y para todo \\(\\alpha,\\beta\\in\\RR\\).\nOptimización convexa: Un problema de optimización convexa es aquel en el que tanto la función objetivo como las funciones de restricción son funciones convexas; esto es, son funciones \\(\\varphi:\\RR^n\\to\\RR\\) que satisfacen la desigualdad: \\[\n\\varphi(\\alpha \\xx+\\beta \\yy)\\leq \\alpha\\,\\varphi(\\xx)+\\beta\\,\\varphi(\\yy),\n\\] para todo \\(\\xx,\\yy\\in\\RR^n\\) y para todo \\(\\alpha,\\beta\\in[0,1]\\) con \\(\\alpha+\\beta=1\\).\n\nComparando los dos ejemplos anteriores, vemos que la convexidad es más general que la linealidad: la desigualdad reemplaza la igualdad más restrictiva, y además la desigualdad debe cumplirse solo para ciertos valores de \\(\\alpha\\) y \\(\\beta\\). Por lo tanto, cualquier programa lineal es un problema de optimización convexa.\nEl estudio de los problemas de optimización convexa lo realizaremos en Capítulo 1 - Sección 2. Respecto a programación lineal, veremos un ejemplo básico en esta misma sección más adelante, y otros ejemplos de aplicación se presentarán en Capítulo 1 - Sección 3 cuando exploremos un par de librerías de Python útiles para resolver problemas de optimización.\nPor lo pronto, veamos a continuación algunos ejemplos básicos de ejercicios de optimización, que seguramente les resultarán familiares de cursos previos.\n\nEjemplo 1\n\\[\n\\begin{array}{ll}\n\\text{minimizar } & x^2-4x+5\\\\\n\\text{sujeto a } & x\\in\\RR.\n\\end{array}\n\\]\n\n\n\nEn este problema no se imponen restricciones sobre el valor de \\(x\\), más allá de pedirle que pertenezca al dominio de la función. En estos casos, se dice que es un problema sin restricciones.\nLa función objetivo es \\(f(x)=x^2-4x+5\\). Al ser una función cuadrática con coeficiente cuadrático positivo, sabemos que el punto óptimo ocurre en su vértice. Es decir, \\[\nx^\\star=-\\frac{-4}{2\\cdot 1}=2.\n\\]\nLuego, el valor óptimo es \\(f(2)=2^2-4\\cdot 2+5=1\\).\n\n\n\nEjemplo 2\n\\[\n\\begin{array}{ll}\n\\text{minimizar } & x^3-3x+y^2\\\\\n\\text{sujeto a } & (x,y)\\in\\RR^2.\n\\end{array}\n\\]\n\n\n\nEn este problema de optimización, la función objetivo es \\(f(x,y)=x^3-3x+y^2\\). Dado que no hay restricciones, podemos obtener en primer lugar los puntos críticos que anulan el vector gradiente. Así, a partir de \\[\n\\nabla f(x,y)=(3x^2-3,2y)=(0,0)\n\\] obtenemos los candidatos \\((-1,0)\\) y \\((1,0)\\). Para determinar la condición de estos puntos, tenemos como herramienta el criterio del Hessiano, el cual inspecciona la matriz de derivadas de segundo orden: \\[\nH(x,y)=\\begin{pmatrix}6x&0\\\\0&2\\end{pmatrix}.\n\\]\nAl aplicar dicho criterio, resulta que en \\((1,0)\\) hay un mínimo local, mientras que \\((-1,0)\\) se descarta por ser punto silla (verificar). No obstante, esto no quiere decir que hallamos encontrado el punto óptimo, ya que nuestro problema de optimización requiere que el valor óptimo sea global.\nEs importante remarcar lo siguiente:\n\nSer mínimo local es una condición necesaria, pero no suficiente, para ser mínimo global.\n\n\n\n\nDe hecho, para este problema no hay un punto óptimo, puesto que la función no está acotada inferiormente, tal como se puede apreciar en su gráfica. Analíticamente, notar que para \\(y=0\\) ocurre que \\(\\lim_{x\\to-\\infty}(x^3-3x)=-\\infty\\).\n\n\n\nEjemplo 3\n\\[\n\\begin{array}{ll}\n\\text{minimizar } & x^2+y^2\\\\\n\\text{sujeto a } & xy=1.\n\\end{array}\n\\]\n\n\n\n\n\n\nEn este caso, tenemos una restricción funcional de igualdad definida por \\(h(x,y)=xy-1\\). Este problema se puede resolver aplicando el método de multiplicadores de Lagrange, el cual consiste en analizar la ecuación \\[\n\\begin{align*}\n\\nabla f(x,y)-\\lambda\\nabla h(x,y)&=(0,0)\\\\\n(2x-\\lambda y,2y-\\lambda x)&=(0,0).\n\\end{align*}\n\\]\nLos puntos críticos son \\((1,1)\\) y \\((-1,-1)\\), ambos con \\(\\lambda=2\\) (verificar). Al valuar la función objetivo, se obtiene \\[\nf(1,1)=f(-1,-1)=2.\n\\]\nEste es el valor óptimo de la función objetivo en el conjunto factible (¿por qué?). En consecuencia, tanto \\((1,1)\\) como \\((-1,-1)\\) son puntos óptimos.\nObservar que este problema se puede interpretar geométricamente como el punto de la hipérbola \\(xy=1\\) más cercano al origen. Esto se deduce del hecho que la distancia de un punto \\((x,y)\\) al origen es \\[\n\\|(x,y)-(0,0)\\|_2=\\sqrt{x^2+y^2}.\n\\]\n\n\nLos ejemplos anteriores buscan conectar la idea de los problemas de optimización con los ejercicios clásicos de Cálculo, en los que se busca el valor mínimo (o máximo) de una función. Sin embargo, estudiar optimización no se limita a resolver este tipo de ejercicios, sino que implica aprender a formular problemas, comprender sus componentes fundamentales y desarrollar herramientas teóricas y computacionales para abordarlos, incluso cuando no tienen solución analítica o presentan múltiples soluciones.\nLa optimización matemática es una herramienta poderosa para tomar la mejor decisión posible al elegir un vector \\(\\xx\\) dentro de un conjunto de opciones, bajo ciertas restricciones que representan requisitos firmes, y buscando minimizar un costo o maximizar una utilidad. Algunas aplicaciones son:\n\nOptimización de portafolios financieros: Se busca la mejor manera de invertir un determinado capital entre distintos activos. La variable \\(x_i\\) representa la inversión en el \\(i\\)-ésimo activo, y las restricciones pueden representar un límite en el presupuesto, el requisito de que las inversiones sean no negativas y/o un valor mínimo aceptable de rendimiento esperado. La función objetivo podría ser una medida del riesgo total de la cartera.\nAjuste de modelos a datos (data fitting): La tarea es encontrar un modelo, dentro de una familia de modelos potenciales, que se ajuste mejor a un conjunto de datos observados. Aquí, las variables son los parámetros del modelo, y las restricciones pueden representar información previa o límites requeridos en los parámetros. La función objetivo puede ser una medida de error de predicción entre los datos observados y los valores predichos por el modelo.\nOptimización en logística: Se busca determinar la mejor forma de mover productos a través de una cadena de suministro o rutas de distribución. Las variables representan las cantidades transportadas entre diferentes puntos, y las restricciones pueden incluir la capacidad de los vehículos, los horarios de entrega y la demanda de los clientes. La función objetivo suele minimizar costos totales, tiempos de transporte o ambas cosas a la vez.\n\nEstas aplicaciones son solo una pequeña muestra de la enorme variedad de problemas prácticos que pueden plantearse como problemas de optimización, presentes en áreas como ingeniería, control automático, diseño, finanzas, logística, redes, entre otras.\n\n\n2 Mínimos cuadrados y programación lineal\nVamos a introducir dos subclases muy conocidas y ampliamente utilizadas de optimización convexa: los problemas de mínimos cuadrados y la programación lineal.\n\nDefinición 2. (Problema de mínimos cuadrados) Un problema de mínimos cuadrados es de la forma \\[\n\\begin{array}{ll}\n\\text{minimizar } & \\|A\\xx-\\bb\\|_2^2=\\sum_{i=1}^k(\\aa_i^{\\top}\\xx-b_i)^2,\n\\end{array}\n\\tag{2}\n\\] donde \\(A\\in\\RR^{k\\times n}\\) (\\(k\\geq n\\)), \\(\\aa_i^{\\top}\\) son las filas de \\(A\\) y \\(\\bb\\in\\RR^n\\).\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nEs un problema de optimización sin restricciones y su función objetivo es una suma de cuadrados de términos de la forma \\(\\aa_i^{\\top}\\xx-b_i\\).\nSe puede reducir a resolver un conjunto de ecuaciones lineales: \\[\n(A^{\\top}A)\\xx = A^{\\top}\\bb.\n\\] En consecuencia, tiene solución analítica: \\[\n\\xx^\\star=(A^{\\top}A)^{-1}A^{\\top}\\bb.\n\\]\nExisten algoritmos para resolver el problema con alta precisión, con un tiempo aproximadamente proporcional a \\(n^2k\\), con constante conocida.\nPara aumentar su flexibilidad en las aplicaciones, se utilizan varias técnicas estándar. Por ejemplo, en los mínimos cuadrados ponderados se minimiza \\[\n\\sum_{i=1}^k w_i(\\aa_i^{\\top}\\xx-b_i)^2,\n\\] donde \\(w_i\\) son pesos positivos. Otra técnica es la regularización, que consiste en agregar términos adicionales a la función objetivo para controlar ciertas propiedades de la solución. El caso más simple es \\[\n\\sum_{i=1}^{k}(\\aa_{i}^{\\top}\\xx - b_{i})^{2} + \\lambda \\sum_{i=1}^{n}x_{i}^{2}.\n\\] En el Capítulo 2 exploraremos con mayor detalle las técnicas de regularización y sus variantes.\n\n\n\n\n\n\nEjemplo 4\n\n\n\nDados los puntos \\((1,2)\\), \\((2,2.5)\\) y \\((3,3.7)\\), consideremos el problema de hallar la recta \\(y = mx + b\\) que mejor los aproxime en el sentido de mínimos cuadrados. Esto define en el problema \\[\n\\begin{array}{ll}\n\\text{minimizar } & \\sum_{i=1}^3 (m x_i + b - y_i)^2.\n\\end{array}\n\\]\nCuidado: las variables de optimización son los parámetros \\(m\\in\\RR\\) y \\(b\\in\\RR\\), mientras que \\((x_i,y_i)\\) son los datos conocidos. La función objetivo es la suma de los cuadrados de los errores (RSS). Matricialmente resulta en \\[\n\\begin{array}{ll}\n\\text{minimizar } & \\left\\|A\\begin{pmatrix}m\\\\b\\end{pmatrix}-\\yy\\right\\|_2^2.\n\\end{array}\n\\] con \\[\nA = \\begin{pmatrix}\n1 & 1\\\\\n2 & 1\\\\\n3 & 1\n\\end{pmatrix},\\qquad\n\\yy=\\begin{pmatrix}\n2\\\\\n2.5\\\\\n3.7\n\\end{pmatrix}.\n\\]\nLa solución analítica es \\[\n\\begin{pmatrix}\nm^{\\star}\\\\\nb^{\\star}\n\\end{pmatrix}=\\left[\\begin{pmatrix}\n1 & 1\\\\\n2 & 1\\\\\n3 & 1\n\\end{pmatrix}^{\\top}\\begin{pmatrix}\n1 & 1\\\\\n2 & 1\\\\\n3 & 1\n\\end{pmatrix}\\right]^{-1}\\begin{pmatrix}\n1 & 1\\\\\n2 & 1\\\\\n3 & 1\n\\end{pmatrix}^{\\top}\n\\begin{pmatrix}\n2\\\\\n2.5\\\\\n3.7\n\\end{pmatrix}\n= \\begin{pmatrix}\n17/20 \\\\\n31/30\n\\end{pmatrix}.\n\\]\nPor lo tanto, la recta ajustada es \\[\n\\hat{y} = \\frac{17}{20}x+\\frac{31}{30}.\n\\]\nEsto permite obtener el vector de valores ajustados \\[\n\\hat{\\yy}=\\begin{pmatrix}\n\\frac{17}{20}\\cdot 1+\\frac{31}{30}\\\\\n\\frac{17}{20}\\cdot 2+\\frac{31}{30}\\\\\n\\frac{17}{20}\\cdot 3+\\frac{31}{30}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n113/60\\\\\n51/30\\\\\n43/12\n\\end{pmatrix}\n\\approx\n\\begin{pmatrix}\n1.88\\\\\n2.73\\\\\n3.58\n\\end{pmatrix}.\n\\]\nPor último, calculamos el valor de la función objetivo, que interpretamos como el error del ajuste obtenido:\n\\[\n\\text{RSS}=\\|\\hat{\\yy}-\\yy\\|_2^2\\approx (1.88-2)^2+(2.73-2.5)^2+3.58-3.7)^2=0.0817.\n\\]\n\nEn Python, podemos resolver problemas de mínimos cuadrados con la función numpy.linalg.lstsq.\n\nimport numpy as np\n\n# Datos:\nx_data = np.array([1, 2, 3])\ny_data = np.array([2, 2.5, 3.7])\n\n# Matriz A:\nA = np.vstack([np.ones_like(x_data), x_data]).T\n\n# Resolución:\ncoeffs, residuals, rank, s = np.linalg.lstsq(A, y_data, rcond=None)\nb, m = coeffs  # Ordenamos como y = mx + b\n\nprint(f\"Recta ajustada: y = {m:.4f}x + {b:.4f}\")\nprint(f\"RSS: {residuals}\")\n\nRecta ajustada: y = 0.8500x + 1.0333\nRSS: [0.08166667]\n\n\n\n\n\nDefinición 3. (Programación lineal) Un problema de programación lineal es de la forma \\[\n\\begin{array}{ll}\n\\text{minimizar } & \\cc^{\\top}\\xx\\\\\n\\text{sujeto a } & \\aa_i^{\\top}\\xx\\leq b_i,\\quad i=1,\\ldots,m.\n\\end{array}\n\\tag{2}\n\\] donde \\(\\cc,\\aa_1,\\ldots,\\aa_m\\in\\RR^n\\) y \\(b_1,\\ldots,b_m\\in\\RR\\).\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nNo existe una fórmula analítica simple para la solución, pero hay una variedad de métodos muy efectivos para resolver el problema, como el método simplex de Datnzig y los métodos de punto interior.\nEn la práctica, la complejidad es del orden de \\(n^2m\\) (asumiento \\(m\\geq n\\)), pero con una constante que está menos caracterizada que en el caso de mínimos cuadrados.\nEn muchos casos, el problema de optimización original no tiene una forma estándar de programa lineal, pero puede transformarse en un programa lineal equivalente. Por ejemplo, el problema de aproximación de Chebyshev: \\[\n\\begin{array}{ll}\n\\text{minimizar } & \\max_{i=1,\\ldots,k} |\\aa_{i}^{\\top}\\xx- b_{i}|,\n\\end{array}\n\\] con variable \\(\\xx\\in\\RR^n\\), puede ser resuelto a través del programa lineal \\[\n\\begin{array}{ll}\n\\text{minimizar } & t\\\\\n\\text{sujeto a } & \\aa_i^{\\top}\\xx-t\\leq b_i,\\quad i=1,\\ldots,k\\\\\n    & -\\aa_i^{\\top}\\xx-t\\leq -b_i,\\quad i=1,\\ldots,k,\n\\end{array}\n\\] con variables \\(\\xx\\in\\RR^n\\) y \\(t\\in\\RR\\).\n\n\n\n\n\n\nEjemplo 5\nUna fábrica produce dos productos, en cantidades que definimos como \\(x_1\\) y \\(x_2\\), los cuales generan ganancias de 3 y 5 unidades monetarias, respectivamente. Producir una unidad de cualquiera de los productos requiere 1 hora de tiempo de producción. Además, la producción de una unidad del primer producto consume 1 unidad de materia prima, mientras que para producir una unidad del segundo producto se necesitan 3 unidades de materia prima. Queremos maximizar la ganancia, teniendo en cuenta que se dispone de 5 horas de producción y 9 unidades de materia prima.\nLa formulación del problema es\n\\[\n\\begin{array}{ll}\n\\text{maximizar } & 3x_1+5x_2\\\\\n\\text{sujeto a }  & x_1+x_2\\leq 5\\\\\n                  & x_1+3x_2\\leq 9\\\\\n                  & x_1\\geq 0, x_2\\geq 0\n\\end{array}\n\\]\nUna forma de obtener la solución gráficamente es analizando las curvas de nivel de la función objetivo \\(f(x_1,x_2)=3x_1+5x_2\\), las cuales tienen la particularidad de ser rectas paralelas. La idea es controlar el valor del nivel \\(z\\), con \\(z=3x_1+5x_2\\), e ir aumentándolo progresivamente sin salirse de la región factible, hasta alcanzar el último punto de contacto. Ese último punto de contacto es el punto óptimo, que como puede verse gráficamente es uno de los vértices definidos por el polígono factible.\n\n\n\nLa ganancia máxima es 19 y ocurre cuando \\(x_1=3\\) y \\(x_2=2\\).\nLa relación geométrica en este ejemplo no es casual: en programación lineal, el óptimo (si existe) se alcanza siempre en alguno de los vértices de la región factible. Este hecho constituye la base del método del simplex y de otros algoritmos clásicos.\n\nEn Python, se pueden resolver problemas de este tipo utilizando scipy.optimize.linprog.\n\nfrom scipy.optimize import linprog\n\n# Coeficientes de la función objetivo (negativos porque linprog minimiza):\nc = [-3, -5]\n\n# Coeficientes de las restricciones (Ax &lt;= b):\nA = [\n    [1, 1],    # x1 + x2 &lt;= 5\n    [1, 3]     # x1 + 3x2 &lt;= 9\n]\nb = [5, 9]\n\n# Restricciones de no negatividad:\nbounds = [(0, None), (0, None)]  # x1 &gt;= 0, x2 &gt;= 0\n\n# Resolución:\nres = linprog(c, A_ub=A, b_ub=b, bounds=bounds, method='highs')\n\nprint(\"Éxito:\", res.success)\nprint(\"x1 =\", res.x[0])\nprint(\"x2 =\", res.x[1])\nprint(\"Ganancia máxima =\", -res.fun)\n\nÉxito: True\nx1 = 3.0\nx2 = 2.0\nGanancia máxima = 19.0\n\n\n\n\n\n\n\n\n\nEjercicios\n\nDé ejemplos de problemas que haya resuelto en cursos anteriores que involucren maximizar o minimizar alguna cantidad. Para cada ejemplo, identifique sus elementos: función objetivo, variables de optimización, conjunto de restricciones.\nMuestre que efectivamente el problema de mínimos cuadrados se reduce a \\((A^{\\top} A)\\xx=A^{\\top}\\bb\\).\nReescriba el problema de mínimos cuadrados ponderados como un problema de mínimos cuadrados estándar.\nEjercicios de mínimos cuadrados.\nEjercicios de programación lineal.\n\n\n\n\n\nReferencias\nBoyd, S., & Vandenberghe, L. (2004). Convex Optimization. Capítulo 1. Cambridge University Press.\nFarina, G. Apuntes del curso MIT 6.7220: Nonlinear Optimization. Lección 1(2025). Disponible en la página del curso.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.1 Introducción a la optimización"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html",
    "title": "Optimización convexa",
    "section": "",
    "text": "En esta sección nos enfocaremos en los conceptos fundamentales que sustentan la optimización convexa, una rama central en la teoría y práctica de la optimización. A partir de las ideas presentadas en la Introducción, donde destacamos el rol de la convexidad, ahora desarrollaremos con mayor profundidad las nociones teóricas que permiten formular y analizar este tipo de problemas.\nPrimero repasaremos las definiciones clave relacionadas con la convexidad, incluyendo conjuntos convexos y funciones convexas. Luego, utilizaremos estas definiciones para precisar qué entendemos por un problema de optimización convexa. Más adelante, en Capítulo 1 - Sección 4, estos conceptos serán claves para establecer las condiciones de optimalidad que caracterizan a este tipo de problemas.\nlibrary(shiny)\n\nx &lt;- c(1,4)\ny &lt;- c(2,3)\n\nui &lt;- fluidPage(\n  sliderInput(\"theta\", \"θ\", min = 0, max = 1, value = 0.5, step = 0.01),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output, session) {\n  output$plot &lt;- renderPlot({\n    theta &lt;- input$theta\n    x_point &lt;- theta * x[1] + (1 - theta) * x[2]\n    y_point &lt;- theta * y[1] + (1 - theta) * y[2]\n\n    plot(x, y, type = \"b\", lty = 2, col = \"gray\", xlim = c(0,5), ylim = c(0,5),\n         main = paste(\"θ =\", round(theta,2)))\n    points(x_point, y_point, col = \"green\", pch = 19, cex = 2)\n  })\n}\n\nshinyApp(ui, server)\n\nShiny applications not supported in static R Markdown documents",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html#definiciones-básicas",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html#definiciones-básicas",
    "title": "Optimización convexa",
    "section": "1.1 Definiciones básicas",
    "text": "1.1 Definiciones básicas\nEn esta sección introduciremos tres tipos fundamentales de conjuntos que aparecen en optimización: conjuntos afines, conjuntos convexos y conos. Antes, es necesario recordar la forma parámetrica de rectas y segmentos de recta.\nSean \\(\\xx_{1} \\neq \\xx_{2}\\) dos puntos en \\(\\RR^{n}\\). La recta que pasa por \\(\\xx_1\\) y \\(\\xx_2\\) queda determinada por \\[\n\\yy = \\theta \\xx_{1} + (1 - \\theta) \\xx_{2},\\qquad \\theta\\in\\RR.\n\\]\nMientras que, si restringimos el valor del parámetro a \\(0\\leq \\theta\\leq 1\\), obtenemos el segmento de recta (cerrado) entre ambos puntos. Una expresión alternativa es\n\\[\n\\yy=\\xx_2+\\theta(\\xx_1-\\xx_2),\n\\]\nla cual permite interpretar a \\(\\yy\\) en términos del punto inicial \\(\\xx_2\\) y la dirección \\(\\xx_1-\\xx_2\\). Así, \\(\\theta\\) indica la fracción del camino desde \\(\\xx_2\\) hasta \\(\\xx_1\\) donde se encuentra \\(\\yy\\).\n\n\n\nRecta que pasa por dos puntos.\n\n\n\n\n1.1.1 Conjuntos afines\n\nDefinición 1. (Conjunto afín) Un conjunto \\(C \\subseteq \\RR^{n}\\) es afín si la línea que pasa por cualquier par de puntos distintos en \\(C\\) está contenida en \\(C\\). Es decir, si se verifica \\[\n\\theta \\xx_1+(1-\\theta)\\xx_2\\in C\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall\\theta\\in\\RR.\n\\]\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nLa expresión \\(\\theta \\xx_1+(1-\\theta)\\xx_2\\) es una combinación lineal entre los puntos \\(\\xx_1\\) y \\(\\xx_2\\) que verifica que la suma de sus coeficientes sea uno. Esta idea se puede generalizar a más de dos puntos: un punto de la forma \\[\n\\theta_1\\xx_1+\\cdots+\\theta_k\\xx_k,\\qquad \\sum_{i=1}^k\\theta_i=1\n\\] se denomina combinación afín de los puntos \\(\\xx_1,\\ldots,\\xx_k\\). Es fácil ver que un conjunto afín \\(C\\) contiene todas las combinaciones afines de sus puntos.\nDado un conjunto afín \\(C\\) y un punto \\(\\xx_0\\in C\\), el conjunto \\[\nV:= C-\\xx_0=\\{\\xx-\\xx_0 \\mid \\xx\\in C\\}\n\\] es un subespacio vectorial, que permite expresar el conjunto afín \\(C\\) como \\[\nC=V+\\xx_0=\\{v+\\xx_0 \\mid v\\in V\\}.\n\\] El subespacio \\(V\\) asociado con el conjunto afín \\(C\\) no depende de la elección de \\(x_{0}\\), por lo que \\(x_{0}\\) puede elegirse como cualquier punto en \\(C\\). Definimos la dimensión de \\(C\\) como \\[\n\\dim C:=\\dim V=\\dim C-\\xx_0,\\quad \\xx_0\\in C.\n\\]\n\n\n\n\n\n\n\n1.1.2 Conjuntos convexos\n\nDefinición 2. (Conjunto convexo) Un conjunto \\(C \\subseteq \\RR^{n}\\) es convexo si el segmento de línea entre cualquier par de puntos distintos en \\(C\\) está contenido en \\(C\\). Es decir, si se verifica \\[\n\\theta \\xx_1+(1-\\theta)\\xx_2\\in C\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall\\theta\\in[0,1].\n\\]\n\nClaramente, todo conjunto afín también es convexo, ya que contiene toda la recta que pasa por cualquier par de puntos distintos en él y, por lo tanto, también el segmento de línea entre los puntos.\n\n\n\nConjuntos en \\(\\RR^2\\). Únicamente el hexágono, que incluye su frontera, es convexo.\n\n\n\nLlamamos combinación convexa a un punto de la forma \\[\n\\theta_{1} \\xx_{1} + \\cdots + \\theta_{k} \\xx_{k},\\qquad \\sum_{i=1}^k\\theta_i = 1, \\theta_{i} \\geq 0.\n\\]\nA diferencia de una combinación afín, una combinación convexa requiere la no negatividad de los coeficientes \\(\\theta_i\\), lo cual significa que puede ser interpretada como un promedio ponderado de los puntos \\(\\xx_i\\).\n\nDefinición 3. (Envolvente convexa) La envolvente convexa de un conjunto \\(C\\) es el conjunto de todas las combinaciones convexas de puntos en \\(C\\). Esto es \\[\n\\text{conv}\\, C = \\left\\{\\theta_{1} x_{1} + \\cdots + \\theta_{k} x_{k}\\;\\Big|\\; x_{i} \\in C, \\theta_{i} \\geq 0, \\sum_{i=1}^k\\theta_{i} = 1\\right\\}.\n\\]\n\nComo su nombre lo indica, la envolvente convexa \\(\\text{conv}\\, C\\) es siempre un conjunto convexo. Más aún, es el conjunto convexo más pequeño que contiene a \\(C\\): si \\(B\\) es cualquier conjunto convexo que contiene a \\(C\\), entonces \\(\\text{conv}\\, C \\subseteq B\\).\n\n\n\nEnvolvente convexa de dos conjuntos: (Izq.) La envolvente convexa de un numero finito de puntos. (Der.) La envolvente convexa de un conjunto infinito no convexo.\n\n\n\n\n\n1.1.3 Conos\n\nDefinición 4. (Cono) Un conjunto \\(C\\in\\RR^n\\) se denomina cono si verifica \\[\n\\theta\\xx\\in C,\\qquad\\forall \\xx\\in C, \\forall \\theta\\geq 0.\n\\]\n\nUn conjunto \\(C\\) es un cono convexo si es convexo y es un cono, lo que significa que \\[\n\\theta_1\\xx_1+\\theta_2\\xx_2\\in C,\\qquad\\forall \\xx_1,\\xx_2\\in C, \\forall \\theta_1, \\theta_2\\geq 0.\n\\]\n\n\n\nConjunto de puntos de la forma \\(\\theta_1\\xx_1+\\theta_2\\xx_2\\) para \\(\\xx_1,\\xx_2\\in\\RR^2\\).\n\n\n\nLlamamos combinación cónica a un punto de la forma \\[\n\\theta_1\\xx_1+\\cdot+\\theta_k\\xx_j,\\qquad \\theta_i\\geq 0.\n\\]\n\nDefinición 5. (Envolvente cónica) La envolvente cónica de un conjunto \\(C\\) es el conjunto de todas las combinaciones cónicas de puntos en \\(C\\). Esto es \\[\n\\text{cone}\\, C = \\left\\{\\theta_{1} \\xx_{1} + \\cdots + \\theta_{k} \\xx_{k}\\;\\Big|\\; x_{i} \\in C, \\theta_{i} \\geq 0\\right\\}.\n\\]\n\nDe manera análoga a la envolvente convexa, la envolvente cónica de un conjunto \\(C\\) es el conjunto de todas las combinación cónicas de puntos en \\(C\\) y, además, es el cono convexo más pequeño que contiene a \\(C\\).\n\n\n\nEnvolvente cónica de dos conjuntos: (Izq.) La envolvente convexa de un numero finito de puntos. (Der.) La envolvente convexa de un conjunto infinito no convexo.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html#operaciones-que-preservan-convexidad",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html#operaciones-que-preservan-convexidad",
    "title": "Optimización convexa",
    "section": "1.2 Operaciones que preservan convexidad",
    "text": "1.2 Operaciones que preservan convexidad\nEn esta sección describimos algunas operaciones que preservan la convexidad de conjuntos o nos permiten construir conjuntos convexos a partir de otros. Estas operaciones, junto con los ejemplos simples descritos anteriormente, forman un cálculo de conjuntos convexos que es útil para determinar o establecer la convexidad de conjuntos. Las verificaciones se dejan como ejercicio.\n\nIntersección. Si \\(S_{1}\\) y \\(S_{2}\\) son convexos, entonces \\(S_{1} \\cap S_{2}\\) es convexo. Esta propiedad se extiende a la intersección de un número infinito de conjuntos: si \\(S_{\\alpha}\\) es convexo para cada \\(\\alpha \\in \\mathcal{A}\\), entonces \\(\\bigcap_{\\alpha \\in \\mathcal{A}} S_{\\alpha}\\) es convexo. Como ejemplo simple, un poliedro es la intersección de semiespacios e hiperplanos (que son convexos), y por lo tanto es convexo.\nFunciones afínes. Si \\(S\\subset \\RR^{n}\\) es convexo y \\(f: \\mathbf{R}^{n} \\to \\mathbf{R}^{m}\\) es una función afín, entonces, la imagen de \\(S\\) bajo \\(f\\), \\(f(S) := \\{f(\\xx) \\mid \\xx \\in S\\}\\), es convexa. De manera similar, si \\(f: \\RR^{k} \\to \\RR^{n}\\) es una función afín, la imagen inversa de \\(S\\) bajo \\(f\\), \\(f^{-1}(S) := \\{\\xx \\mid f(\\xx) \\in S\\}\\), es convexa.\n\n\\(f:\\RR^n\\to\\RR^m\\) es afín si es de la forma \\(f(\\xx)=A\\xx+\\bb\\), con \\(A\\in\\RR^{n\\times m}\\) y \\(\\bb\\in\\RR^m\\).\n\nSuma. Si \\(S_1\\) y \\(S_2\\) son conjuntos convexos de \\(\\RR^n\\), entonces \\[\nS_{1} + S_{2} := \\{\\xx_1 + \\xx_2 \\mid \\xx_1 \\in S_{1}, \\xx_2 \\in S_{2}\\}\n\\] es un conjunto convexo.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html#conos-normales",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html#conos-normales",
    "title": "Optimización convexa",
    "section": "1.3 Conos normales",
    "text": "1.3 Conos normales\nEn muchos problemas de optimización, especialmente aquellos en los que las soluciones están restringidas a un conjunto convexo, es esencial entender cómo se comportan las direcciones “externas” al conjunto en torno a un punto dado.\nEl cono normal es una herramienta geométrica fundamental para describir esas direcciones. Nos permitirá luego expresar condiciones que caracterizan soluciones óptimas a partir de información local del conjunto factible.\n\nDefinición 6. (Cono normal) Sean \\(\\Omega\\subset\\RR^n\\) un conjunto convexo y \\(\\xx_0\\in\\Omega\\). El cono normal de \\(\\Omega\\) en \\(\\xx\\) se define como \\[\n\\mathcal{N}_{\\Omega}(\\xx_0) := \\{\\dd\\in\\RR^n \\mid \\langle\\dd,\\xx-\\xx_0\\rangle\\leq 0, \\forall\\xx\\in\\Omega\\}.\n\\]\n\n\n\n\nConos normales de un conjunto convexo.\n\n\n\nPara entender esta definición, vamos a ver algunos ejemplos.\n\nEjemplo 1 (Cono normal a un punto interior) Si \\(\\xx_0\\) es un punto interior de \\(\\Omega\\), el cono normal contiene únicamente el vector cero. Es decir,\n\\[\nN_{\\Omega}(\\xx_0) = \\{\\mathbf{0}\\}.\n\\]\n\n\nLa prueba es sencilla: si \\(\\dd\\neq\\mathbf{0}\\), entonces podemos tomar un \\(\\delta&gt;0\\) lo suficientemente pequeño para que \\(\\xx=\\xx_0+\\delta\\dd\\in\\Omega\\); resulta \\(\\dd\\notin\\mathcal{N}_{\\Omega}(\\xx_0)\\) ya que \\[\n\\langle \\dd,\\xx-\\xx_0\\rangle=\\langle\\dd,\\delta\\dd\\rangle=\\delta\\|\\dd\\|^2\\geq 0.\n\\]\n\n\n\n\n\n\n\n\nEjemplo 2 (Cono normal a un hiperplano) Sea \\(\\aa\\in\\RR^n\\), \\(\\aa\\neq\\mathbf{0}\\), Definimos el hiperplano \\[\n\\Omega:=\\{\\xx\\in\\RR^n \\mid \\langle\\aa,\\xx\\rangle=0\\}.\n\\]\n\n\nEl cono normal a un punto \\(\\xx_0\\in\\Omega\\) es la recta con dirección \\(\\aa\\). Esto es, \\[\n\\mathcal{N}_{\\xx_0}(\\Omega)=\\{\\lambda\\aa \\mid \\lambda\\in\\RR\\}.\n\\]\nLa verificación se deja como ejercicio.\n\n\n\n\n\n\nDado que los conos normales son insensibles a desplazamientos en el conjunto \\(\\Omega\\), este resultado se aplica sin cambios a cualquier plano afín \\(\\Omega:=\\{\\xx\\in\\RR^n \\mid \\langle\\aa,\\xx\\rangle=b\\}\\), con \\(b\\in\\RR\\).\n\n\nEjemplo 3 (Cono normal a un semiespacio) Sean \\(\\aa\\in\\RR^n\\), \\(\\aa\\neq\\mathbf{0}\\), y \\(b\\in\\RR\\). Definimos el semiplano \\[\n\\Omega:=\\{\\xx\\in\\RR^n \\mid \\langle\\aa,\\xx\\rangle\\leq b\\}.\n\\]\n\n\n\nSi \\(\\xx_0\\) está en el interior de \\(\\Omega\\), \\(\\langle\\aa,\\xx_0\\rangle&lt;b\\), el cono normal es \\(\\mathcal{N}_{\\Omega}(\\xx_0)=\\{\\mathbf{0}\\}\\).\nSi \\(\\xx_0\\) está en la frontera de \\(\\Omega\\), \\(\\langle\\aa,\\xx_0\\rangle=b\\), resulta \\[\n\\mathcal{N}_{\\xx_0}(\\Omega)=\\{\\lambda\\aa \\mid \\lambda\\in\\RR_0^+\\}.\n\\] La diferencia con el ejemplo anterior radica en que ahora el cono normal es una semirrecta.\n\n\n\n\n\n\n\n\n\nEjemplo 4 (Cono normal a la intersección de dos semiespacios) Sean \\(\\aa_1,\\aa_2\\in\\RR^n\\) no nulos, y \\(b_1,b_2\\in\\RR\\). Definimos la intersección de dos semiplanos como \\[\n\\Omega:=\\{\\xx\\in\\RR^n \\mid \\langle\\aa_1,\\xx\\rangle\\leq b_1\\quad\\text{y}\\quad\\langle\\aa_2,\\xx\\rangle\\leq b_2\\}.\n\\]\n\n\n\nSi \\(\\xx_0\\) está en el interior de \\(\\Omega\\) o en la frontera de solo uno de los semiespacios, el cono normal resulta del ejemplo anterior.\nSi \\(\\xx_0\\) está en la intersección de ambas fronteras, \\(\\langle\\aa_1,\\xx_0\\rangle=b_1\\) y \\(\\langle\\aa_2,\\xx_0\\rangle =b_2\\), entonces el cono normal es la envolvente cónica de las direcciones \\(\\aa_1\\) y \\(\\aa_2\\). Esto es \\[\n\\mathcal{N}_{\\Omega}(\\xx_0)=\\{\\lambda_1\\aa_1+\\lambda_2\\aa_2 \\mid \\lambda_1,\\lambda_2\\in\\RR_0^+\\}.\n\\]\n\n\n\n\n\n\n\nEste resultado puede generalizarse al caso de \\(m\\) subespacios. El cono normal estará dado por las direcciones de los hiperplanos cuyas fronteras contengan al punto \\(\\xx_0\\).",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html#condiciones-de-convexidad",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html#condiciones-de-convexidad",
    "title": "Optimización convexa",
    "section": "2.1 Condiciones de convexidad",
    "text": "2.1 Condiciones de convexidad\nPara verificar si una función es convexa, además de recurrir a la definición, existen criterios basados en sus derivadas. Estos permiten caracterizar la convexidad en términos del comportamiento local de la función, ya sea a través del gradiente (primera derivada) o de la matriz hessiana (segunda derivada). Para ello, debemos imponer condiciones a \\(f\\) en relación con su diferenciabilidad.\n\nImportante\nDiremos que \\(f\\) es diferenciable si su gradiente \\(\\nabla f\\) existe en todo su dominio, y que es dos veces diferenciable si además su hessiana \\(\\nabla^2 f\\) existe en todo el dominio. En ambos casos, asumimos que dicho dominio es un conjunto abierto.\n\n\nTeorema 1. (Condición de primer orden para convexidad) Sea \\(f:\\RR^n\\to\\RR\\) una función diferenciable. \\(f\\) es convexa si y solo si \\(\\text{dom}\\,f\\) es convexo y \\[\nf(\\xx_2)\\geq f(\\xx_1)+\\langle\\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle,\\qquad\\forall\\xx_1,\\xx_2\\in\\text{dom}\\,f.\n\\]\n\n\n\nMostrar detalles\n\n\nInterpretación geométricaObservacionesDemostración\n\n\nLa función afín de \\(\\xx_2\\), definida por \\(f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\\), es la aproximación lineal de \\(f\\) cerca de \\(\\xx_1\\). En consecuencia, la desigualdad del teorema implica que la aproximación lineal de \\(f\\) en \\(\\xx_1\\) es un subestimador global de \\(f\\).\n\n\n\nGrafo de una función convexa \\(f\\) y su aproximación lineal.\n\n\n\n\n\nObservar que, si \\(\\nabla f(\\xx_1) = 0\\), entonces la desigualdad del teorema implica \\(f(\\xx_2) \\geq f(\\xx_1)\\) para todo \\(\\xx_2 \\in \\text{dom} f\\). Es decir, en tal caso \\(\\xx_1\\) es un minimizador global de la función \\(f\\).\nLa convexidad estricta también puede caracterizarse por una condición de primer orden: \\(f\\) es estrictamente convexa si y solo si \\(\\text{dom} f\\) es convexo y \\[\nf(\\xx_2) &gt; f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\n\\] para todo \\(\\xx_1, \\xx_2 \\in \\text{dom} f\\), con \\(\\xx_1 \\neq \\xx_2\\).\nPara funciones cóncavas, tenemos la caracterización correspondiente: \\(f\\) es cóncava si y solo si \\(\\text{dom} f\\) es convexo y \\[\nf(\\xx_2) \\leq f(\\xx_1) + \\langle \\nabla f(\\xx_1), \\xx_2 - \\xx_1 \\rangle\n\\] para todo \\(\\xx_1, \\xx_2 \\in \\text{dom} f\\).\n\n\n\nSupongamos que \\(f\\) es convexa y sean \\(\\xx_1,\\xx_2\\in\\text{dom}\\,f\\). Entonces, por definición, \\(\\text{dom}\\,f\\) es convexo; en consecuencia \\(\\xx_1+t(\\xx_2-\\xx_1)\\in\\text{dom}\\,f\\) para todo \\(0&lt;t\\leq 1\\). La convexidad de \\(f\\) nos permite escribir\n\\[\nf(\\xx_1+t(\\xx_2-\\xx_1))=f((1-t)\\xx_1+t\\xx_2)\\leq (1-t)f(\\xx_1)+tf(\\xx_2).\n\\]\nDiviendo ambos lados de la desigualdad por \\(t\\), resulta\n\\[\nf(\\xx_2)\\geq f(\\xx_1)+\\frac{f(\\xx_1+t(\\xx_2-\\xx_1))-f(\\xx_1)}{t}.\n\\]\nAl tomar límite cuando \\(t\\to 0\\), el cociente incremental del lado derecho es la derivada direccional de \\(f\\) en \\(\\xx_1\\) en la dirección del vector \\(\\xx_2-\\xx_1\\), lo cual es equivalente a \\(\\langle \\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle\\) en virtud de la diferenciabilidad de \\(f\\). Luego,\n\\[\nf(\\xx_2)\\geq f(\\xx_1)+\\langle\\nabla f(\\xx_1),\\xx_2-\\xx_1\\rangle.\n\\]\nPara probar la suficiencia, vamos a asumir que sí se cumple para funciones de una variable (se deja como ejercicio). Sean \\(\\xx_1,\\xx_2\\in\\text{dom}\\,f\\) y \\(t,\\tilde{t}\\in(0,1]\\). Partimos de la desigualdad\n\\[\nf(t\\xx_2+(1-t)\\xx_1)\\geq f(\\tilde{t}\\xx_2+(1-\\tilde{t})\\xx_1)+\\langle \\nabla f(\\tilde{t}\\xx_2+(1-\\tilde{t})\\xx_1),(\\xx_2-\\xx_1)\\rangle (t-\\tilde{t}).\n\\]\nSi restringimos \\(f\\) a la recta entre \\(\\xx_1\\) y \\(\\xx_2\\), tenemos la función de una variable \\(g(t)=f(t\\xx_2+(1-t)\\xx_1)\\). Por regla de la cadena, tenemos \\(g'(t)\\langle \\nabla f(t\\xx_2+(1-t)\\xx_1),\\xx_2-\\xx_1\\rangle\\). En consecuencia, la desigualdad anterior puede reescribirse como\n\\[\ng(t)\\geq g(\\tilde{t})+g'(\\tilde{t})(t-\\tilde{t}).\n\\]\nLuego, \\(g\\) es convexa y, dado que la restricción sobre una recta es arbitraria (ver observaciones de la definición de funciones convexas), \\(f\\) es convexa. \\(\\blacksquare\\)\n\n\n\n\n\nTeorema 2. (Condición de segundo orden para convexidad) Sea \\(f:\\RR^n\\to\\RR\\) una función dos veces diferenciable. \\(f\\) es convexa si y solo si \\(\\text{dom}\\,f\\) es convexo y \\[\n\\nabla^2 f(\\xx)\\succeq 0,\\qquad\\forall\\xx\\in\\text{dom}\\,f.\n\\]\n\n\n\\(A\\succeq 0\\) significa que \\(A\\) es semidefinida positiva. Esto es, \\(\\xx^\\top A\\xx\\geq 0\\) para todo \\(\\xx\\in\\RR^n\\).\n\n\n\nMostrar detalles\n\n\nObservaciones\n\n\n\nPara funciones de una variable, la condición se reduce a \\(f''(x)\\geq 0\\), lo cual implica que la derivada \\(f'(x)\\) es no decreciente.\nLa convexidad estricta también puede caracterizarse por una condición de primer orden, pero de manera parcial: si \\(\\text{dom}\\,f\\) es convexo y \\(\\nabla^2 f\\succ 0\\) para todo \\(\\xx\\in\\text{dom}\\,f\\), entonces \\(f\\) es estrictamente convexa. El recíproco no es cierto: por ejemplo, \\(f(x)=x^4\\) es estrictamente convexa pero \\(f''(0)=0\\).\nPara funciones cóncavas, tenemos la caracterización correspondiente: \\(f\\) es cóncava si y solo si \\(\\text{dom} f\\) es convexo y \\(\\nabla^2 f(\\xx)\\preceq 0\\) para todo \\(\\xx\\in\\text{dom}\\,f\\).\n\n\n\n\n\n\nEjemplo 5 Consideremos la función cuadrática \\(f:\\RR^n\\to\\RR\\) definida por\n\\[\nf(\\xx)=\\frac{1}{2}\\xx^\\top A\\xx+\\bb^\\top\\xx+c,\n\\]\ndonde \\(A\\in\\SS^n:=\\{X\\in\\RR^{n\\times n} \\mid X=X^\\top\\}\\), \\(\\bb\\in\\RR^n\\) y \\(c\\in\\RR\\). Dado que \\(\\nabla^2 f(\\xx)=A\\) para todo \\(\\xx\\), podemos afirmar que \\(f\\) es convexa si y sólo si \\(A\\succeq 0\\).\nAsí, por ejemplo, la función \\(f:\\RR^2\\to\\RR\\) definida por\n\\[\nf(x,y)=\\frac{1}{2}\\begin{pmatrix}x&y\\end{pmatrix}\\begin{pmatrix}2&1\\\\1&3\\end{pmatrix}\\begin{pmatrix}x\\\\ y\\end{pmatrix}=\\frac{1}{2}(2x^2+2xy+3y^2)\n\\]\nes convexa, ya que \\(\\xx^\\top A\\xx=2x^2+2xy+3y^2=x^2+(x+y)^2+2y^2\\geq 0\\) para todo \\(\\xx\\in\\RR^n\\), lo cual significa que \\(A\\succeq 0\\).\n\n\nMostrar código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D  # para 3D\n\n# Definir la matriz A (simétrica)\nA = np.array([[2, 1],\n              [1, 3]])\n\n# Crear una malla de puntos en R^2\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\n\n# Evaluar la función f(x) = 1/2 x^T A x\nZ = 0.5 * (A[0,0]*X**2 + (A[0,1] + A[1,0])*X*Y + A[1,1]*Y**2)\n\n# Graficar\nfig = plt.figure(figsize=(8,6))\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A2_optimizacion_convexa.html#operaciones-que-preservan-convexidad-1",
    "href": "CAPITULO_1/A2_optimizacion_convexa.html#operaciones-que-preservan-convexidad-1",
    "title": "Optimización convexa",
    "section": "2.2 Operaciones que preservan convexidad",
    "text": "2.2 Operaciones que preservan convexidad\nEn esta sección describimos algunas operaciones que preservan la convexidad o concavidad de funciones, o que permiten construir nuevas funciones convexas y cóncavas. Las verificaciones se dejan como ejercicio.\n\nSumas ponderadas no negativas. Si \\(f\\) es una función convexa y \\(\\alpha \\geq 0\\), entonces la función \\(\\alpha f\\) es convexa. Si \\(f_1\\) y \\(f_2\\) son ambas funciones convexas, entonces su suma \\(f_1 + f_2\\) también lo es. Combinando estas dos propiedades, se obtiene que el conjunto de funciones convexas es en sí mismo un cono convexo: una suma ponderada no negativa de funciones convexas, \\[\nf = w_1 f_1 + \\cdots + w_m f_m,\n\\] es convexa. De manera similar, una suma ponderada no negativa de funciones cóncavas es cóncava.\nComposición con una aplicación afín. Sean \\(f:\\RR^n\\to\\RR\\), \\(A\\in\\RR^{n\\times m}\\) y \\(\\bb\\in\\RR^n\\). Definimos \\(g:\\RR^m\\to\\RR\\) como \\[\ng(\\xx):=f(A\\xx+\\bb)\n\\] con \\(\\text{dom}\\,g = \\{\\xx \\mid A\\xx + \\bb \\in \\text{dom}\\, f\\}\\). Entonces, \\(g\\) conserva la convexidad o concavidad de \\(f\\).\nMáximo puntual. Si \\(f_1\\) y \\(f_2\\) son funciones convexas, entonces su máximo puntual \\(f\\), definido por \\[\nf(\\xx) = \\max\\{f_1(\\xx), f_2(\\xx)\\},\n\\] con \\(\\text{dom}\\,f = \\text{dom}\\,f_1 \\cap \\text{dom}\\,f_2\\), también es convexa. Además, este resultado se puede extender a: si \\(f_1,\\dots,f_m\\) son funciones convexas, entonces su máximo puntual, definido por \\(f(\\xx)=\\max\\{f_1(\\xx), \\ldots, f_m(\\xx)\\}\\), también lo es.\nSupremo puntual. La propiedad del máximo puntual se extiende al supremo puntual sobre un conjunto infinito de funciones convexas. Si para $i, donde \\(\\mathcal{A}\\) es un conjunto de índices, se tiene que \\(f_i(\\xx)\\) es convexa, entonces la función \\(f\\) definida por \\[\nf(\\xx) = \\sup_{i \\in \\mathcal{A}} f_i(\\xx)\n\\] también es convexa en \\(\\xx\\). Aquí, el dominio de \\(f\\) es \\[\n\\text{dom}\\, f = \\{\\xx \\mid \\xx \\in \\text{dom}\\, f_i \\text{ para todo } i \\in \\mathcal{A}, \\sup_{i \\in \\mathcal{A}} f_i(\\xx) &lt; \\infty\\}.\n\\] De manera similar, el ínfimo puntual de un conjunto de funciones cóncavas es una función cóncava.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.2 Optimización convexa"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html",
    "title": "Condiciones de optimalidad",
    "section": "",
    "text": "En un problema de optimización general \\[\n\\min_{x} f(x)\n\\] \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\ng_i(x)\\leq 0,& i=1,\\cdots,r.\\\\\nh_j(x)=0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\nlas condiciones de optimalidad definen los requisitos que deben cumplir los puntos óptimos. En lo que sigue, asumiremos que trabajamos con funciones diferenciables.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#optimización-sin-restricciones",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#optimización-sin-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "1.1 Optimización sin restricciones",
    "text": "1.1 Optimización sin restricciones\nDe cursos anteriores recordemos que, cuando se pretende optimizar una función \\(f\\) respecto a \\(x\\in\\RR^n\\), una condición necesaria para que un punto sea óptimo es que verifique \\[\n\\nabla f(x)=\\mathbf{0}.\n\\]\nPero cuidado: es solo una condición necesaria que todos los puntos óptimos deben cumplir, pero no implica que cualquier punto que la satisfaga sea automáticamente óptimo. En otras palabras, las soluciones de \\(\\nabla f(x) = 0\\) forman una lista de puntos candidatos para minimizar, llamados puntos críticos.\nDe inmediato surgen dos preguntas claves:\n\n¿Cuál es la generalización correcta de la condición necesaria \\(\\nabla f(x) = 0\\) cuando enfrentamos un problema de optimización con restricciones?\n¿Bajo qué circunstancias \\(\\nabla f(x) = 0\\) también se convierte en una condición suficiente para la optimalidad?\n\nAntes, veamos cómo surge la condición \\(\\nabla f(x)=\\mathbf{0}\\) para problemas de optimización sin restricciones.\n\n1.1.1 Prueba de condición necesaria \\(\\nabla f(x)=\\mathbf{0}\\)\nSea \\(x\\in\\RR^n\\) es un minimizador de la función \\(f: \\RR^n \\to \\RR\\) y sea \\(d\\in\\RR^n\\) una dirección arbitraria. Entonces se cumple\n\\[\nf(x + t \\cdot d) \\geq f(x) \\quad \\text{para todo } t \\geq 0.\n\\]\nEn consecuencia, la derivada direccional de \\(f\\) en \\(x\\) a lo largo de \\(d\\) es\n\\[\n\\frac{\\partial f}{\\partial d}(x)= \\lim_{t \\to 0} \\frac{f(x + t \\cdot d) - f(x)}{t} \\geq 0.\n\\]\nAhora bien, como \\(f\\) es diferenciable, se verifica la propiedad \\(\\frac{\\partial f}{\\partial d}(x)=\\langle \\nabla f(x),d\\rangle\\), por lo que la desigualdad anterior se puede reescribir como:\n\\[\n\\langle \\nabla f(x), d \\rangle \\geq 0 \\quad \\forall d \\in {R}^n.\n\\]\nEn particular, eligiendo \\(d = -\\nabla f(x)\\), resulta \\(-\\|\\nabla f(x)\\|^2\\geq 0\\), lo cual es cierto si y sólo si \\(\\nabla f(x)=\\mathbf{0}\\).",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#optimización-con-restricciones",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#optimización-con-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "1.2 Optimización con restricciones",
    "text": "1.2 Optimización con restricciones\nLa clave para generalizar la condición \\(\\nabla f(x)=\\mathbf{0}\\) al caso de optimización con restricciones surge de la prueba anterior, más precisamente de la desigualdad \\(\\langle\\nabla f(x),d\\rangle\\geq 0\\).\nLa diferencia principal con el caso sin restricciones es que, en un conjunto restringido, podríamos estar limitados en la elección de las direcciones \\(d\\) a lo largo de las cuales podemos aproximarnos a \\(x\\) sin salirnos del conjunto.\nNo obstante, para cualquier dirección \\(d\\) tal que \\(x + t \\cdot d \\in \\Omega\\) para todo \\(t \\geq 0\\) suficientemente pequeño, el mismo argumento aplicado anteriormente sigue siendo válido. Por lo tanto, podemos concluir que necesariamente:\n\\[\n\\langle \\nabla f(x), d \\rangle \\geq 0 \\quad \\text{para todo } d \\in  {R}^n \\text{ que permanezca en } \\Omega \\text{ desde } x.\n\\]\nPara aplicar esta condición, se requieren dos pasos:\n\nDeterminar el conjunto de direcciones \\(d\\) que permanecen en \\(\\Omega\\) desde \\(x\\)*.\nA partir de esas direcciones, ver de qué manera imponen restricciones sobre \\(\\nabla f(x)\\).\n\nDe estos dos pasos, el primero suele ser el más sencillo. En todos los casos de interés, podemos determinar el conjunto de direcciones permitidas simplemente considerando cualquier otro punto \\(y \\in \\Omega\\) y observando la dirección de \\(x\\) a \\(y\\). Esta propiedad se cumple trivialmente si todos los segmentos de línea entre \\(x\\) y cualquier punto en \\(\\Omega\\) están contenidos en \\(\\Omega\\), lo cual es siempre cierto para conjuntos convexos.\n\nTeorema 1. (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo) Sea \\(\\Omega \\subseteq  {R}^n\\) convexo y sea \\(f:  {R}^n \\to  {R}\\) una función diferenciable. Si \\(x \\in \\Omega\\) es un minimizador de \\(f\\) sobre \\(\\Omega\\), entonces \\[\n\\langle \\nabla f(x), y - x \\rangle \\geq 0 \\quad \\forall y \\in \\Omega.\n\\]\n\n\n\nInterpretación geométrica\n\n\nLa condición del Teorema 1 se verifica si el vector gradiente de \\(f\\) en una solución \\(x\\in\\Omega\\) forma un ángulo agudo con todas las direcciones \\(y-x\\), donde \\(y\\in\\Omega\\).\nAhora bien, a la hora de buscar un minimizador, la dirección que realmente nos importa es \\(-\\nabla f(x)\\). Así, el Teorema 1 nos dice que \\(-\\nabla f(x)\\) debe formar un ángulo obtuso con las direcciones \\(y-x\\). En otras palabras, la condición dada es equivalente a escribir\n\\[\n-\\nabla f(x)\\in N_{\\Omega}(x),\n\\]\ndonde \\(N_{\\Omega}(x)\\) es el cono normal a \\(\\Omega\\) en \\(x\\).\nEs importante observar que si \\(x\\) es un punto interior de \\(\\Omega\\), sabemos que \\(N_{\\Omega}(x)=\\{\\mathbf{0}\\}\\) y, en consecuencia, debe ser \\(\\nabla f(x)=\\mathbf{0}\\). Esto es consistente con la condición de optimalidad de los problemas sin restricciones.\nNo obstante, la importancia del Teorema 1 radica en cómo tratar los puntos en la frontera de \\(\\Omega\\). A partir de los ejemplos previamente estudiados sobre el cono normal, podemos ver que la interpretación del Teorema 1 es bastante intuitiva. Por ejemplo, si \\(\\Omega\\) es un polígono y \\(x\\in\\Omega\\) es una solución, el vector \\(-\\nabla f(x)\\) es perpendicular a \\(\\Omega\\) y apunta hacia afuera, lo cual significa que no hay posibilidad de “moverse” en dirección opuesta al gradiente sin salirse de \\(\\Omega\\).\n\n\n¡Cuidado! La condición provista por el Teorema 1 es necesaria pero no suficiente. Podría verificarse la condición en otros puntos críticos de \\(\\Omega\\) que no sean un mínimo global de \\(f\\) en dicho conjunto. Sin embargo, para el notable caso de las funciones convexas dicha condición sí es suficiente.\n\nTeorema 2. (Condición necesaria de optimalidad de primer orden para un conjunto factible convexo y una función objetivo convexa) Sea \\(\\Omega \\subseteq  {R}^n\\) convexo y sea \\(f:  {R}^n \\to  {R}\\) una función diferenciable convexa. Entonces \\[\n-\\nabla f(x)\\in N_{\\Omega}(x)\\Leftrightarrow x \\text{ es un minimizador de }f\\text{ en }\\Omega.\n\\]",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#el-caso-particular-de-restricciones-lineales",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#el-caso-particular-de-restricciones-lineales",
    "title": "Condiciones de optimalidad",
    "section": "2.1 El caso particular de restricciones lineales",
    "text": "2.1 El caso particular de restricciones lineales\nVamos a considerar el caso en que \\(\\Omega\\) un polítopo convexo, esto es, el conjunto convexo definido por la intersección de un número finito de medios espacios (desigualdades lineales):\n\\[\n\\Omega=\\{\\xx\\in\\RR^n|A\\xx\\leq \\bb\\},\n\\]\ndonde \\(A\\in\\RR^{m\\times n}\\) es una matriz, cuyas filas denotaremos con \\(\\aa_j\\), \\(j=1,\\cdots,m\\), y \\(\\bb\\in\\RR^m\\).\nEn el ejemplo … (Agregar ejemplo 3.6 de Lecture 2 a ‘Intro’) hemos visto que el cono normal en un punto en la intersección de dos medios espacios es la envolvente cónica de las direcciones ortogonales a dichos subespacios.\n\n\n\nEnvolvente cónica de la intersección de dos subespacios \\(\\aa_1^T\\xx\\leq b_1\\) y \\(\\aa_2^T\\xx\\leq b_2\\).\n\n\nPor otra parte, los otros casos también ya han sido vistos:\n\nSi \\(\\xx\\) pertenece al interior de \\(\\Omega\\), entonces \\(N_{\\Omega}(\\xx)=\\{\\mathbf{0}\\}\\).\nSi \\(\\xx\\) pertenece a la frontera de un único medio espacio, a saber \\(\\aa_k^T\\xx=b_k\\), entonces \\(N_{\\Omega}(\\xx)=\\{\\lambda \\aa_k:\\lambda\\geq 0\\}\\).\n\nLa generalización al caso de \\(m\\) medios espacios se presenta en el siguiente teorema.\n\nTeorema 3. Sea \\(\\Omega=\\{x\\in\\RR^n\\}\\) la intersección de \\(m\\) medios espacios \\(\\aa_j^T\\xx\\leq b_j\\). Dado un punto \\(x\\in\\Omega\\), se define el conjunto de índices de las restricciones activas mediante\n\\[\nI(\\xx):=\\left\\{j\\in\\{1,\\cdots,m\\}:\\aa_j^T\\xx=b_j\\right\\}.\n\\] Entonces, el cono normal en \\(\\xx\\) está dado por\n\\[\nN_{\\Omega}(\\xx)=\\left\\{\\sum_{j\\in I(\\xx)}\\lambda_j\\aa_j:\\lambda_j\\geq 0\\right\\}.\n\\]\n\n\n\nInterpretación\n\n\nSi \\(\\xx\\) pertenece al interior de \\(\\Omega\\), entonces no hay restricciones activas. Esto se corresponde con el hecho de que el cono normal es \\(N_{\\Omega}(\\xx)=\\{\\mathbf{0}\\}\\).\nPor su parte, si \\(\\xx\\) pertenece a la frontera de \\(\\Omega\\), entonces el cono normal es la envolvente cónica de las direcciones ortogonales a las restricciones activas.\nObservar que la condición de optimalidad \\(-\\nabla f(\\xx)\\in N_{\\Omega}(\\xx)\\) se traduce como\n\\[\n-\\nabla f(\\xx)=\\sum_{j\\in I(\\xx)}\\lambda_j\\aa_j,\n\\]\ny, en consecuencia, se puede escribir\n\\[\n\\nabla f(\\xx)-\\sum_{j\\in I(\\xx)}\\lambda_j \\nabla g_j(\\xx)=0,\n\\]\ncon \\(g_j(\\xx)=\\aa_j^T\\xx-b\\). Los coeficientes \\(\\lambda_j\\) se denominan tipicamente multiplicadores de Lagrange.\n\n\nLa suma en la expresión del cono normal puede ser reescrita sin restringir \\(j\\in I(\\xx)\\), simplemente imponiendo \\(\\lambda_j=0\\) para todo \\(j\\notin I(\\xx)\\). Esta imposición queda ímplicita de forma inmediata si se escribe\n\\[\n\\sum_{j=1}^m\\lambda_j\\left(\\aa_j^T\\xx-b_j\\right)=0.\n\\]\nEn forma vectorial, esto es \\(\\bflambda^T\\left(A\\xx-\\bb\\right)=0\\), donde \\(\\bflambda=(\\lambda_1,\\cdots,\\lambda_m)^T\\). Con esta notación, el resultado del Teorema 3 puede reescribirse como\n\\[\nN_{\\Omega}(\\xx)=\\left\\{A^T\\bflambda:\\bflambda^T(A\\xx-\\bb)=0,\\bflambda\\in\\RR^m_{\\geq 0}\\right\\}.\n\\]\nPara concluir este análisis, y teniendo en cuenta lo expuesto hasta aquí, podemos hacer énfasis en tres condiciones necesarias para que una solución sea óptima en este caso particular de restricciones lineales.\n\nPara que \\(\\xx\\in\\Omega\\) sea un minimizador de \\(f\\) sobre \\(\\Omega\\), debe cumplir:\n\nEstacionariedad: El gradiente debe ser una combinación lineal de los gradientes de las restricciones activas. \\[\n\\nabla f(\\xx)-\\sum_{j=1}^{m}\\lambda_j(\\aa_j^T\\xx-b_j).\n\\]\nFactibilidad dual: Los multiplicadores de Lagrange asociados a las restricciones de desigualdad deben ser no negativos. \\[\n\\lambda_j\\geq 0 \\quad \\forall j=1,\\cdots,m.\n\\]\nHolgura complementaria: Los multiplicadores de Lagrange solo pueden ser positivos si la restricción está activa. \\[\n\\lambda_j\\left(\\aa_j^T\\xx-b_j\\right)=0 \\quad \\forall j=1,\\cdots,m.\n\\]\n\n\n Las condiciones mencionadas se conocen como condiciones de Karush-Kuhn-Tucker y son una consecuencia de la caracterización del cono normal para conjuntos definidos como interseccion de restricciones lineales, provista por el Teorema 3. Ya estamos en condiciones de abordar el problema de optimización general.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#generalización",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#generalización",
    "title": "Condiciones de optimalidad",
    "section": "2.2 Generalización",
    "text": "2.2 Generalización\nConsideremos el problema de optimización general \\[\n\\min_{x} f(x)\n\\] \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\nh_i(x)= 0,& i=1,\\cdots,r.\\\\\ng_j(x)\\leq 0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\ndonde \\(\\Omega\\) está definido como una intersección de restricciones funcionales diferenciables.\nSupongamos que \\(\\xx^*\\) es un punto óptimo en la frontera del conjunto factible \\(\\Omega\\) correspondiente a tres condiciones de desigualdad \\(g_i(x) \\le 0\\) para \\(i=1,2,3\\) (ver figura abajo). La idea principal es la siguiente:\n\nEl conjunto de direcciones que forma un ángulo obtuso con todas las direcciones desde \\(\\xx^*\\) que permanecen en \\(\\Omega\\) coincide con el cono normal de la linearización de las restricciones activas en \\(\\xx^*\\).\n\n\n\n\nEnvolvente cónica de la intersección de restricciones \\(g_i(\\xx)\\leq 0\\), para \\(i=1,2,3\\).\n\n\nSi aplicamos la idea anterior a \\(-\\nabla f(\\xx)\\) y consideramos el Teorema 3, obtenemos la generalización de las condiciones de optimalidad de Karush-Kuhn-Tucker (KKT). Denominemos \\(\\tilde{\\Omega}\\) la linearización de \\(\\Omega\\), dado por la linearización de las restricciones en un punto óptimo \\(\\xx^*\\):\n\\[\nh_i(\\xx^*)+\\nabla h_i(\\xx^*)\\cdot (\\xx-\\xx^*)=0,\n\\]\n\\[\ng_i(\\xx^*)+\\nabla g_i(\\xx^*)\\cdot (\\xx-\\xx^*)\\leq 0.\n\\]\nEntonces, por Teorema 3, resulta\n\\[\nN_{\\tilde{\\Omega}}(\\xx^*)=\\left\\{\\sum_{i=1}^m\\lambda_i\\nabla h_i(\\xx^*)+\\sum_{j\\in I(\\xx^*)}\\mu_j\\nabla g_j(\\xx^*): \\lambda_i\\in\\RR, \\mu_j\\in\\RR_{\\geq 0}\\right\\},\n\\]\ndonde \\(I(\\xx^*):=\\left\\{j\\in\\{1,\\cdots,m\\}: g_j(\\xx^*)=0\\right\\}\\). Por supuesto, puede reformularse la condición $jI(^*) utilizando holgura complementaria, tal como antes.\nSi bien no estamos aún en condiciones de extender el Teorema 3, puesto que el desarrollo previo fue más bien intuitivo, podemos establecer las condiciones KKT mediante una definición formal de la siguiente manera.\n\nDefinición 1. (Condiciones de Karush-Kuhn-Tucker (KKT) Sea un problema de optimización no lineal con función objetivo diferenciable y restricciones funcionales, de la forma \\[\n\\text{s.t.}\\; x\\in\\Omega=\\left\\{x\\in\\RR^n\\left|\\begin{array}{rl}\nh_i(x)= 0,& i=1,\\cdots,r.\\\\\ng_j(x)\\leq 0, & j=1,\\cdots,m.\n\\end{array}\\right.\\right\\},\n\\]\ny sea \\(\\xx\\in\\Omega\\) (factibilidad primal). Las condiciones KKT en \\(\\xx\\) están dadas por:\n\nEstacionariedad: \\[\n-\\nabla f(\\xx)=\\sum_{i=1}^r\\lambda_i\\nabla h_i(\\xx)+\\sum_{j=1}^m\\mu_j\\nabla g_j(\\xx).\n\\]\nFactibilidad dual: \\[\n\\lambda_i\\in\\RR, \\mu_j\\in\\RR_{\\geq 0}\\quad\\forall i=1,\\cdots,r, \\forall j=1,\\cdots, m.\n\\]\nHolgura complementaria: \\[\n\\mu_j g_j(\\xx)=0\\quad \\forall j=1,\\cdots,m.\n\\]\n\n\nEs importante remarcar que:\n\nLas condiciones KKT indican que -\\(\\nabla f(\\xx)\\) debe estar en el cono normal a la linearización del conjunto de restricciones.\nLa condición de holgura compelementaria se resume en “si la restricción \\(g_j(\\xx)\\leq 0\\) no está activa, entonces \\(\\mu_j=0\\)”.\nLas condiciones KKT a menudo son necesarias para la optimalidad, pero no siempre.\n\nA continuación, veremos un ejemplo donde las condiciones KKT fallan. Luego, en la siguiente sección veremos en qué escenarios las condiciones KKT son efectivamente una condición necesaria de optimalidad.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#cualificación-de-restricciones",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#cualificación-de-restricciones",
    "title": "Condiciones de optimalidad",
    "section": "2.3 Cualificación de restricciones",
    "text": "2.3 Cualificación de restricciones",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#función-dual-de-lagrange",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#función-dual-de-lagrange",
    "title": "Condiciones de optimalidad",
    "section": "3.1 Función dual de Lagrange",
    "text": "3.1 Función dual de Lagrange\n\nDefinición 2. (Lagrangiano) Sea el problema de optimización general \\[\n\\min f(\\xx)\n\\] \\[\n\\text{sujeto a}\\; \\xx\\in\\Omega=\\left\\{\\xx\\in\\RR^p\\left|\\begin{array}{rl}\ng_i(\\xx)\\leq 0,& i=1,\\cdots,q\\\\\nh_j(\\xx)= 0, & j=1,\\cdots,r\n\\end{array}\\right.\\right\\}.\n\\]\nSe denomina Lagrangiano a la función \\(\\calL:\\RR^p\\times\\RR^q\\times\\RR^r\\to\\RR\\) definida por \\[\n\\calL(\\xx,\\bflambda,\\bfnu)=f(\\xx)+\\sum_{i=1}^q\\lambda_i g_i(\\xx)+\\sum_{j=1}^r\\nu_j h_j(\\xx).\n\\]\n\nLos vectores \\(\\bflambda\\) y \\(\\bfnu\\), cuyas componentes son multiplicadores de Lagrange, se denominan variables duales del problema de optimización y son el argumento de la función definida a continuación. A su vez, al problema de optimización original se lo denomina problema primal.\n\nDefinición 3. (Función dual) Sea \\(\\calL\\) el Lagrangiano de la Definición 2. Se denomina función dual de Lagrange a \\(\\calG:\\RR^q\\times\\RR^r\\to\\RR\\) definida por \\[\n\\calG(\\bflambda,\\bfmu)=\\inf_{\\xx}\\calL(\\xx,\\bflambda,\\bfnu).\n\\]\nCuando el Lagrangiano no está acotado inferiormente en \\(\\xx\\), se asume el valor \\(-\\infty\\).\n\nDado que la función dual es el ínfimo puntual de una familia de funciones afínes de \\((\\bflambda,\\bfnu)\\), es cóncava, aún cuando el problema primal no sea convexo [ver Ejercicio …].\nLa propiedad más importante de la función dual es que es una cota inferior del valor óptimo \\(p^*\\) del problema primal. Es decir, para todo \\(\\bflambda\\geq 0\\) y cualquier \\(\\bfnu\\), resulta \\[\n\\calG(\\bflambda,\\bfnu)\\leq p^*.\n\\]\n\n\nVerificación\n\n\nSea \\(\\tilde{\\xx}\\) un punto factible del problema primal. Entonces \\(g_i(\\tilde{\\xx})\\leq 0\\) y \\(h_j(\\tilde{\\xx})=0\\) para todo \\(i=1,\\cdots,q\\) y \\(j=1,\\cdots,r\\), respectivamente. Por lo tanto, para \\(\\bflambda\\geq 0\\) se tiene que \\[\n\\sum_{i=1}^q\\lambda_ig_i(\\tilde{\\xx})+\\sum_{j=1}^r\\nu_j h_j(\\tilde{\\xx})\\geq 0.\n\\]\nSumando \\(f(\\tilde{\\xx})\\) a ambos miembros, se obtiene \\(\\calL(\\xx,\\bflambda,\\bfnu)\\leq f(\\tilde{\\xx})\\). Luego, por propiedad del ínfimo, resulta \\[\n\\calG(\\bflambda,\\bfnu)\\leq f(\\tilde{\\xx}).\n\\]\nFinalmente, dado que \\(\\tilde{\\xx}\\) es cualquier punto factible, en particular la desigualdad anterior es cierta para un punto óptimo \\(\\xx^*\\) tal que \\(f(\\xx^*)=p^*\\).",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#el-problema-dual-de-lagrange",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#el-problema-dual-de-lagrange",
    "title": "Condiciones de optimalidad",
    "section": "3.2 El problema dual de Lagrange",
    "text": "3.2 El problema dual de Lagrange\nInmediatamente nos podemos preguntar: ¿cual es el valor máximo \\(d^*\\) de \\(\\calG(\\bflambda,\\bfnu)\\) si asumimos \\(\\bflambda\\geq 0\\)? Esto da lugar al problema que definiremos a continuación. Observar que la desigualdad \\(\\calG(\\bflambda,\\bfnu)\\leq p^*\\) implica \\[\nd^*\\leq p^*.\n\\]\n\nDefinición 3. (Problema dual) Sea \\(\\calG\\) la función dual de Lagrange asociado al problema primal de la Definición 2. El problema dual de Lagrange es \\[\n\\max \\calG(\\bflambda,\\bfnu)\n\\] \\[\n\\text{sujeto a }\\; \\bflambda\\geq 0.\n\\]\n\nEn línea con la notación anterior, denominaremos multiplicadores óptimos a un par \\((\\bflambda^*,\\bfnu^*)\\) que es solución del problema dual. Es decir, verifican \\(\\calG(\\bflambda^*,\\bfnu^*)=d^*\\).\nEl problema dual de Lagrange es un problema de optimización convexo, independientemente de que el problema primal sea convexo o no. Esto se debe a que la función a maximizar es cóncava y la restricción es un conjunto convexo.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#suboptimalidad-y-criterio-de-parada",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#suboptimalidad-y-criterio-de-parada",
    "title": "Condiciones de optimalidad",
    "section": "3.3 Suboptimalidad y criterio de parada",
    "text": "3.3 Suboptimalidad y criterio de parada\nLos puntos factibles duales nos permiten acotar cuán subóptimo es un punto factible dado, sin conocer el valor exacto de \\(p^{*}\\). De hecho, si \\(\\xx\\) es factible primal y \\((\\bflambda, \\bfnu)\\) es factible dual, entonces se cumple la siguiente desigualdad: \\[\nf(\\xx) - p^{*} \\leq f(\\xx)-\\calG(\\bflambda, \\bfnu).\n\\]\nEn particular, esto establece que \\(\\xx\\) es \\(\\epsilon\\)-subóptimo, con \\[\\epsilon = f(\\xx) - g(\\bflambda, \\bfnu).\n\\]\nLa brecha \\(\\epsilon\\) se conoce como brecha de dualidad para los puntos factibles \\(\\xx\\) y \\((\\bflambda,\\bfnu)\\). Para dichos puntos, los valores óptimos de los problemas primal y dual verifican \\[\np^*,d^*\\in\\left[g(\\bflambda,\\bfnu), f(\\xx)\\right],\n\\] donde el ancho del intervalo es justamente la brecha de dualidad. Observar que si \\(\\epsilon=0\\), entonces \\(\\xx\\) es óptimo primal y \\((\\bflambda,\\bfnu)\\) es óptimo dual.\nEl concepto de brecha de dualidad puede usarse en algoritmos de optimización para proporcionar criterios de parada no heurísticos. Supongamos que un algoritmo produce una secuencia de puntos factibles primales \\(\\xx^{(k)}\\) y puntos factibles duales \\((\\bflambda^{(k)}, \\bfnu^{(k)})\\), para \\(k = 1, 2, \\ldots\\), y sea \\(\\epsilon_{\\text{abs}} &gt; 0\\) una precisión absoluta requerida. Entonces, el criterio de parada \\[\nf(\\xx^{(k)}) - g(\\bflambda^{(k)}, \\bfnu^{(k)}) \\leq \\epsilon_{\\text{abs}}\n\\]\ngarantiza que, cuando el algoritmo termina, \\(\\xx^{(k)}\\) es \\(\\epsilon_{\\text{abs}}\\)-subóptimo. Por supuesto, la dualidad fuerte debe cumplirse si se pretende que este método funcione para tolerancias \\(\\epsilon_{\\text{abs}}\\) arbitrariamente pequeñas.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#holgura-complementaria",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#holgura-complementaria",
    "title": "Condiciones de optimalidad",
    "section": "3.4 Holgura complementaria",
    "text": "3.4 Holgura complementaria\nSupongamos que los valores óptimos primal y dual se alcanzan y son iguales. Esto es, se cumple la desigualdad fuerte \\(p^*=d^*\\). Esto significa que para puntos óptimos \\(\\xx^*\\) y \\((\\bflambda^*,\\bfnu^*)\\) se verifica \\[\n\\begin{align*}\nf(\\xx^{*}) &= \\calG(\\bflambda^{*}, \\bfnu^{*}) \\\\\n&= \\inf_{x} \\left( f(\\xx) + \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(x) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx) \\right)\\\\\n& \\leq f(\\xx^{*}) + \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx^{*}) \\\\&\\leq f(\\xx^{*}).\n\\end{align*}\n\\]\nLa justificación de cada uno los pasos es sencilla [Ejercicio …]. Concluimos que las dos desigualdades en esta cadena se cumplen con igualdad. En particular, la última igualdad\n\\[\nf(\\xx^*)+ \\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx^{*})=f(\\xx^*)\n\\]\nimplica que\n\\[\n\\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx^{*}) = 0.\n\\]\nPero cada término en esta suma es no positivo, por lo tanto debe verificarse\n\\[\n\\boxed{\\lambda_{i}^{*} g_{i}(\\xx^{*}) = 0, \\quad \\forall i = 1, \\ldots, q.}\n\\]\nEsta es la condición de holgura complementaria que hemos visto en la sección anterior. Se cumple para cualquier punto óptimo primal \\(\\xx^{*}\\) y cualquier punto óptimo dual \\((\\bflambda^{*}, \\bfnu^{*})\\) bajo dualidad fuerte. Recordemos que, en términos generales, esta condición significa que el \\(i\\)-ésimo multiplicador de Lagrange óptimo es cero salvo que la \\(i\\)-ésima restricción esté activa.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "CAPITULO_1/A4_condiciones_optimalidad.html#relación-entre-dualidad-y-kkt",
    "href": "CAPITULO_1/A4_condiciones_optimalidad.html#relación-entre-dualidad-y-kkt",
    "title": "Condiciones de optimalidad",
    "section": "3.5 Relación entre dualidad y KKT",
    "text": "3.5 Relación entre dualidad y KKT\nLos conceptos de Lagrangiano y su función dual han permitido caracterizar la relación entre los valores óptimos \\(p^*\\) y \\(d^*\\). En particular, las condiciones de factibilidad dual y de holgura complementaria de la Definición 1 (Condiciones de Karush-Kuhn-Tucker) han permitido primero escribir la desigualdad \\(\\calG(\\bflambda,\\bfmu)\\leq p^*\\) y luego analizar qué sucede cuando \\(p^*=q^*\\).\nVeamos ahora cómo surge la estacionariedad en este contexto. Podemos afirmar que\n\\[\nf(\\xx^*)\\leq f(\\xx)+\\sum_{i=1}^{q} \\lambda_{i}^{*} g_{i}(\\xx) + \\sum_{j=1}^{r} \\nu_{j}^{*} h_{j}(\\xx)\n\\]\npara todo punto factible \\(\\xx\\), con igualdad si \\(\\xx=\\xx^*\\). El lado derecho es el Lagrangiano \\(L(\\xx,\\bflambda^*,\\bfnu^*)\\), del cual podemos afirmar que \\(\\xx\\) es un minimizador. En consecuencia, debe verificarse\n\\[\n\\begin{align*}\n  \\nabla L(\\xx^*,\\bflambda^*,\\bfnu^*)&=0\\\\\n  \\nabla f(\\xx^*)+\\sum_{i=1}^q\\lambda_i^*\\nabla g_i(\\xx^*)+\\sum_{j=1}^r\\nu_j^*\\nabla h_j(\\xx^*)&=0.\n\\end{align*}\n\\]\n\nTeorema 4. (Dualidad y KKT) Sea \\(\\xx^*\\) un punto óptimo primal y \\((\\bflambda^*,\\bfnu^*)\\) un punto óptimo dual. Si \\(p^*=q^*\\), entonces \\((\\xx^*,\\bflambda^*,\\bfnu^*)\\) satisfacen las condiciones de Karush-Kuhn-Tucker.",
    "crumbs": [
      "1. OPTIMIZACIÓN MATEMÁTICA",
      "1.4 Condiciones de optimalidad"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "",
    "text": "1.1 Introducción a la optimización\n1.2 Optimización convexa\n1.3 Herramientas computacionales para optimización\n1.4 Condiciones de optimalidad\n1.5 Métodos de optimización"
  },
  {
    "objectID": "index.html#optimización-matemática",
    "href": "index.html#optimización-matemática",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "",
    "text": "1.1 Introducción a la optimización\n1.2 Optimización convexa\n1.3 Herramientas computacionales para optimización\n1.4 Condiciones de optimalidad\n1.5 Métodos de optimización"
  },
  {
    "objectID": "index.html#modelos-discriminativos",
    "href": "index.html#modelos-discriminativos",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "2 Modelos discriminativos",
    "text": "2 Modelos discriminativos\n\nRegresión lineal\nRegresión logística\nGLM\nPenalización Ridge/Lasso\nSVM lineal (clasificador de vectores soporte)\nEvaluación?"
  },
  {
    "objectID": "index.html#modelos-generativos",
    "href": "index.html#modelos-generativos",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "3 Modelos generativos",
    "text": "3 Modelos generativos\n\nMáxima verosimilitud\nLDA y QDA\nGMM\nK medias\nAlgoritmo EM"
  },
  {
    "objectID": "index.html#modelos-y-métodos-avanzados",
    "href": "index.html#modelos-y-métodos-avanzados",
    "title": "Optimización y Aprendizaje Automático II",
    "section": "4 Modelos y métodos avanzados",
    "text": "4 Modelos y métodos avanzados\n\nSVM no lineal (kernels, RKHS)\nNNs (perceptrón, backpropagation, CNNs, RNNs, +-)\nAutoencoders\nMétodos de optimización avanzados (AdaGrad, RMSProp, ADAM, ADMM, +-)"
  }
]