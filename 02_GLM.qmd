---
title: "Modelos lineales generalizados"
lang: es
format:
  live-html:
    pyodide:
      cell-options:
        edit: true
        include: true
    css: style.css
    toc: true
    toc-depth: 3
    toc-location: left
    toc-floating: true
number-sections: true
---


::: {.hidden} 
$$
\def\RR{\mathbb{R}}
\def\media{\mathbb{E}}
\def\xx{{\bf x}}
\def\XX{{\bf X}}
\def\TT{{\bf T}}
\def\bftheta{\boldsymbol{\theta}}
\def\bfeta{\boldsymbol{\eta}}
\def\bfone{\mathbf{1}}
$$ 
:::

<hr style="border: 1px solid rgba(50, 0, 0, 1);">



Tanto en el modelo de regresión lineal como en el de regresión logística, asumimos una cierta distribución condicional para $Y|\XX$ que depende de un conjunto de parámetros $\bftheta$. 

- En regresión lineal, suponemos $Y|\XX\sim\mathcal{N}(\mu,\sigma^2)$ con $\mu=\bftheta^T\XX$.

- En regresión logística, que recordemos está pensado para problemas de clasificación, suponemos $Y|\XX\sim\text{Bernoulli}(\phi)$ con $\phi=g(\bftheta^T\XX)$, donde $g(z)=1/(1+e^{-z})$.

En esta sección mostraremos que ambos métodos son casos especiales de una familia más amplia de modelos, llamados **Modelos Lineales Generalizados (GLMs)**. También mostraremos cómo otros modelos en GLM pueden derivarse y aplicarse a otros problemas de regresión y clasificación. 


# La familia exponencial

::: {.definicion}
**Definición:**  Decimos que una clase de distribuciones pertenece a la familia exponencial si se puede escribir en la forma

$$p(y; \bfeta) = b(y) \exp\left(\bfeta^T \TT(y) - a(\bfeta)\right)$$
:::


- $\bfeta$ se llama **parámetro natural** de la distribución.
- $\TT(y)$ es el **estadístico suficiente**.
- $a(\bfeta)$ es la **función de partición logarítmica** que normaliza la expresión para que la distribución sea válida (es decir, integre a 1).


Una elección fija de $\TT$, $a$ y $b$ define un conjunto de distribuciones parametrizadas por $\bfeta$, de manera que al variar $\bfeta$ obtenemos diferentes distribuciones dentro de esta familia.

## Ejemplos

Mostraremos que las distribuciones Bernoulli y Normal son ejemplos de distribuciones de la familia exponencial.

### Distribución Bernoulli

Sea $Y\in\{0,1\}$ tal que $Y\sim\text{Bernoulli}(\phi)$. Entonces


$$
\begin{align*}
p(y; \phi) &= \phi^y (1 - \phi)^{1-y} \\ 
& = \exp\left( y \log\phi + (1-y)\log(1-\phi) \right) \\
& = \exp\left(\log\left(\frac{\phi}{1-\phi}\right)y+\log(1-\phi)\right) \\
& = \exp\left(\log\left(\frac{\phi}{1-\phi}\right)y+\log(1-\phi)\right)
\end{align*}
$$

Reconocemos el parámetro natural
$$\eta=\log\left(\frac{\phi}{1-\phi}\right)$$

mientras que el resto de los elementos son:
$$T(y)=y, \qquad a(\eta)=-\log(1-\phi)=\log(1+e^\eta), \qquad b(y)=1.$$



### Distribución Gaussiana

Sea $Y\in\RR$ tal que $Y\sim\mathcal{N}(\mu,\sigma^2)$. Entonces

$$
\begin{align*}
p(y; \mu, \sigma^2) & = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(y - \mu)^2}{2\sigma^2}\right) \\
& = \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2\sigma^2}y^2+\frac{\mu}{\sigma^2}y-\frac{\mu^2}{2\sigma^2}-\log\sigma\right) \\
& = \frac{1}{\sqrt{2\pi}}\exp\left(\left(\frac{\mu}{\sigma^2},-\frac{1}{2\sigma^2}\right)^T(y,y^2)-\frac{\mu^2}{2\sigma^2}-\log\sigma\right)
\end{align*}
$$

El parámetro natural es el vector

$$\bfeta=\left(\frac{\mu}{\sigma^2},-\frac{1}{2\sigma^2}\right)$$

y el resto de los elementos son
$$\TT(y)=(y,y^2), \qquad a(\bfeta)=\frac{\mu^2}{2\sigma^2}+\log\sigma=-\frac{\eta_1^2}{4\eta_2}+\frac{1}{2}\log(-2\eta_2), \qquad b(y)=\frac{1}{\sqrt{2\pi}}.$$

---

Existen muchas otras distribuciones que son miembros de la familia exponencial: la multinomial (que veremos más adelante), la Poisson (para modelar datos de conteo), la gamma y la exponencial (para modelar variables continuas no negativas, como intervalos de tiempo); la beta y la Dirichlet (para distribuciones sobre probabilidades); y muchas más. 

En la próxima sección, describiremos una "receta" general para construir modelos en los cuales $y$ (dado $\xx$ y $\theta$) proviene de cualquiera de estas distribuciones.


# Construcción de GLMs

Supongamos que deseas construir un modelo para estimar el número $y$ de clientes que llegan a tu tienda (o el número de visitas a páginas web en tu sitio) en una hora determinada, basándote en ciertas características como promociones en la tienda, publicidad reciente, clima, día de la semana, etc. Sabemos que la distribución Poisson usualmente proporciona un buen modelo para el número de visitantes. Sabiendo esto, ¿cómo podemos proponer un modelo para nuestro problema? Afortunadamente, la Poisson es una distribución de la familia exponencial, por lo que podemos aplicar un Modelo Lineal Generalizado (GLM). En esta sección, describiremos un método para construir modelos GLM para problemas como este.

Más generalmente, consideremos un problema de regresión o clasificación o regresión donde queremos predecir el valor de alguna variable aleatoria $y$ como función de $\xx$. Para derivar un GLM para este problema, haremos las siguientes tres suposiciones:

::: {.highlight}
**Suposición 1:**  $y|\xx;\bftheta\sim\text{FamiliaExponencial}(\bfeta)$.

**Suposición 2:** Dado $\xx$, el objetivo es predecir $\media[T(y)|\xx]$.

**Suposición 3:** El parámetro natural $\bfeta$ y las predictoras $\xx$ están relacionadas linealmente; esto es, $\bfeta=\bftheta^T\xx$.
:::


Generalmente $T(y)=y$ y, en tal caso, la suposición 2 significa que queremos que la predicción sea $h(\xx)=\media[\xx]$. Por otra parte, si el parámetro natural $\bfeta$ es un vector, observar que la suposición 3 implica que $\bftheta$ debe ser una matriz. Esta última suposición podría parecer la menos justificada de las anteriores, y podría considerarse más como una "elección de diseño" en nuestra receta para diseñar GLMs, en lugar de una suposición como tal. 

Estas tres suposiciones o elecciones de diseño nos permitirán derivar una clase muy elegante de algoritmos de aprendizaje, a saber, los GLMs, que tienen muchas propiedades deseables, como la facilidad de aprendizaje. Además, los modelos resultantes son frecuentemente muy efectivos.


## Terminología

- La función $g(\bfeta) = \mathbb{E}[T(y); \bfeta]$ se denomina **función de respuesta canónica**.

- La inversa de esta función, $g^{-1}$, se llama la **función de enlace canónica**.
  

# Ajuste de parámetros

Los Modelos Lineales Generalizados (GLMs) son una extensión poderosa de los modelos lineales que permite trabajar con una amplia variedad de distribuciones en la familia exponencial. En esta sección, discutiremos en detalle cómo se ajustan los parámetros de un GLM usando el principio de máxima verosimilitud.

## El principio de máxima verosimilitud

El ajuste de parámetros en los GLMs se basa en maximizar la log-verosimilitud de los datos observados. Dado un conjunto de entrenamiento $\{(\xx^{(i)}, y^{(i)})\}_{i=1}^n$, la función de log-verosimilitud está dada por:

$$
\ell(\theta) = \log L(\theta) = \sum_{i=1}^n \log p(y^{(i)} | \xx^{(i)}; \theta).
$$

Para maximizar $\ell(\theta)$, derivamos con respecto a $\theta$ para obtener el gradiente. En GLMs, las propiedades de la familia exponencial simplifican esta derivada, que resulta ser:

$$
\nabla_\theta \ell(\theta) = \sum_{i=1}^n (T(y^{(i)}) - \mathbb{E}[T(y) | \xx^{(i)}; \theta]) \xx^{(i)}.
$$

A continuación describiremos dos métodos iterativos para realizar la tarea de maximizar la log-verosimilitud.

### El método de gradiente descendente

Este método optimiza $\ell(\bftheta)$ iterativamente ajustando los parámetros en la dirección opuesta al gradiente de la función objetivo, con un paso de tamaño controlado por una tasa de aprendizaje $\alpha$:

$$
\bftheta^{(t+1)} = \bftheta^{(t)} - \alpha \nabla_\theta \ell(\bftheta^{(t)}).
$$

El gradiente descendente es computacionalmente barato, pero su convergencia puede ser lenta, especialmente si no se ajusta adecuadamente la tasa de aprendizaje.

### El método de Newton-Raphson

Este método requiere calcular la Hessiana de $\ell(\theta)$, que es la matriz de segundas derivadas

$$
H(\bftheta) = \sum_{i=1}^n \left(-\text{Var}[T(y) | \xx^{(i)}; \bftheta]\right) \xx^{(i)} (\xx^{(i)})^T,
$$

El método de Newton-Raphson actualiza $\bftheta$ como:

$$
\bftheta^{(t+1)} = \bftheta^{(t)} - H(\bftheta^{(t)})^{-1} \nabla_\theta \ell(\bftheta^{(t)}).
$$

Aunque este método converge rápidamente en muchas aplicaciones, calcular la Hessiana e invertirla puede ser computacionalmente costoso para modelos de alta dimensionalidad.


# Regresión Softmax

Consideremos un problema de clasificación en el que $Y \in \{1, 2, \ldots, k\}$. Por ejemplo, en lugar de clasificar correos electrónicos en dos clases (spam o no spam), podríamos clasificarlos en tres clases: spam, correo personal y correo relacionado con el trabajo. Para modelar esta situación, usaremos la **distribución multinomial** como una distribución de la familia exponencial.


## La distribución multinomial como familia exponencial

Supongamos que $Y\in\{1, 2, \cdots, k\}$ se distribuye mediante una distribución multinomial con $k-1$ parámetros $\phi_1, \dots, \phi_{k-1}$, y sea $\phi_k=1-\sum_{i=1}^{k-1}\phi_i$, tal que $\sum_{i=1}^k \phi_i = 1$. Para expresar la multinomial como una distribución de la familia exponencial, definimos

$$
T(1) = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, 
\quad
T(2) = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}, 
\quad \dots, \quad
T(k-1) = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix},
\quad 
T(k) = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{pmatrix}.
$$

En lo que sigue, $\bfone\{\cdot\}$ es la función indicatriz, que vale 1 si su argumento es cierto y 0 en caso contrario. Resulta

$$
\begin{align*}
p(y; \mathbf{\phi})& =
\phi_1^{\bfone\{y=1\}} \phi_2^{\bfone\{y=2\}} \cdots \phi_k^{\bfone\{y=k\}}\\
&= \phi_1^{(T(y))_1} \phi_2^{(T(y))_2} \cdots \phi_{k-1}^{(T(y))_{k-1}} \left(1 - \sum_{i=1}^{k-1} \phi_i\right)^{1-\sum_{i=1}^{k-1}(T(y))_i}
\\
&= \exp\left((T(y))_1 \log(\phi_1) + (T(y))_2 \log(\phi_2) + \dots + \left(1 - \sum_{i=1}^{k-1}(T(y))_i\right)\log\left(1 - \sum_{i=1}^{k-1} \phi_i\right)\right).
\end{align*}
$$

Así, $Y$ se distribuye en la familia exponencial

$$
p(y; \phi) = b(y) \exp\left(\eta^T T(y) - a(\eta)\right),
$$

donde:

$$
\begin{align*}
\eta &= \begin{bmatrix}
\log\left(\frac{\phi_1}{\phi_k}\right) \\
\log\left(\frac{\phi_2}{\phi_k}\right) \\
\vdots \\
\log\left(\frac{\phi_{k-1}}{\phi_k}\right)
\end{bmatrix},
\\
a(\eta) &= -\log(\phi_k),
\\
b(y)& = 1.
\end{align*}
$$

Esto completa nuestra formulación de la multinomial como una distribución de la familia exponencial.


La función que mapea \(\eta\) a \(\phi\) se llama la **función softmax**:

## Función de Enlace y Función de Respuesta

La función de enlace está dada (para $i = 1, \dots, k$) por:

$$
\eta_i = \log\left(\frac{\phi_i}{\phi_k}\right).
$$

Para conveniencia, también definimos $\eta_k = \log(\phi_k / \phi_k) = 0$. Para invertir la función de enlace y derivar la función de respuesta, tenemos que:

$$
e^{\eta_i} = \frac{\phi_i}{\phi_k},
$$

lo que implica:

$$
\phi_k \sum_{i=1}^k e^{\eta_i} = \sum_{i=1}^k \phi_i = 1.
$$

Por lo tanto:

$$
\phi_k = \frac{1}{\sum_{i=1}^k e^{\eta_i}},
$$

y al sustituir en la ecuación obtenemos la función de respuesta:

$$
\phi_i = \frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}.
$$



## Softmax Function y Modelo de Clasificación

La función que mapea de $\eta$ a $\phi$ se llama la función \textit{softmax}. 

Para completar nuestro modelo, usamos la Asunción 3, mencionada previamente, donde los $\eta_i$ están relacionados linealmente con los $x$'s. Así, tenemos $\eta_i = \theta_i^T x$ (para $i = 1, \dots, k - 1$), donde $\theta_1, \dots, \theta_{k-1} \in \mathbb{R}^{d+1}$ son los parámetros de nuestro modelo. Por notación, podemos definir $\theta_k = 0$, de modo que $\eta_k = \theta_k^T x = 0$, como se definió anteriormente. Por lo tanto, nuestro modelo asume que la distribución condicional de $y$ dado $x$ está dada por:

$$
\begin{align*}
p(y = i | x; \theta) &= \phi_i\\
&= \frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}\\
&= \frac{e^{\theta_i^T x}}{\sum_{j=1}^k e^{\theta_j^T x}}, \quad (5)
\end{align*}
$$

donde este modelo, que aplica a problemas de clasificación donde $y \in \{1, \dots, k\}$, se llama \textit{regresión softmax}. Es una generalización de la regresión logística.

### Hipótesis del Modelo

Nuestra hipótesis producirá:

$$
\begin{align*}
h_\theta(x) &= \mathbb{E}[T(y) | x; \theta]
\\
&= \mathbb{E}
\begin{bmatrix}
1\{y = 1\} \\
1\{y = 2\} \\
\vdots \\
1\{y = k - 1\}
\end{bmatrix}
\\&=
\begin{bmatrix}
\phi_1 \\
\phi_2 \\
\vdots \\
\phi_{k-1}
\end{bmatrix}
\\&=
\begin{bmatrix}
\frac{\exp(\theta_1^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)} \\
\frac{\exp(\theta_2^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)} \\
\vdots \\
\frac{\exp(\theta_{k-1}^T x)}{\sum_{j=1}^k \exp(\theta_j^T x)}
\end{bmatrix}.
\end{align*}
$$

En otras palabras, nuestra hipótesis producirá la probabilidad estimada de que $p(y = i | x; \theta)$ para cada valor $i = 1, \dots, k$. (Aunque $h_\theta(x)$, como se definió arriba, tiene solo $k - 1$ dimensiones, claramente $p(y = k | x; \theta)$ puede obtenerse como $1 - \sum_{i=1}^{k-1} \phi_i$).



## Ajuste de Parámetros

Por último, discutamos el ajuste de parámetros. Similar a nuestra derivación original de mínimos cuadrados ordinarios y regresión logística, si tenemos un conjunto de entrenamiento de $n$ ejemplos $\{(x^{(i)}, y^{(i)}); i = 1, \dots, n\}$ y deseamos aprender los parámetros $\theta_i$ de este modelo, comenzaríamos escribiendo la log-verosimilitud:

$$
\begin{align*}
\ell(\theta) &= \sum_{i=1}^n \log p(y^{(i)} | x^{(i)}; \theta)
\\
&= \sum_{i=1}^n \log \prod_{l=1}^k \left( \frac{e^{\theta_l^T x^{(i)}}}{\sum_{j=1}^k e^{\theta_j^T x^{(i)}}} \right)^{1\{y^{(i)} = l\}}.
\end{align*}
$$

Para obtener la segunda línea anterior, usamos la definición de $p(y | x; \theta)$ dada en la Ecuación (5). Ahora podemos obtener la estimación de máxima verosimilitud de los parámetros maximizando $\ell(\theta)$ en términos de $\theta$, utilizando un método como ascenso de gradiente o el método de Newton.



ACA FALTA AJUSTE DE PARAMETROS PARA EL MODELO GLM EN GENERAL
eso esta en el video de el viejo del 2008 , no esta en el nuevo. 
seria importante poner algo


### Ejemplo Práctico en Python

Implementemos un ejemplo práctico para un problema de clasificación multiclasificación.

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Generar datos simulados para clasificación multiclase
X, y = make_classification(
    n_samples=300, n_features=2, n_informative=2, n_redundant=0,
    n_classes=3, n_clusters_per_class=1, random_state=42
)

# Visualizar los datos
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap="viridis")
plt.title("Datos de Clasificación Multiclase")
plt.xlabel("Característica 1")
plt.ylabel("Característica 2")
plt.colorbar(scatter, label="Clases")
plt.grid(True)
plt.show()

# Dividir los datos en entrenamiento y prueba
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Ajustar el modelo de regresión softmax
model = LogisticRegression(multi_class="multinomial", solver="lbfgs", max_iter=200)
model.fit(X_train, y_train)

# Predicciones
y_pred = model.predict(X_test)

# Frontera de decisión
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                     np.arange(y_min, y_max, 0.01))
Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, alpha=0.8, cmap="viridis")
scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor="k", cmap="viridis")
plt.title("Frontera de Decisión: Regresión Softmax")
plt.xlabel("Característica 1")
plt.ylabel("Característica 2")
plt.colorbar(scatter, label="Clases")
plt.grid(True)
plt.show()

# Evaluación del modelo
print("Reporte de Clasificación:")
print(classification_report(y_test, y_pred))
print("Matriz de Confusión:")
print(confusion_matrix(y_test, y_pred))
```
